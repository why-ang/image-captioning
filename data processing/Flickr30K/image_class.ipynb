{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/why/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import h5py\n",
    "import json\n",
    "import os\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_folder, data_name, split):\n",
    "        \n",
    "        # Open hdf5 file where images are stored\n",
    "        self.split = split\n",
    "        self.train_hf = h5py.File(data_folder + '/train36.hdf5', 'r')\n",
    "        self.train_features = self.train_hf['image_features']\n",
    "        self.val_hf = h5py.File(data_folder + '/val36.hdf5', 'r')\n",
    "        self.val_features = self.val_hf['image_features']\n",
    "\n",
    "        # Load bottom up image features distribution\n",
    "        with open(os.path.join(data_folder, self.split + '_GENOME_DETS_' + data_name + '.json'), 'r') as j:\n",
    "            self.objdet = json.load(j)\n",
    "\n",
    "        with open(os.path.join(data_folder, self.split + '_TOPIC_CLASS.json'), 'r') as j:\n",
    "            self.topic = json.load(j)\n",
    "            \n",
    "        self.dataset_size = len(self.topic)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # The Nth caption corresponds to the (N // captions_per_image)th image\n",
    "        objdet = self.objdet[i]\n",
    "        \n",
    "        # Load bottom up image features\n",
    "        if objdet[0] == \"v\":\n",
    "            img = torch.FloatTensor(self.val_features[objdet[1]])\n",
    "        else:\n",
    "            img = torch.FloatTensor(self.train_features[objdet[1]])\n",
    "            \n",
    "        topic = torch.LongTensor([self.topic[i]])\n",
    "        \n",
    "        return img,topic\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dataset_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, out_dim = 50, features_dim=2048, dropout=0.3):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc = nn.Linear(2048, 50)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(features_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, out_dim),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0) # one batch\n",
    "        x = x.mean(1)  # (batch_size, num_pixels, encoder_dim)\n",
    "        x = self.linear(self.dropout(x))\n",
    "        \n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "\n",
    "data_folder = '/home/why/image-captioning-bottom-up-top-down/other_dataset'\n",
    "data_name = 'coco_5_cap_per_img_5_min_word_freq'\n",
    "\n",
    "# Training settings\n",
    "batch_size = 128\n",
    "workers = 1\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    CaptionDataset(data_folder ,data_name,'TRAIN'),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    CaptionDataset(data_folder ,data_name, 'VAL'),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
    "\n",
    "def train(epoch):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        target = target.squeeze()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss))\n",
    "\n",
    "\n",
    "def test():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx,(data, target) in enumerate(test_loader):\n",
    "        batch_size = data.size(0)\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        data = Variable(data,volatile = True)\n",
    "        target = Variable(target,volatile = True)\n",
    "        #target = target.squeeze()\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        #loss += F.nll_loss(output, target.squeeze(),size_average=False)\n",
    "        # get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        #correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        correct += pred.eq(target).sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/why/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/113287 (0%)]\tLoss: 3.904691\n",
      "Train Epoch: 1 [1280/113287 (1%)]\tLoss: 3.891490\n",
      "Train Epoch: 1 [2560/113287 (2%)]\tLoss: 3.919845\n",
      "Train Epoch: 1 [3840/113287 (3%)]\tLoss: 3.900365\n",
      "Train Epoch: 1 [5120/113287 (5%)]\tLoss: 3.865664\n",
      "Train Epoch: 1 [6400/113287 (6%)]\tLoss: 3.863529\n",
      "Train Epoch: 1 [7680/113287 (7%)]\tLoss: 3.852815\n",
      "Train Epoch: 1 [8960/113287 (8%)]\tLoss: 3.853329\n",
      "Train Epoch: 1 [10240/113287 (9%)]\tLoss: 3.849704\n",
      "Train Epoch: 1 [11520/113287 (10%)]\tLoss: 3.848873\n",
      "Train Epoch: 1 [12800/113287 (11%)]\tLoss: 3.843569\n",
      "Train Epoch: 1 [14080/113287 (12%)]\tLoss: 3.822124\n",
      "Train Epoch: 1 [15360/113287 (14%)]\tLoss: 3.799979\n",
      "Train Epoch: 1 [16640/113287 (15%)]\tLoss: 3.812196\n",
      "Train Epoch: 1 [17920/113287 (16%)]\tLoss: 3.775379\n",
      "Train Epoch: 1 [19200/113287 (17%)]\tLoss: 3.771463\n",
      "Train Epoch: 1 [20480/113287 (18%)]\tLoss: 3.784264\n",
      "Train Epoch: 1 [21760/113287 (19%)]\tLoss: 3.765289\n",
      "Train Epoch: 1 [23040/113287 (20%)]\tLoss: 3.787389\n",
      "Train Epoch: 1 [24320/113287 (21%)]\tLoss: 3.744679\n",
      "Train Epoch: 1 [25600/113287 (23%)]\tLoss: 3.725713\n",
      "Train Epoch: 1 [26880/113287 (24%)]\tLoss: 3.740235\n",
      "Train Epoch: 1 [28160/113287 (25%)]\tLoss: 3.710414\n",
      "Train Epoch: 1 [29440/113287 (26%)]\tLoss: 3.744832\n",
      "Train Epoch: 1 [30720/113287 (27%)]\tLoss: 3.747530\n",
      "Train Epoch: 1 [32000/113287 (28%)]\tLoss: 3.687883\n",
      "Train Epoch: 1 [33280/113287 (29%)]\tLoss: 3.710105\n",
      "Train Epoch: 1 [34560/113287 (30%)]\tLoss: 3.704626\n",
      "Train Epoch: 1 [35840/113287 (32%)]\tLoss: 3.567845\n",
      "Train Epoch: 1 [37120/113287 (33%)]\tLoss: 3.602076\n",
      "Train Epoch: 1 [38400/113287 (34%)]\tLoss: 3.634146\n",
      "Train Epoch: 1 [39680/113287 (35%)]\tLoss: 3.680155\n",
      "Train Epoch: 1 [40960/113287 (36%)]\tLoss: 3.666761\n",
      "Train Epoch: 1 [42240/113287 (37%)]\tLoss: 3.637512\n",
      "Train Epoch: 1 [43520/113287 (38%)]\tLoss: 3.637473\n",
      "Train Epoch: 1 [44800/113287 (40%)]\tLoss: 3.571251\n",
      "Train Epoch: 1 [46080/113287 (41%)]\tLoss: 3.582712\n",
      "Train Epoch: 1 [47360/113287 (42%)]\tLoss: 3.647056\n",
      "Train Epoch: 1 [48640/113287 (43%)]\tLoss: 3.607977\n",
      "Train Epoch: 1 [49920/113287 (44%)]\tLoss: 3.540677\n",
      "Train Epoch: 1 [51200/113287 (45%)]\tLoss: 3.551043\n",
      "Train Epoch: 1 [52480/113287 (46%)]\tLoss: 3.474662\n",
      "Train Epoch: 1 [53760/113287 (47%)]\tLoss: 3.601958\n",
      "Train Epoch: 1 [55040/113287 (49%)]\tLoss: 3.541479\n",
      "Train Epoch: 1 [56320/113287 (50%)]\tLoss: 3.522580\n",
      "Train Epoch: 1 [57600/113287 (51%)]\tLoss: 3.454229\n",
      "Train Epoch: 1 [58880/113287 (52%)]\tLoss: 3.543396\n",
      "Train Epoch: 1 [60160/113287 (53%)]\tLoss: 3.546565\n",
      "Train Epoch: 1 [61440/113287 (54%)]\tLoss: 3.549042\n",
      "Train Epoch: 1 [62720/113287 (55%)]\tLoss: 3.526397\n",
      "Train Epoch: 1 [64000/113287 (56%)]\tLoss: 3.498222\n",
      "Train Epoch: 1 [65280/113287 (58%)]\tLoss: 3.447520\n",
      "Train Epoch: 1 [66560/113287 (59%)]\tLoss: 3.446798\n",
      "Train Epoch: 1 [67840/113287 (60%)]\tLoss: 3.413037\n",
      "Train Epoch: 1 [69120/113287 (61%)]\tLoss: 3.378670\n",
      "Train Epoch: 1 [70400/113287 (62%)]\tLoss: 3.373075\n",
      "Train Epoch: 1 [71680/113287 (63%)]\tLoss: 3.467700\n",
      "Train Epoch: 1 [72960/113287 (64%)]\tLoss: 3.381316\n",
      "Train Epoch: 1 [74240/113287 (65%)]\tLoss: 3.204133\n",
      "Train Epoch: 1 [75520/113287 (67%)]\tLoss: 3.351578\n",
      "Train Epoch: 1 [76800/113287 (68%)]\tLoss: 3.187479\n",
      "Train Epoch: 1 [78080/113287 (69%)]\tLoss: 3.308870\n",
      "Train Epoch: 1 [79360/113287 (70%)]\tLoss: 3.326527\n",
      "Train Epoch: 1 [80640/113287 (71%)]\tLoss: 3.305784\n",
      "Train Epoch: 1 [81920/113287 (72%)]\tLoss: 3.260664\n",
      "Train Epoch: 1 [83200/113287 (73%)]\tLoss: 3.194161\n",
      "Train Epoch: 1 [84480/113287 (74%)]\tLoss: 3.253487\n",
      "Train Epoch: 1 [85760/113287 (76%)]\tLoss: 3.164703\n",
      "Train Epoch: 1 [87040/113287 (77%)]\tLoss: 3.337485\n",
      "Train Epoch: 1 [88320/113287 (78%)]\tLoss: 3.118365\n",
      "Train Epoch: 1 [89600/113287 (79%)]\tLoss: 3.213514\n",
      "Train Epoch: 1 [90880/113287 (80%)]\tLoss: 3.181627\n",
      "Train Epoch: 1 [92160/113287 (81%)]\tLoss: 3.160839\n",
      "Train Epoch: 1 [93440/113287 (82%)]\tLoss: 3.093420\n",
      "Train Epoch: 1 [94720/113287 (84%)]\tLoss: 3.082235\n",
      "Train Epoch: 1 [96000/113287 (85%)]\tLoss: 3.178651\n",
      "Train Epoch: 1 [97280/113287 (86%)]\tLoss: 3.028011\n",
      "Train Epoch: 1 [98560/113287 (87%)]\tLoss: 3.075900\n",
      "Train Epoch: 1 [99840/113287 (88%)]\tLoss: 2.888046\n",
      "Train Epoch: 1 [101120/113287 (89%)]\tLoss: 3.023234\n",
      "Train Epoch: 1 [102400/113287 (90%)]\tLoss: 2.896028\n",
      "Train Epoch: 1 [103680/113287 (91%)]\tLoss: 3.155648\n",
      "Train Epoch: 1 [104960/113287 (93%)]\tLoss: 2.946754\n",
      "Train Epoch: 1 [106240/113287 (94%)]\tLoss: 2.946640\n",
      "Train Epoch: 1 [107520/113287 (95%)]\tLoss: 2.804421\n",
      "Train Epoch: 1 [108800/113287 (96%)]\tLoss: 2.885863\n",
      "Train Epoch: 1 [110080/113287 (97%)]\tLoss: 2.752662\n",
      "Train Epoch: 1 [111360/113287 (98%)]\tLoss: 2.920204\n",
      "Train Epoch: 1 [112640/113287 (99%)]\tLoss: 2.664913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/why/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/why/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 1975/5000 (39%)\n",
      "\n",
      "Train Epoch: 2 [0/113287 (0%)]\tLoss: 2.815035\n",
      "Train Epoch: 2 [1280/113287 (1%)]\tLoss: 2.872782\n",
      "Train Epoch: 2 [2560/113287 (2%)]\tLoss: 2.681639\n",
      "Train Epoch: 2 [3840/113287 (3%)]\tLoss: 2.781986\n",
      "Train Epoch: 2 [5120/113287 (5%)]\tLoss: 2.642687\n",
      "Train Epoch: 2 [6400/113287 (6%)]\tLoss: 2.847109\n",
      "Train Epoch: 2 [7680/113287 (7%)]\tLoss: 2.717479\n",
      "Train Epoch: 2 [8960/113287 (8%)]\tLoss: 2.744192\n",
      "Train Epoch: 2 [10240/113287 (9%)]\tLoss: 2.672832\n",
      "Train Epoch: 2 [11520/113287 (10%)]\tLoss: 2.626578\n",
      "Train Epoch: 2 [12800/113287 (11%)]\tLoss: 2.498728\n",
      "Train Epoch: 2 [14080/113287 (12%)]\tLoss: 2.650059\n",
      "Train Epoch: 2 [15360/113287 (14%)]\tLoss: 2.519052\n",
      "Train Epoch: 2 [16640/113287 (15%)]\tLoss: 2.563042\n",
      "Train Epoch: 2 [17920/113287 (16%)]\tLoss: 2.580826\n",
      "Train Epoch: 2 [19200/113287 (17%)]\tLoss: 2.449224\n",
      "Train Epoch: 2 [20480/113287 (18%)]\tLoss: 2.593746\n",
      "Train Epoch: 2 [21760/113287 (19%)]\tLoss: 2.551198\n",
      "Train Epoch: 2 [23040/113287 (20%)]\tLoss: 2.533249\n",
      "Train Epoch: 2 [24320/113287 (21%)]\tLoss: 2.636341\n",
      "Train Epoch: 2 [25600/113287 (23%)]\tLoss: 2.713639\n",
      "Train Epoch: 2 [26880/113287 (24%)]\tLoss: 2.323117\n",
      "Train Epoch: 2 [28160/113287 (25%)]\tLoss: 2.494503\n",
      "Train Epoch: 2 [29440/113287 (26%)]\tLoss: 2.248953\n",
      "Train Epoch: 2 [30720/113287 (27%)]\tLoss: 2.648567\n",
      "Train Epoch: 2 [32000/113287 (28%)]\tLoss: 2.485756\n",
      "Train Epoch: 2 [33280/113287 (29%)]\tLoss: 2.397051\n",
      "Train Epoch: 2 [34560/113287 (30%)]\tLoss: 2.420198\n",
      "Train Epoch: 2 [35840/113287 (32%)]\tLoss: 2.288233\n",
      "Train Epoch: 2 [37120/113287 (33%)]\tLoss: 2.459649\n",
      "Train Epoch: 2 [38400/113287 (34%)]\tLoss: 2.304592\n",
      "Train Epoch: 2 [39680/113287 (35%)]\tLoss: 2.220327\n",
      "Train Epoch: 2 [40960/113287 (36%)]\tLoss: 2.477701\n",
      "Train Epoch: 2 [42240/113287 (37%)]\tLoss: 2.282044\n",
      "Train Epoch: 2 [43520/113287 (38%)]\tLoss: 2.456324\n",
      "Train Epoch: 2 [44800/113287 (40%)]\tLoss: 2.203008\n",
      "Train Epoch: 2 [46080/113287 (41%)]\tLoss: 2.142702\n",
      "Train Epoch: 2 [47360/113287 (42%)]\tLoss: 2.257231\n",
      "Train Epoch: 2 [48640/113287 (43%)]\tLoss: 2.121702\n",
      "Train Epoch: 2 [49920/113287 (44%)]\tLoss: 2.251911\n",
      "Train Epoch: 2 [51200/113287 (45%)]\tLoss: 2.170270\n",
      "Train Epoch: 2 [52480/113287 (46%)]\tLoss: 2.202294\n",
      "Train Epoch: 2 [53760/113287 (47%)]\tLoss: 2.081411\n",
      "Train Epoch: 2 [55040/113287 (49%)]\tLoss: 2.262148\n",
      "Train Epoch: 2 [56320/113287 (50%)]\tLoss: 2.180892\n",
      "Train Epoch: 2 [57600/113287 (51%)]\tLoss: 2.178246\n",
      "Train Epoch: 2 [58880/113287 (52%)]\tLoss: 1.903195\n",
      "Train Epoch: 2 [60160/113287 (53%)]\tLoss: 2.045380\n",
      "Train Epoch: 2 [61440/113287 (54%)]\tLoss: 2.225280\n",
      "Train Epoch: 2 [62720/113287 (55%)]\tLoss: 2.055051\n",
      "Train Epoch: 2 [64000/113287 (56%)]\tLoss: 2.010412\n",
      "Train Epoch: 2 [65280/113287 (58%)]\tLoss: 1.945708\n",
      "Train Epoch: 2 [66560/113287 (59%)]\tLoss: 2.074710\n",
      "Train Epoch: 2 [67840/113287 (60%)]\tLoss: 1.867777\n",
      "Train Epoch: 2 [69120/113287 (61%)]\tLoss: 2.024866\n",
      "Train Epoch: 2 [70400/113287 (62%)]\tLoss: 1.954134\n",
      "Train Epoch: 2 [71680/113287 (63%)]\tLoss: 2.109165\n",
      "Train Epoch: 2 [72960/113287 (64%)]\tLoss: 2.020881\n",
      "Train Epoch: 2 [74240/113287 (65%)]\tLoss: 1.963657\n",
      "Train Epoch: 2 [75520/113287 (67%)]\tLoss: 2.043738\n",
      "Train Epoch: 2 [76800/113287 (68%)]\tLoss: 2.002489\n",
      "Train Epoch: 2 [78080/113287 (69%)]\tLoss: 1.958502\n",
      "Train Epoch: 2 [79360/113287 (70%)]\tLoss: 2.259144\n",
      "Train Epoch: 2 [80640/113287 (71%)]\tLoss: 1.974885\n",
      "Train Epoch: 2 [81920/113287 (72%)]\tLoss: 2.044993\n",
      "Train Epoch: 2 [83200/113287 (73%)]\tLoss: 2.003577\n",
      "Train Epoch: 2 [84480/113287 (74%)]\tLoss: 1.810330\n",
      "Train Epoch: 2 [85760/113287 (76%)]\tLoss: 1.968332\n",
      "Train Epoch: 2 [87040/113287 (77%)]\tLoss: 1.918513\n",
      "Train Epoch: 2 [88320/113287 (78%)]\tLoss: 1.900582\n",
      "Train Epoch: 2 [89600/113287 (79%)]\tLoss: 1.930590\n",
      "Train Epoch: 2 [90880/113287 (80%)]\tLoss: 1.850577\n",
      "Train Epoch: 2 [92160/113287 (81%)]\tLoss: 1.847308\n",
      "Train Epoch: 2 [93440/113287 (82%)]\tLoss: 1.754739\n",
      "Train Epoch: 2 [94720/113287 (84%)]\tLoss: 2.053608\n",
      "Train Epoch: 2 [96000/113287 (85%)]\tLoss: 1.933768\n",
      "Train Epoch: 2 [97280/113287 (86%)]\tLoss: 2.045403\n",
      "Train Epoch: 2 [98560/113287 (87%)]\tLoss: 2.232712\n",
      "Train Epoch: 2 [99840/113287 (88%)]\tLoss: 2.010440\n",
      "Train Epoch: 2 [101120/113287 (89%)]\tLoss: 1.812453\n",
      "Train Epoch: 2 [102400/113287 (90%)]\tLoss: 1.861839\n",
      "Train Epoch: 2 [103680/113287 (91%)]\tLoss: 1.955966\n",
      "Train Epoch: 2 [104960/113287 (93%)]\tLoss: 1.859750\n",
      "Train Epoch: 2 [106240/113287 (94%)]\tLoss: 1.844015\n",
      "Train Epoch: 2 [107520/113287 (95%)]\tLoss: 1.891753\n",
      "Train Epoch: 2 [108800/113287 (96%)]\tLoss: 1.845375\n",
      "Train Epoch: 2 [110080/113287 (97%)]\tLoss: 1.820777\n",
      "Train Epoch: 2 [111360/113287 (98%)]\tLoss: 1.784371\n",
      "Train Epoch: 2 [112640/113287 (99%)]\tLoss: 1.791930\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 2903/5000 (58%)\n",
      "\n",
      "Train Epoch: 3 [0/113287 (0%)]\tLoss: 1.777216\n",
      "Train Epoch: 3 [1280/113287 (1%)]\tLoss: 1.672612\n",
      "Train Epoch: 3 [2560/113287 (2%)]\tLoss: 1.870975\n",
      "Train Epoch: 3 [3840/113287 (3%)]\tLoss: 1.893342\n",
      "Train Epoch: 3 [5120/113287 (5%)]\tLoss: 1.909974\n",
      "Train Epoch: 3 [6400/113287 (6%)]\tLoss: 1.776410\n",
      "Train Epoch: 3 [7680/113287 (7%)]\tLoss: 1.647373\n",
      "Train Epoch: 3 [8960/113287 (8%)]\tLoss: 1.888039\n",
      "Train Epoch: 3 [10240/113287 (9%)]\tLoss: 1.714084\n",
      "Train Epoch: 3 [11520/113287 (10%)]\tLoss: 1.713404\n",
      "Train Epoch: 3 [12800/113287 (11%)]\tLoss: 1.675194\n",
      "Train Epoch: 3 [14080/113287 (12%)]\tLoss: 1.696222\n",
      "Train Epoch: 3 [15360/113287 (14%)]\tLoss: 1.646344\n",
      "Train Epoch: 3 [16640/113287 (15%)]\tLoss: 1.625950\n",
      "Train Epoch: 3 [17920/113287 (16%)]\tLoss: 1.735990\n",
      "Train Epoch: 3 [19200/113287 (17%)]\tLoss: 1.597296\n",
      "Train Epoch: 3 [20480/113287 (18%)]\tLoss: 1.857536\n",
      "Train Epoch: 3 [21760/113287 (19%)]\tLoss: 1.656483\n",
      "Train Epoch: 3 [23040/113287 (20%)]\tLoss: 1.671331\n",
      "Train Epoch: 3 [24320/113287 (21%)]\tLoss: 1.679604\n",
      "Train Epoch: 3 [25600/113287 (23%)]\tLoss: 1.629839\n",
      "Train Epoch: 3 [26880/113287 (24%)]\tLoss: 1.568306\n",
      "Train Epoch: 3 [28160/113287 (25%)]\tLoss: 1.758887\n",
      "Train Epoch: 3 [29440/113287 (26%)]\tLoss: 1.572744\n",
      "Train Epoch: 3 [30720/113287 (27%)]\tLoss: 1.471093\n",
      "Train Epoch: 3 [32000/113287 (28%)]\tLoss: 1.739044\n",
      "Train Epoch: 3 [33280/113287 (29%)]\tLoss: 1.636943\n",
      "Train Epoch: 3 [34560/113287 (30%)]\tLoss: 1.625254\n",
      "Train Epoch: 3 [35840/113287 (32%)]\tLoss: 1.520843\n",
      "Train Epoch: 3 [37120/113287 (33%)]\tLoss: 1.482558\n",
      "Train Epoch: 3 [38400/113287 (34%)]\tLoss: 1.727187\n",
      "Train Epoch: 3 [39680/113287 (35%)]\tLoss: 1.553846\n",
      "Train Epoch: 3 [40960/113287 (36%)]\tLoss: 1.548079\n",
      "Train Epoch: 3 [42240/113287 (37%)]\tLoss: 1.425958\n",
      "Train Epoch: 3 [43520/113287 (38%)]\tLoss: 1.534046\n",
      "Train Epoch: 3 [44800/113287 (40%)]\tLoss: 1.445602\n",
      "Train Epoch: 3 [46080/113287 (41%)]\tLoss: 1.766806\n",
      "Train Epoch: 3 [47360/113287 (42%)]\tLoss: 1.455602\n",
      "Train Epoch: 3 [48640/113287 (43%)]\tLoss: 1.423858\n",
      "Train Epoch: 3 [49920/113287 (44%)]\tLoss: 1.576154\n",
      "Train Epoch: 3 [51200/113287 (45%)]\tLoss: 1.655813\n",
      "Train Epoch: 3 [52480/113287 (46%)]\tLoss: 1.752909\n",
      "Train Epoch: 3 [53760/113287 (47%)]\tLoss: 1.519763\n",
      "Train Epoch: 3 [55040/113287 (49%)]\tLoss: 1.514892\n",
      "Train Epoch: 3 [56320/113287 (50%)]\tLoss: 1.419073\n",
      "Train Epoch: 3 [57600/113287 (51%)]\tLoss: 1.371959\n",
      "Train Epoch: 3 [58880/113287 (52%)]\tLoss: 1.664183\n",
      "Train Epoch: 3 [60160/113287 (53%)]\tLoss: 1.501420\n",
      "Train Epoch: 3 [61440/113287 (54%)]\tLoss: 1.590470\n",
      "Train Epoch: 3 [62720/113287 (55%)]\tLoss: 1.719954\n",
      "Train Epoch: 3 [64000/113287 (56%)]\tLoss: 1.694920\n",
      "Train Epoch: 3 [65280/113287 (58%)]\tLoss: 1.718972\n",
      "Train Epoch: 3 [66560/113287 (59%)]\tLoss: 1.669588\n",
      "Train Epoch: 3 [67840/113287 (60%)]\tLoss: 1.604219\n",
      "Train Epoch: 3 [69120/113287 (61%)]\tLoss: 1.402797\n",
      "Train Epoch: 3 [70400/113287 (62%)]\tLoss: 1.545921\n",
      "Train Epoch: 3 [71680/113287 (63%)]\tLoss: 1.775944\n",
      "Train Epoch: 3 [72960/113287 (64%)]\tLoss: 1.676461\n",
      "Train Epoch: 3 [74240/113287 (65%)]\tLoss: 1.681542\n",
      "Train Epoch: 3 [75520/113287 (67%)]\tLoss: 1.499356\n",
      "Train Epoch: 3 [76800/113287 (68%)]\tLoss: 1.373485\n",
      "Train Epoch: 3 [78080/113287 (69%)]\tLoss: 1.454417\n",
      "Train Epoch: 3 [79360/113287 (70%)]\tLoss: 1.411201\n",
      "Train Epoch: 3 [80640/113287 (71%)]\tLoss: 1.340445\n",
      "Train Epoch: 3 [81920/113287 (72%)]\tLoss: 1.324258\n",
      "Train Epoch: 3 [83200/113287 (73%)]\tLoss: 1.598210\n",
      "Train Epoch: 3 [84480/113287 (74%)]\tLoss: 1.525868\n",
      "Train Epoch: 3 [85760/113287 (76%)]\tLoss: 1.408707\n",
      "Train Epoch: 3 [87040/113287 (77%)]\tLoss: 1.429342\n",
      "Train Epoch: 3 [88320/113287 (78%)]\tLoss: 1.680148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [89600/113287 (79%)]\tLoss: 1.644827\n",
      "Train Epoch: 3 [90880/113287 (80%)]\tLoss: 1.452450\n",
      "Train Epoch: 3 [92160/113287 (81%)]\tLoss: 1.367846\n",
      "Train Epoch: 3 [93440/113287 (82%)]\tLoss: 1.543216\n",
      "Train Epoch: 3 [94720/113287 (84%)]\tLoss: 1.560789\n",
      "Train Epoch: 3 [96000/113287 (85%)]\tLoss: 1.361784\n",
      "Train Epoch: 3 [97280/113287 (86%)]\tLoss: 1.617597\n",
      "Train Epoch: 3 [98560/113287 (87%)]\tLoss: 1.575597\n",
      "Train Epoch: 3 [99840/113287 (88%)]\tLoss: 1.529496\n",
      "Train Epoch: 3 [101120/113287 (89%)]\tLoss: 1.560580\n",
      "Train Epoch: 3 [102400/113287 (90%)]\tLoss: 1.439574\n",
      "Train Epoch: 3 [103680/113287 (91%)]\tLoss: 1.610497\n",
      "Train Epoch: 3 [104960/113287 (93%)]\tLoss: 1.324591\n",
      "Train Epoch: 3 [106240/113287 (94%)]\tLoss: 1.388606\n",
      "Train Epoch: 3 [107520/113287 (95%)]\tLoss: 1.590441\n",
      "Train Epoch: 3 [108800/113287 (96%)]\tLoss: 1.500149\n",
      "Train Epoch: 3 [110080/113287 (97%)]\tLoss: 1.550954\n",
      "Train Epoch: 3 [111360/113287 (98%)]\tLoss: 1.430126\n",
      "Train Epoch: 3 [112640/113287 (99%)]\tLoss: 1.630909\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3093/5000 (61%)\n",
      "\n",
      "Train Epoch: 4 [0/113287 (0%)]\tLoss: 1.492408\n",
      "Train Epoch: 4 [1280/113287 (1%)]\tLoss: 1.308506\n",
      "Train Epoch: 4 [2560/113287 (2%)]\tLoss: 1.512784\n",
      "Train Epoch: 4 [3840/113287 (3%)]\tLoss: 1.383696\n",
      "Train Epoch: 4 [5120/113287 (5%)]\tLoss: 1.444050\n",
      "Train Epoch: 4 [6400/113287 (6%)]\tLoss: 1.441278\n",
      "Train Epoch: 4 [7680/113287 (7%)]\tLoss: 1.443708\n",
      "Train Epoch: 4 [8960/113287 (8%)]\tLoss: 1.501810\n",
      "Train Epoch: 4 [10240/113287 (9%)]\tLoss: 1.419098\n",
      "Train Epoch: 4 [11520/113287 (10%)]\tLoss: 1.465872\n",
      "Train Epoch: 4 [12800/113287 (11%)]\tLoss: 1.568532\n",
      "Train Epoch: 4 [14080/113287 (12%)]\tLoss: 1.508511\n",
      "Train Epoch: 4 [15360/113287 (14%)]\tLoss: 1.278527\n",
      "Train Epoch: 4 [16640/113287 (15%)]\tLoss: 1.601797\n",
      "Train Epoch: 4 [17920/113287 (16%)]\tLoss: 1.378633\n",
      "Train Epoch: 4 [19200/113287 (17%)]\tLoss: 1.366571\n",
      "Train Epoch: 4 [20480/113287 (18%)]\tLoss: 1.262714\n",
      "Train Epoch: 4 [21760/113287 (19%)]\tLoss: 1.351053\n",
      "Train Epoch: 4 [23040/113287 (20%)]\tLoss: 1.376431\n",
      "Train Epoch: 4 [24320/113287 (21%)]\tLoss: 1.300536\n",
      "Train Epoch: 4 [25600/113287 (23%)]\tLoss: 1.499497\n",
      "Train Epoch: 4 [26880/113287 (24%)]\tLoss: 1.389756\n",
      "Train Epoch: 4 [28160/113287 (25%)]\tLoss: 1.421582\n",
      "Train Epoch: 4 [29440/113287 (26%)]\tLoss: 1.679100\n",
      "Train Epoch: 4 [30720/113287 (27%)]\tLoss: 1.424112\n",
      "Train Epoch: 4 [32000/113287 (28%)]\tLoss: 1.433942\n",
      "Train Epoch: 4 [33280/113287 (29%)]\tLoss: 1.525447\n",
      "Train Epoch: 4 [34560/113287 (30%)]\tLoss: 1.482927\n",
      "Train Epoch: 4 [35840/113287 (32%)]\tLoss: 1.532638\n",
      "Train Epoch: 4 [37120/113287 (33%)]\tLoss: 1.478849\n",
      "Train Epoch: 4 [38400/113287 (34%)]\tLoss: 1.611546\n",
      "Train Epoch: 4 [39680/113287 (35%)]\tLoss: 1.441675\n",
      "Train Epoch: 4 [40960/113287 (36%)]\tLoss: 1.277599\n",
      "Train Epoch: 4 [42240/113287 (37%)]\tLoss: 1.646525\n",
      "Train Epoch: 4 [43520/113287 (38%)]\tLoss: 1.367868\n",
      "Train Epoch: 4 [44800/113287 (40%)]\tLoss: 1.279805\n",
      "Train Epoch: 4 [46080/113287 (41%)]\tLoss: 1.191651\n",
      "Train Epoch: 4 [47360/113287 (42%)]\tLoss: 1.287257\n",
      "Train Epoch: 4 [48640/113287 (43%)]\tLoss: 1.335607\n",
      "Train Epoch: 4 [49920/113287 (44%)]\tLoss: 1.346215\n",
      "Train Epoch: 4 [51200/113287 (45%)]\tLoss: 1.187380\n",
      "Train Epoch: 4 [52480/113287 (46%)]\tLoss: 1.423532\n",
      "Train Epoch: 4 [53760/113287 (47%)]\tLoss: 1.456782\n",
      "Train Epoch: 4 [55040/113287 (49%)]\tLoss: 1.362535\n",
      "Train Epoch: 4 [56320/113287 (50%)]\tLoss: 1.359756\n",
      "Train Epoch: 4 [57600/113287 (51%)]\tLoss: 1.367362\n",
      "Train Epoch: 4 [58880/113287 (52%)]\tLoss: 1.457104\n",
      "Train Epoch: 4 [60160/113287 (53%)]\tLoss: 1.433483\n",
      "Train Epoch: 4 [61440/113287 (54%)]\tLoss: 1.341627\n",
      "Train Epoch: 4 [62720/113287 (55%)]\tLoss: 1.131653\n",
      "Train Epoch: 4 [64000/113287 (56%)]\tLoss: 1.157244\n",
      "Train Epoch: 4 [65280/113287 (58%)]\tLoss: 1.349420\n",
      "Train Epoch: 4 [66560/113287 (59%)]\tLoss: 1.298657\n",
      "Train Epoch: 4 [67840/113287 (60%)]\tLoss: 1.278341\n",
      "Train Epoch: 4 [69120/113287 (61%)]\tLoss: 1.225887\n",
      "Train Epoch: 4 [70400/113287 (62%)]\tLoss: 1.435031\n",
      "Train Epoch: 4 [71680/113287 (63%)]\tLoss: 1.505378\n",
      "Train Epoch: 4 [72960/113287 (64%)]\tLoss: 1.250864\n",
      "Train Epoch: 4 [74240/113287 (65%)]\tLoss: 1.282549\n",
      "Train Epoch: 4 [75520/113287 (67%)]\tLoss: 1.150742\n",
      "Train Epoch: 4 [76800/113287 (68%)]\tLoss: 1.382827\n",
      "Train Epoch: 4 [78080/113287 (69%)]\tLoss: 1.294743\n",
      "Train Epoch: 4 [79360/113287 (70%)]\tLoss: 1.371403\n",
      "Train Epoch: 4 [80640/113287 (71%)]\tLoss: 1.072439\n",
      "Train Epoch: 4 [81920/113287 (72%)]\tLoss: 1.335061\n",
      "Train Epoch: 4 [83200/113287 (73%)]\tLoss: 1.360313\n",
      "Train Epoch: 4 [84480/113287 (74%)]\tLoss: 1.596662\n",
      "Train Epoch: 4 [85760/113287 (76%)]\tLoss: 1.508548\n",
      "Train Epoch: 4 [87040/113287 (77%)]\tLoss: 1.268571\n",
      "Train Epoch: 4 [88320/113287 (78%)]\tLoss: 1.334967\n",
      "Train Epoch: 4 [89600/113287 (79%)]\tLoss: 1.644648\n",
      "Train Epoch: 4 [90880/113287 (80%)]\tLoss: 1.323938\n",
      "Train Epoch: 4 [92160/113287 (81%)]\tLoss: 1.164139\n",
      "Train Epoch: 4 [93440/113287 (82%)]\tLoss: 1.182116\n",
      "Train Epoch: 4 [94720/113287 (84%)]\tLoss: 1.277558\n",
      "Train Epoch: 4 [96000/113287 (85%)]\tLoss: 1.205478\n",
      "Train Epoch: 4 [97280/113287 (86%)]\tLoss: 1.396029\n",
      "Train Epoch: 4 [98560/113287 (87%)]\tLoss: 1.408215\n",
      "Train Epoch: 4 [99840/113287 (88%)]\tLoss: 1.115961\n",
      "Train Epoch: 4 [101120/113287 (89%)]\tLoss: 1.251047\n",
      "Train Epoch: 4 [102400/113287 (90%)]\tLoss: 1.248857\n",
      "Train Epoch: 4 [103680/113287 (91%)]\tLoss: 1.363527\n",
      "Train Epoch: 4 [104960/113287 (93%)]\tLoss: 1.355071\n",
      "Train Epoch: 4 [106240/113287 (94%)]\tLoss: 1.250508\n",
      "Train Epoch: 4 [107520/113287 (95%)]\tLoss: 1.570192\n",
      "Train Epoch: 4 [108800/113287 (96%)]\tLoss: 1.360516\n",
      "Train Epoch: 4 [110080/113287 (97%)]\tLoss: 1.266285\n",
      "Train Epoch: 4 [111360/113287 (98%)]\tLoss: 1.451097\n",
      "Train Epoch: 4 [112640/113287 (99%)]\tLoss: 1.541160\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3215/5000 (64%)\n",
      "\n",
      "Train Epoch: 5 [0/113287 (0%)]\tLoss: 1.455052\n",
      "Train Epoch: 5 [1280/113287 (1%)]\tLoss: 1.310048\n",
      "Train Epoch: 5 [2560/113287 (2%)]\tLoss: 1.286267\n",
      "Train Epoch: 5 [3840/113287 (3%)]\tLoss: 1.340648\n",
      "Train Epoch: 5 [5120/113287 (5%)]\tLoss: 1.238173\n",
      "Train Epoch: 5 [6400/113287 (6%)]\tLoss: 1.399941\n",
      "Train Epoch: 5 [7680/113287 (7%)]\tLoss: 1.185993\n",
      "Train Epoch: 5 [8960/113287 (8%)]\tLoss: 1.261531\n",
      "Train Epoch: 5 [10240/113287 (9%)]\tLoss: 1.476295\n",
      "Train Epoch: 5 [11520/113287 (10%)]\tLoss: 1.154215\n",
      "Train Epoch: 5 [12800/113287 (11%)]\tLoss: 1.315566\n",
      "Train Epoch: 5 [14080/113287 (12%)]\tLoss: 1.205165\n",
      "Train Epoch: 5 [15360/113287 (14%)]\tLoss: 1.214555\n",
      "Train Epoch: 5 [16640/113287 (15%)]\tLoss: 1.119917\n",
      "Train Epoch: 5 [17920/113287 (16%)]\tLoss: 1.335520\n",
      "Train Epoch: 5 [19200/113287 (17%)]\tLoss: 1.392292\n",
      "Train Epoch: 5 [20480/113287 (18%)]\tLoss: 1.208634\n",
      "Train Epoch: 5 [21760/113287 (19%)]\tLoss: 1.500850\n",
      "Train Epoch: 5 [23040/113287 (20%)]\tLoss: 1.568807\n",
      "Train Epoch: 5 [24320/113287 (21%)]\tLoss: 1.394817\n",
      "Train Epoch: 5 [25600/113287 (23%)]\tLoss: 1.300777\n",
      "Train Epoch: 5 [26880/113287 (24%)]\tLoss: 1.346202\n",
      "Train Epoch: 5 [28160/113287 (25%)]\tLoss: 1.394225\n",
      "Train Epoch: 5 [29440/113287 (26%)]\tLoss: 1.419303\n",
      "Train Epoch: 5 [30720/113287 (27%)]\tLoss: 1.436256\n",
      "Train Epoch: 5 [32000/113287 (28%)]\tLoss: 1.292999\n",
      "Train Epoch: 5 [33280/113287 (29%)]\tLoss: 1.272419\n",
      "Train Epoch: 5 [34560/113287 (30%)]\tLoss: 1.150557\n",
      "Train Epoch: 5 [35840/113287 (32%)]\tLoss: 1.410909\n",
      "Train Epoch: 5 [37120/113287 (33%)]\tLoss: 1.250716\n",
      "Train Epoch: 5 [38400/113287 (34%)]\tLoss: 1.502749\n",
      "Train Epoch: 5 [39680/113287 (35%)]\tLoss: 1.132798\n",
      "Train Epoch: 5 [40960/113287 (36%)]\tLoss: 1.046153\n",
      "Train Epoch: 5 [42240/113287 (37%)]\tLoss: 1.415581\n",
      "Train Epoch: 5 [43520/113287 (38%)]\tLoss: 1.230394\n",
      "Train Epoch: 5 [44800/113287 (40%)]\tLoss: 1.254080\n",
      "Train Epoch: 5 [46080/113287 (41%)]\tLoss: 1.271871\n",
      "Train Epoch: 5 [47360/113287 (42%)]\tLoss: 1.434629\n",
      "Train Epoch: 5 [48640/113287 (43%)]\tLoss: 1.210650\n",
      "Train Epoch: 5 [49920/113287 (44%)]\tLoss: 1.273875\n",
      "Train Epoch: 5 [51200/113287 (45%)]\tLoss: 1.289274\n",
      "Train Epoch: 5 [52480/113287 (46%)]\tLoss: 1.366058\n",
      "Train Epoch: 5 [53760/113287 (47%)]\tLoss: 1.416024\n",
      "Train Epoch: 5 [55040/113287 (49%)]\tLoss: 1.416618\n",
      "Train Epoch: 5 [56320/113287 (50%)]\tLoss: 1.546700\n",
      "Train Epoch: 5 [57600/113287 (51%)]\tLoss: 1.290699\n",
      "Train Epoch: 5 [58880/113287 (52%)]\tLoss: 0.984700\n",
      "Train Epoch: 5 [60160/113287 (53%)]\tLoss: 1.301667\n",
      "Train Epoch: 5 [61440/113287 (54%)]\tLoss: 1.376269\n",
      "Train Epoch: 5 [62720/113287 (55%)]\tLoss: 1.290275\n",
      "Train Epoch: 5 [64000/113287 (56%)]\tLoss: 1.328456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [65280/113287 (58%)]\tLoss: 1.381940\n",
      "Train Epoch: 5 [66560/113287 (59%)]\tLoss: 1.336925\n",
      "Train Epoch: 5 [67840/113287 (60%)]\tLoss: 1.383606\n",
      "Train Epoch: 5 [69120/113287 (61%)]\tLoss: 1.095682\n",
      "Train Epoch: 5 [70400/113287 (62%)]\tLoss: 1.241034\n",
      "Train Epoch: 5 [71680/113287 (63%)]\tLoss: 1.197714\n",
      "Train Epoch: 5 [72960/113287 (64%)]\tLoss: 1.074889\n",
      "Train Epoch: 5 [74240/113287 (65%)]\tLoss: 1.107900\n",
      "Train Epoch: 5 [75520/113287 (67%)]\tLoss: 1.295192\n",
      "Train Epoch: 5 [76800/113287 (68%)]\tLoss: 1.356691\n",
      "Train Epoch: 5 [78080/113287 (69%)]\tLoss: 1.235426\n",
      "Train Epoch: 5 [79360/113287 (70%)]\tLoss: 1.159856\n",
      "Train Epoch: 5 [80640/113287 (71%)]\tLoss: 1.255378\n",
      "Train Epoch: 5 [81920/113287 (72%)]\tLoss: 1.150045\n",
      "Train Epoch: 5 [83200/113287 (73%)]\tLoss: 1.176483\n",
      "Train Epoch: 5 [84480/113287 (74%)]\tLoss: 1.291645\n",
      "Train Epoch: 5 [85760/113287 (76%)]\tLoss: 1.376676\n",
      "Train Epoch: 5 [87040/113287 (77%)]\tLoss: 1.193392\n",
      "Train Epoch: 5 [88320/113287 (78%)]\tLoss: 1.346783\n",
      "Train Epoch: 5 [89600/113287 (79%)]\tLoss: 1.034318\n",
      "Train Epoch: 5 [90880/113287 (80%)]\tLoss: 1.403671\n",
      "Train Epoch: 5 [92160/113287 (81%)]\tLoss: 1.552836\n",
      "Train Epoch: 5 [93440/113287 (82%)]\tLoss: 1.393481\n",
      "Train Epoch: 5 [94720/113287 (84%)]\tLoss: 1.377367\n",
      "Train Epoch: 5 [96000/113287 (85%)]\tLoss: 1.155780\n",
      "Train Epoch: 5 [97280/113287 (86%)]\tLoss: 1.031470\n",
      "Train Epoch: 5 [98560/113287 (87%)]\tLoss: 1.340737\n",
      "Train Epoch: 5 [99840/113287 (88%)]\tLoss: 1.216121\n",
      "Train Epoch: 5 [101120/113287 (89%)]\tLoss: 1.011718\n",
      "Train Epoch: 5 [102400/113287 (90%)]\tLoss: 1.401559\n",
      "Train Epoch: 5 [103680/113287 (91%)]\tLoss: 1.302448\n",
      "Train Epoch: 5 [104960/113287 (93%)]\tLoss: 1.179486\n",
      "Train Epoch: 5 [106240/113287 (94%)]\tLoss: 1.494001\n",
      "Train Epoch: 5 [107520/113287 (95%)]\tLoss: 1.216779\n",
      "Train Epoch: 5 [108800/113287 (96%)]\tLoss: 1.381548\n",
      "Train Epoch: 5 [110080/113287 (97%)]\tLoss: 1.249372\n",
      "Train Epoch: 5 [111360/113287 (98%)]\tLoss: 1.140787\n",
      "Train Epoch: 5 [112640/113287 (99%)]\tLoss: 1.259164\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3295/5000 (65%)\n",
      "\n",
      "Train Epoch: 6 [0/113287 (0%)]\tLoss: 1.211361\n",
      "Train Epoch: 6 [1280/113287 (1%)]\tLoss: 1.260106\n",
      "Train Epoch: 6 [2560/113287 (2%)]\tLoss: 1.174066\n",
      "Train Epoch: 6 [3840/113287 (3%)]\tLoss: 1.036457\n",
      "Train Epoch: 6 [5120/113287 (5%)]\tLoss: 1.307605\n",
      "Train Epoch: 6 [6400/113287 (6%)]\tLoss: 1.337315\n",
      "Train Epoch: 6 [7680/113287 (7%)]\tLoss: 1.450956\n",
      "Train Epoch: 6 [8960/113287 (8%)]\tLoss: 1.196991\n",
      "Train Epoch: 6 [10240/113287 (9%)]\tLoss: 1.416442\n",
      "Train Epoch: 6 [11520/113287 (10%)]\tLoss: 1.088825\n",
      "Train Epoch: 6 [12800/113287 (11%)]\tLoss: 1.168143\n",
      "Train Epoch: 6 [14080/113287 (12%)]\tLoss: 1.295065\n",
      "Train Epoch: 6 [15360/113287 (14%)]\tLoss: 1.376709\n",
      "Train Epoch: 6 [16640/113287 (15%)]\tLoss: 1.316310\n",
      "Train Epoch: 6 [17920/113287 (16%)]\tLoss: 1.274820\n",
      "Train Epoch: 6 [19200/113287 (17%)]\tLoss: 1.357106\n",
      "Train Epoch: 6 [20480/113287 (18%)]\tLoss: 1.269901\n",
      "Train Epoch: 6 [21760/113287 (19%)]\tLoss: 1.430216\n",
      "Train Epoch: 6 [23040/113287 (20%)]\tLoss: 1.278386\n",
      "Train Epoch: 6 [24320/113287 (21%)]\tLoss: 1.054925\n",
      "Train Epoch: 6 [25600/113287 (23%)]\tLoss: 1.317078\n",
      "Train Epoch: 6 [26880/113287 (24%)]\tLoss: 1.280219\n",
      "Train Epoch: 6 [28160/113287 (25%)]\tLoss: 1.303013\n",
      "Train Epoch: 6 [29440/113287 (26%)]\tLoss: 1.403793\n",
      "Train Epoch: 6 [30720/113287 (27%)]\tLoss: 1.152651\n",
      "Train Epoch: 6 [32000/113287 (28%)]\tLoss: 1.321671\n",
      "Train Epoch: 6 [33280/113287 (29%)]\tLoss: 1.234443\n",
      "Train Epoch: 6 [34560/113287 (30%)]\tLoss: 1.196250\n",
      "Train Epoch: 6 [35840/113287 (32%)]\tLoss: 1.404473\n",
      "Train Epoch: 6 [37120/113287 (33%)]\tLoss: 1.256254\n",
      "Train Epoch: 6 [38400/113287 (34%)]\tLoss: 0.951307\n",
      "Train Epoch: 6 [39680/113287 (35%)]\tLoss: 1.076840\n",
      "Train Epoch: 6 [40960/113287 (36%)]\tLoss: 1.145365\n",
      "Train Epoch: 6 [42240/113287 (37%)]\tLoss: 1.316048\n",
      "Train Epoch: 6 [43520/113287 (38%)]\tLoss: 1.212434\n",
      "Train Epoch: 6 [44800/113287 (40%)]\tLoss: 1.123798\n",
      "Train Epoch: 6 [46080/113287 (41%)]\tLoss: 1.247137\n",
      "Train Epoch: 6 [47360/113287 (42%)]\tLoss: 1.156284\n",
      "Train Epoch: 6 [48640/113287 (43%)]\tLoss: 1.178321\n",
      "Train Epoch: 6 [49920/113287 (44%)]\tLoss: 1.169327\n",
      "Train Epoch: 6 [51200/113287 (45%)]\tLoss: 1.256910\n",
      "Train Epoch: 6 [52480/113287 (46%)]\tLoss: 1.293721\n",
      "Train Epoch: 6 [53760/113287 (47%)]\tLoss: 1.123521\n",
      "Train Epoch: 6 [55040/113287 (49%)]\tLoss: 1.271085\n",
      "Train Epoch: 6 [56320/113287 (50%)]\tLoss: 1.339201\n",
      "Train Epoch: 6 [57600/113287 (51%)]\tLoss: 1.234179\n",
      "Train Epoch: 6 [58880/113287 (52%)]\tLoss: 1.423767\n",
      "Train Epoch: 6 [60160/113287 (53%)]\tLoss: 1.447157\n",
      "Train Epoch: 6 [61440/113287 (54%)]\tLoss: 1.026410\n",
      "Train Epoch: 6 [62720/113287 (55%)]\tLoss: 1.106286\n",
      "Train Epoch: 6 [64000/113287 (56%)]\tLoss: 1.208994\n",
      "Train Epoch: 6 [65280/113287 (58%)]\tLoss: 1.294648\n",
      "Train Epoch: 6 [66560/113287 (59%)]\tLoss: 1.493522\n",
      "Train Epoch: 6 [67840/113287 (60%)]\tLoss: 1.262585\n",
      "Train Epoch: 6 [69120/113287 (61%)]\tLoss: 1.235018\n",
      "Train Epoch: 6 [70400/113287 (62%)]\tLoss: 1.261578\n",
      "Train Epoch: 6 [71680/113287 (63%)]\tLoss: 1.120672\n",
      "Train Epoch: 6 [72960/113287 (64%)]\tLoss: 1.209215\n",
      "Train Epoch: 6 [74240/113287 (65%)]\tLoss: 0.994963\n",
      "Train Epoch: 6 [75520/113287 (67%)]\tLoss: 1.413325\n",
      "Train Epoch: 6 [76800/113287 (68%)]\tLoss: 1.214827\n",
      "Train Epoch: 6 [78080/113287 (69%)]\tLoss: 1.259386\n",
      "Train Epoch: 6 [79360/113287 (70%)]\tLoss: 1.209311\n",
      "Train Epoch: 6 [80640/113287 (71%)]\tLoss: 1.112589\n",
      "Train Epoch: 6 [81920/113287 (72%)]\tLoss: 1.237455\n",
      "Train Epoch: 6 [83200/113287 (73%)]\tLoss: 1.259815\n",
      "Train Epoch: 6 [84480/113287 (74%)]\tLoss: 1.171642\n",
      "Train Epoch: 6 [85760/113287 (76%)]\tLoss: 1.212256\n",
      "Train Epoch: 6 [87040/113287 (77%)]\tLoss: 1.115027\n",
      "Train Epoch: 6 [88320/113287 (78%)]\tLoss: 0.983204\n",
      "Train Epoch: 6 [89600/113287 (79%)]\tLoss: 1.188484\n",
      "Train Epoch: 6 [90880/113287 (80%)]\tLoss: 1.206142\n",
      "Train Epoch: 6 [92160/113287 (81%)]\tLoss: 1.090911\n",
      "Train Epoch: 6 [93440/113287 (82%)]\tLoss: 1.412441\n",
      "Train Epoch: 6 [94720/113287 (84%)]\tLoss: 1.181829\n",
      "Train Epoch: 6 [96000/113287 (85%)]\tLoss: 1.325379\n",
      "Train Epoch: 6 [97280/113287 (86%)]\tLoss: 1.324770\n",
      "Train Epoch: 6 [98560/113287 (87%)]\tLoss: 1.254887\n",
      "Train Epoch: 6 [99840/113287 (88%)]\tLoss: 1.230673\n",
      "Train Epoch: 6 [101120/113287 (89%)]\tLoss: 1.432402\n",
      "Train Epoch: 6 [102400/113287 (90%)]\tLoss: 1.573648\n",
      "Train Epoch: 6 [103680/113287 (91%)]\tLoss: 1.098476\n",
      "Train Epoch: 6 [104960/113287 (93%)]\tLoss: 1.141598\n",
      "Train Epoch: 6 [106240/113287 (94%)]\tLoss: 1.121173\n",
      "Train Epoch: 6 [107520/113287 (95%)]\tLoss: 1.367059\n",
      "Train Epoch: 6 [108800/113287 (96%)]\tLoss: 1.171022\n",
      "Train Epoch: 6 [110080/113287 (97%)]\tLoss: 1.254172\n",
      "Train Epoch: 6 [111360/113287 (98%)]\tLoss: 1.284346\n",
      "Train Epoch: 6 [112640/113287 (99%)]\tLoss: 1.196083\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3309/5000 (66%)\n",
      "\n",
      "Train Epoch: 7 [0/113287 (0%)]\tLoss: 1.013611\n",
      "Train Epoch: 7 [1280/113287 (1%)]\tLoss: 1.111009\n",
      "Train Epoch: 7 [2560/113287 (2%)]\tLoss: 1.239045\n",
      "Train Epoch: 7 [3840/113287 (3%)]\tLoss: 1.419501\n",
      "Train Epoch: 7 [5120/113287 (5%)]\tLoss: 1.193691\n",
      "Train Epoch: 7 [6400/113287 (6%)]\tLoss: 1.215260\n",
      "Train Epoch: 7 [7680/113287 (7%)]\tLoss: 1.178615\n",
      "Train Epoch: 7 [8960/113287 (8%)]\tLoss: 1.344989\n",
      "Train Epoch: 7 [10240/113287 (9%)]\tLoss: 1.385182\n",
      "Train Epoch: 7 [11520/113287 (10%)]\tLoss: 1.245005\n",
      "Train Epoch: 7 [12800/113287 (11%)]\tLoss: 1.235647\n",
      "Train Epoch: 7 [14080/113287 (12%)]\tLoss: 1.093119\n",
      "Train Epoch: 7 [15360/113287 (14%)]\tLoss: 1.121917\n",
      "Train Epoch: 7 [16640/113287 (15%)]\tLoss: 1.251871\n",
      "Train Epoch: 7 [17920/113287 (16%)]\tLoss: 1.196360\n",
      "Train Epoch: 7 [19200/113287 (17%)]\tLoss: 1.061662\n",
      "Train Epoch: 7 [20480/113287 (18%)]\tLoss: 1.055722\n",
      "Train Epoch: 7 [21760/113287 (19%)]\tLoss: 1.269815\n",
      "Train Epoch: 7 [23040/113287 (20%)]\tLoss: 1.145019\n",
      "Train Epoch: 7 [24320/113287 (21%)]\tLoss: 1.111836\n",
      "Train Epoch: 7 [25600/113287 (23%)]\tLoss: 1.056001\n",
      "Train Epoch: 7 [26880/113287 (24%)]\tLoss: 1.158304\n",
      "Train Epoch: 7 [28160/113287 (25%)]\tLoss: 1.209807\n",
      "Train Epoch: 7 [29440/113287 (26%)]\tLoss: 1.098031\n",
      "Train Epoch: 7 [30720/113287 (27%)]\tLoss: 0.987456\n",
      "Train Epoch: 7 [32000/113287 (28%)]\tLoss: 1.175395\n",
      "Train Epoch: 7 [33280/113287 (29%)]\tLoss: 1.105763\n",
      "Train Epoch: 7 [34560/113287 (30%)]\tLoss: 1.036868\n",
      "Train Epoch: 7 [35840/113287 (32%)]\tLoss: 1.131854\n",
      "Train Epoch: 7 [37120/113287 (33%)]\tLoss: 0.979621\n",
      "Train Epoch: 7 [38400/113287 (34%)]\tLoss: 1.169769\n",
      "Train Epoch: 7 [39680/113287 (35%)]\tLoss: 1.282633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [40960/113287 (36%)]\tLoss: 1.135990\n",
      "Train Epoch: 7 [42240/113287 (37%)]\tLoss: 1.276561\n",
      "Train Epoch: 7 [43520/113287 (38%)]\tLoss: 1.298959\n",
      "Train Epoch: 7 [44800/113287 (40%)]\tLoss: 1.045595\n",
      "Train Epoch: 7 [46080/113287 (41%)]\tLoss: 1.006519\n",
      "Train Epoch: 7 [47360/113287 (42%)]\tLoss: 1.301902\n",
      "Train Epoch: 7 [48640/113287 (43%)]\tLoss: 1.247136\n",
      "Train Epoch: 7 [49920/113287 (44%)]\tLoss: 1.066962\n",
      "Train Epoch: 7 [51200/113287 (45%)]\tLoss: 1.215142\n",
      "Train Epoch: 7 [52480/113287 (46%)]\tLoss: 1.154340\n",
      "Train Epoch: 7 [53760/113287 (47%)]\tLoss: 1.253857\n",
      "Train Epoch: 7 [55040/113287 (49%)]\tLoss: 1.237383\n",
      "Train Epoch: 7 [56320/113287 (50%)]\tLoss: 1.353612\n",
      "Train Epoch: 7 [57600/113287 (51%)]\tLoss: 1.053780\n",
      "Train Epoch: 7 [58880/113287 (52%)]\tLoss: 1.148246\n",
      "Train Epoch: 7 [60160/113287 (53%)]\tLoss: 0.973296\n",
      "Train Epoch: 7 [61440/113287 (54%)]\tLoss: 1.075528\n",
      "Train Epoch: 7 [62720/113287 (55%)]\tLoss: 1.208340\n",
      "Train Epoch: 7 [64000/113287 (56%)]\tLoss: 1.120157\n",
      "Train Epoch: 7 [65280/113287 (58%)]\tLoss: 1.178051\n",
      "Train Epoch: 7 [66560/113287 (59%)]\tLoss: 1.050728\n",
      "Train Epoch: 7 [67840/113287 (60%)]\tLoss: 1.384040\n",
      "Train Epoch: 7 [69120/113287 (61%)]\tLoss: 1.252333\n",
      "Train Epoch: 7 [70400/113287 (62%)]\tLoss: 0.910832\n",
      "Train Epoch: 7 [71680/113287 (63%)]\tLoss: 1.106392\n",
      "Train Epoch: 7 [72960/113287 (64%)]\tLoss: 1.117558\n",
      "Train Epoch: 7 [74240/113287 (65%)]\tLoss: 1.032787\n",
      "Train Epoch: 7 [75520/113287 (67%)]\tLoss: 1.067328\n",
      "Train Epoch: 7 [76800/113287 (68%)]\tLoss: 1.175603\n",
      "Train Epoch: 7 [78080/113287 (69%)]\tLoss: 1.152416\n",
      "Train Epoch: 7 [79360/113287 (70%)]\tLoss: 1.006844\n",
      "Train Epoch: 7 [80640/113287 (71%)]\tLoss: 1.270220\n",
      "Train Epoch: 7 [81920/113287 (72%)]\tLoss: 1.033581\n",
      "Train Epoch: 7 [83200/113287 (73%)]\tLoss: 1.114318\n",
      "Train Epoch: 7 [84480/113287 (74%)]\tLoss: 1.261348\n",
      "Train Epoch: 7 [85760/113287 (76%)]\tLoss: 1.352606\n",
      "Train Epoch: 7 [87040/113287 (77%)]\tLoss: 0.967723\n",
      "Train Epoch: 7 [88320/113287 (78%)]\tLoss: 1.268240\n",
      "Train Epoch: 7 [89600/113287 (79%)]\tLoss: 1.357488\n",
      "Train Epoch: 7 [90880/113287 (80%)]\tLoss: 1.382425\n",
      "Train Epoch: 7 [92160/113287 (81%)]\tLoss: 1.274278\n",
      "Train Epoch: 7 [93440/113287 (82%)]\tLoss: 0.922090\n",
      "Train Epoch: 7 [94720/113287 (84%)]\tLoss: 1.342677\n",
      "Train Epoch: 7 [96000/113287 (85%)]\tLoss: 1.201170\n",
      "Train Epoch: 7 [97280/113287 (86%)]\tLoss: 1.270356\n",
      "Train Epoch: 7 [98560/113287 (87%)]\tLoss: 1.060186\n",
      "Train Epoch: 7 [99840/113287 (88%)]\tLoss: 0.976614\n",
      "Train Epoch: 7 [101120/113287 (89%)]\tLoss: 1.277423\n",
      "Train Epoch: 7 [102400/113287 (90%)]\tLoss: 1.217219\n",
      "Train Epoch: 7 [103680/113287 (91%)]\tLoss: 1.087186\n",
      "Train Epoch: 7 [104960/113287 (93%)]\tLoss: 1.130505\n",
      "Train Epoch: 7 [106240/113287 (94%)]\tLoss: 1.235867\n",
      "Train Epoch: 7 [107520/113287 (95%)]\tLoss: 1.125072\n",
      "Train Epoch: 7 [108800/113287 (96%)]\tLoss: 1.208008\n",
      "Train Epoch: 7 [110080/113287 (97%)]\tLoss: 1.262124\n",
      "Train Epoch: 7 [111360/113287 (98%)]\tLoss: 1.350761\n",
      "Train Epoch: 7 [112640/113287 (99%)]\tLoss: 1.186376\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3358/5000 (67%)\n",
      "\n",
      "Train Epoch: 8 [0/113287 (0%)]\tLoss: 1.185038\n",
      "Train Epoch: 8 [1280/113287 (1%)]\tLoss: 1.184052\n",
      "Train Epoch: 8 [2560/113287 (2%)]\tLoss: 1.390319\n",
      "Train Epoch: 8 [3840/113287 (3%)]\tLoss: 1.042064\n",
      "Train Epoch: 8 [5120/113287 (5%)]\tLoss: 1.121796\n",
      "Train Epoch: 8 [6400/113287 (6%)]\tLoss: 1.174155\n",
      "Train Epoch: 8 [7680/113287 (7%)]\tLoss: 1.294945\n",
      "Train Epoch: 8 [8960/113287 (8%)]\tLoss: 1.154997\n",
      "Train Epoch: 8 [10240/113287 (9%)]\tLoss: 0.987526\n",
      "Train Epoch: 8 [11520/113287 (10%)]\tLoss: 1.057250\n",
      "Train Epoch: 8 [12800/113287 (11%)]\tLoss: 0.943244\n",
      "Train Epoch: 8 [14080/113287 (12%)]\tLoss: 1.065430\n",
      "Train Epoch: 8 [15360/113287 (14%)]\tLoss: 1.178438\n",
      "Train Epoch: 8 [16640/113287 (15%)]\tLoss: 1.232099\n",
      "Train Epoch: 8 [17920/113287 (16%)]\tLoss: 1.070539\n",
      "Train Epoch: 8 [19200/113287 (17%)]\tLoss: 1.014518\n",
      "Train Epoch: 8 [20480/113287 (18%)]\tLoss: 0.899466\n",
      "Train Epoch: 8 [21760/113287 (19%)]\tLoss: 1.199464\n",
      "Train Epoch: 8 [23040/113287 (20%)]\tLoss: 1.186636\n",
      "Train Epoch: 8 [24320/113287 (21%)]\tLoss: 1.120019\n",
      "Train Epoch: 8 [25600/113287 (23%)]\tLoss: 1.230935\n",
      "Train Epoch: 8 [26880/113287 (24%)]\tLoss: 1.009342\n",
      "Train Epoch: 8 [28160/113287 (25%)]\tLoss: 1.087889\n",
      "Train Epoch: 8 [29440/113287 (26%)]\tLoss: 1.139125\n",
      "Train Epoch: 8 [30720/113287 (27%)]\tLoss: 1.054931\n",
      "Train Epoch: 8 [32000/113287 (28%)]\tLoss: 1.336691\n",
      "Train Epoch: 8 [33280/113287 (29%)]\tLoss: 1.143179\n",
      "Train Epoch: 8 [34560/113287 (30%)]\tLoss: 1.316899\n",
      "Train Epoch: 8 [35840/113287 (32%)]\tLoss: 0.847165\n",
      "Train Epoch: 8 [37120/113287 (33%)]\tLoss: 1.068791\n",
      "Train Epoch: 8 [38400/113287 (34%)]\tLoss: 1.202983\n",
      "Train Epoch: 8 [39680/113287 (35%)]\tLoss: 1.246161\n",
      "Train Epoch: 8 [40960/113287 (36%)]\tLoss: 0.978958\n",
      "Train Epoch: 8 [42240/113287 (37%)]\tLoss: 1.053226\n",
      "Train Epoch: 8 [43520/113287 (38%)]\tLoss: 1.262416\n",
      "Train Epoch: 8 [44800/113287 (40%)]\tLoss: 1.199833\n",
      "Train Epoch: 8 [46080/113287 (41%)]\tLoss: 1.522213\n",
      "Train Epoch: 8 [47360/113287 (42%)]\tLoss: 1.126614\n",
      "Train Epoch: 8 [48640/113287 (43%)]\tLoss: 1.107276\n",
      "Train Epoch: 8 [49920/113287 (44%)]\tLoss: 1.096475\n",
      "Train Epoch: 8 [51200/113287 (45%)]\tLoss: 0.900391\n",
      "Train Epoch: 8 [52480/113287 (46%)]\tLoss: 0.990905\n",
      "Train Epoch: 8 [53760/113287 (47%)]\tLoss: 1.127820\n",
      "Train Epoch: 8 [55040/113287 (49%)]\tLoss: 1.191957\n",
      "Train Epoch: 8 [56320/113287 (50%)]\tLoss: 1.287796\n",
      "Train Epoch: 8 [57600/113287 (51%)]\tLoss: 1.113080\n",
      "Train Epoch: 8 [58880/113287 (52%)]\tLoss: 1.023288\n",
      "Train Epoch: 8 [60160/113287 (53%)]\tLoss: 1.118424\n",
      "Train Epoch: 8 [61440/113287 (54%)]\tLoss: 1.219203\n",
      "Train Epoch: 8 [62720/113287 (55%)]\tLoss: 1.139645\n",
      "Train Epoch: 8 [64000/113287 (56%)]\tLoss: 1.057049\n",
      "Train Epoch: 8 [65280/113287 (58%)]\tLoss: 1.317074\n",
      "Train Epoch: 8 [66560/113287 (59%)]\tLoss: 1.102210\n",
      "Train Epoch: 8 [67840/113287 (60%)]\tLoss: 1.185342\n",
      "Train Epoch: 8 [69120/113287 (61%)]\tLoss: 1.130441\n",
      "Train Epoch: 8 [70400/113287 (62%)]\tLoss: 1.145010\n",
      "Train Epoch: 8 [71680/113287 (63%)]\tLoss: 1.219165\n",
      "Train Epoch: 8 [72960/113287 (64%)]\tLoss: 1.222833\n",
      "Train Epoch: 8 [74240/113287 (65%)]\tLoss: 1.096801\n",
      "Train Epoch: 8 [75520/113287 (67%)]\tLoss: 1.227802\n",
      "Train Epoch: 8 [76800/113287 (68%)]\tLoss: 1.076987\n",
      "Train Epoch: 8 [78080/113287 (69%)]\tLoss: 0.909994\n",
      "Train Epoch: 8 [79360/113287 (70%)]\tLoss: 1.221500\n",
      "Train Epoch: 8 [80640/113287 (71%)]\tLoss: 1.006356\n",
      "Train Epoch: 8 [81920/113287 (72%)]\tLoss: 1.338564\n",
      "Train Epoch: 8 [83200/113287 (73%)]\tLoss: 1.004779\n",
      "Train Epoch: 8 [84480/113287 (74%)]\tLoss: 1.274384\n",
      "Train Epoch: 8 [85760/113287 (76%)]\tLoss: 1.286325\n",
      "Train Epoch: 8 [87040/113287 (77%)]\tLoss: 1.135007\n",
      "Train Epoch: 8 [88320/113287 (78%)]\tLoss: 1.195823\n",
      "Train Epoch: 8 [89600/113287 (79%)]\tLoss: 1.411279\n",
      "Train Epoch: 8 [90880/113287 (80%)]\tLoss: 1.244634\n",
      "Train Epoch: 8 [92160/113287 (81%)]\tLoss: 1.144359\n",
      "Train Epoch: 8 [93440/113287 (82%)]\tLoss: 0.991678\n",
      "Train Epoch: 8 [94720/113287 (84%)]\tLoss: 1.020626\n",
      "Train Epoch: 8 [96000/113287 (85%)]\tLoss: 1.163430\n",
      "Train Epoch: 8 [97280/113287 (86%)]\tLoss: 1.135238\n",
      "Train Epoch: 8 [98560/113287 (87%)]\tLoss: 1.029213\n",
      "Train Epoch: 8 [99840/113287 (88%)]\tLoss: 1.271473\n",
      "Train Epoch: 8 [101120/113287 (89%)]\tLoss: 1.127696\n",
      "Train Epoch: 8 [102400/113287 (90%)]\tLoss: 1.088739\n",
      "Train Epoch: 8 [103680/113287 (91%)]\tLoss: 0.962360\n",
      "Train Epoch: 8 [104960/113287 (93%)]\tLoss: 1.107330\n",
      "Train Epoch: 8 [106240/113287 (94%)]\tLoss: 1.110581\n",
      "Train Epoch: 8 [107520/113287 (95%)]\tLoss: 1.299808\n",
      "Train Epoch: 8 [108800/113287 (96%)]\tLoss: 1.094167\n",
      "Train Epoch: 8 [110080/113287 (97%)]\tLoss: 1.065661\n",
      "Train Epoch: 8 [111360/113287 (98%)]\tLoss: 1.113723\n",
      "Train Epoch: 8 [112640/113287 (99%)]\tLoss: 1.139699\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3396/5000 (67%)\n",
      "\n",
      "Train Epoch: 9 [0/113287 (0%)]\tLoss: 0.917210\n",
      "Train Epoch: 9 [1280/113287 (1%)]\tLoss: 1.315160\n",
      "Train Epoch: 9 [2560/113287 (2%)]\tLoss: 1.274715\n",
      "Train Epoch: 9 [3840/113287 (3%)]\tLoss: 1.171560\n",
      "Train Epoch: 9 [5120/113287 (5%)]\tLoss: 1.054927\n",
      "Train Epoch: 9 [6400/113287 (6%)]\tLoss: 1.306383\n",
      "Train Epoch: 9 [7680/113287 (7%)]\tLoss: 1.047141\n",
      "Train Epoch: 9 [8960/113287 (8%)]\tLoss: 1.189803\n",
      "Train Epoch: 9 [10240/113287 (9%)]\tLoss: 1.263694\n",
      "Train Epoch: 9 [11520/113287 (10%)]\tLoss: 1.029060\n",
      "Train Epoch: 9 [12800/113287 (11%)]\tLoss: 1.006966\n",
      "Train Epoch: 9 [14080/113287 (12%)]\tLoss: 1.189826\n",
      "Train Epoch: 9 [15360/113287 (14%)]\tLoss: 1.063898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [16640/113287 (15%)]\tLoss: 1.096999\n",
      "Train Epoch: 9 [17920/113287 (16%)]\tLoss: 1.086968\n",
      "Train Epoch: 9 [19200/113287 (17%)]\tLoss: 1.152750\n",
      "Train Epoch: 9 [20480/113287 (18%)]\tLoss: 1.001251\n",
      "Train Epoch: 9 [21760/113287 (19%)]\tLoss: 1.225968\n",
      "Train Epoch: 9 [23040/113287 (20%)]\tLoss: 1.026267\n",
      "Train Epoch: 9 [24320/113287 (21%)]\tLoss: 1.178095\n",
      "Train Epoch: 9 [25600/113287 (23%)]\tLoss: 1.116600\n",
      "Train Epoch: 9 [26880/113287 (24%)]\tLoss: 1.118874\n",
      "Train Epoch: 9 [28160/113287 (25%)]\tLoss: 1.251474\n",
      "Train Epoch: 9 [29440/113287 (26%)]\tLoss: 1.074553\n",
      "Train Epoch: 9 [30720/113287 (27%)]\tLoss: 1.229367\n",
      "Train Epoch: 9 [32000/113287 (28%)]\tLoss: 0.932870\n",
      "Train Epoch: 9 [33280/113287 (29%)]\tLoss: 1.127724\n",
      "Train Epoch: 9 [34560/113287 (30%)]\tLoss: 1.218857\n",
      "Train Epoch: 9 [35840/113287 (32%)]\tLoss: 0.946577\n",
      "Train Epoch: 9 [37120/113287 (33%)]\tLoss: 1.238470\n",
      "Train Epoch: 9 [38400/113287 (34%)]\tLoss: 1.126146\n",
      "Train Epoch: 9 [39680/113287 (35%)]\tLoss: 1.112415\n",
      "Train Epoch: 9 [40960/113287 (36%)]\tLoss: 1.175541\n",
      "Train Epoch: 9 [42240/113287 (37%)]\tLoss: 1.076119\n",
      "Train Epoch: 9 [43520/113287 (38%)]\tLoss: 1.241300\n",
      "Train Epoch: 9 [44800/113287 (40%)]\tLoss: 1.218255\n",
      "Train Epoch: 9 [46080/113287 (41%)]\tLoss: 1.178008\n",
      "Train Epoch: 9 [47360/113287 (42%)]\tLoss: 1.001385\n",
      "Train Epoch: 9 [48640/113287 (43%)]\tLoss: 1.109957\n",
      "Train Epoch: 9 [49920/113287 (44%)]\tLoss: 1.008563\n",
      "Train Epoch: 9 [51200/113287 (45%)]\tLoss: 1.155801\n",
      "Train Epoch: 9 [52480/113287 (46%)]\tLoss: 1.171918\n",
      "Train Epoch: 9 [53760/113287 (47%)]\tLoss: 1.049432\n",
      "Train Epoch: 9 [55040/113287 (49%)]\tLoss: 1.028608\n",
      "Train Epoch: 9 [56320/113287 (50%)]\tLoss: 1.321920\n",
      "Train Epoch: 9 [57600/113287 (51%)]\tLoss: 1.029106\n",
      "Train Epoch: 9 [58880/113287 (52%)]\tLoss: 1.195023\n",
      "Train Epoch: 9 [60160/113287 (53%)]\tLoss: 1.049924\n",
      "Train Epoch: 9 [61440/113287 (54%)]\tLoss: 1.190852\n",
      "Train Epoch: 9 [62720/113287 (55%)]\tLoss: 1.203269\n",
      "Train Epoch: 9 [64000/113287 (56%)]\tLoss: 1.203595\n",
      "Train Epoch: 9 [65280/113287 (58%)]\tLoss: 1.030611\n",
      "Train Epoch: 9 [66560/113287 (59%)]\tLoss: 1.172838\n",
      "Train Epoch: 9 [67840/113287 (60%)]\tLoss: 1.163206\n",
      "Train Epoch: 9 [69120/113287 (61%)]\tLoss: 1.122260\n",
      "Train Epoch: 9 [70400/113287 (62%)]\tLoss: 1.287135\n",
      "Train Epoch: 9 [71680/113287 (63%)]\tLoss: 1.258961\n",
      "Train Epoch: 9 [72960/113287 (64%)]\tLoss: 1.171568\n",
      "Train Epoch: 9 [74240/113287 (65%)]\tLoss: 1.039733\n",
      "Train Epoch: 9 [75520/113287 (67%)]\tLoss: 0.982307\n",
      "Train Epoch: 9 [76800/113287 (68%)]\tLoss: 0.999831\n",
      "Train Epoch: 9 [78080/113287 (69%)]\tLoss: 1.247794\n",
      "Train Epoch: 9 [79360/113287 (70%)]\tLoss: 1.184109\n",
      "Train Epoch: 9 [80640/113287 (71%)]\tLoss: 1.074591\n",
      "Train Epoch: 9 [81920/113287 (72%)]\tLoss: 0.969975\n",
      "Train Epoch: 9 [83200/113287 (73%)]\tLoss: 0.948607\n",
      "Train Epoch: 9 [84480/113287 (74%)]\tLoss: 1.011379\n",
      "Train Epoch: 9 [85760/113287 (76%)]\tLoss: 1.056946\n",
      "Train Epoch: 9 [87040/113287 (77%)]\tLoss: 1.414297\n",
      "Train Epoch: 9 [88320/113287 (78%)]\tLoss: 1.351926\n",
      "Train Epoch: 9 [89600/113287 (79%)]\tLoss: 0.998960\n",
      "Train Epoch: 9 [90880/113287 (80%)]\tLoss: 1.051394\n",
      "Train Epoch: 9 [92160/113287 (81%)]\tLoss: 1.425168\n",
      "Train Epoch: 9 [93440/113287 (82%)]\tLoss: 1.054064\n",
      "Train Epoch: 9 [94720/113287 (84%)]\tLoss: 0.834386\n",
      "Train Epoch: 9 [96000/113287 (85%)]\tLoss: 1.411915\n",
      "Train Epoch: 9 [97280/113287 (86%)]\tLoss: 0.956667\n",
      "Train Epoch: 9 [98560/113287 (87%)]\tLoss: 1.062735\n",
      "Train Epoch: 9 [99840/113287 (88%)]\tLoss: 1.090001\n",
      "Train Epoch: 9 [101120/113287 (89%)]\tLoss: 1.075135\n",
      "Train Epoch: 9 [102400/113287 (90%)]\tLoss: 1.068365\n",
      "Train Epoch: 9 [103680/113287 (91%)]\tLoss: 1.234190\n",
      "Train Epoch: 9 [104960/113287 (93%)]\tLoss: 1.070011\n",
      "Train Epoch: 9 [106240/113287 (94%)]\tLoss: 1.125347\n",
      "Train Epoch: 9 [107520/113287 (95%)]\tLoss: 1.408384\n",
      "Train Epoch: 9 [108800/113287 (96%)]\tLoss: 1.246828\n",
      "Train Epoch: 9 [110080/113287 (97%)]\tLoss: 1.174693\n",
      "Train Epoch: 9 [111360/113287 (98%)]\tLoss: 1.076732\n",
      "Train Epoch: 9 [112640/113287 (99%)]\tLoss: 1.114420\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3426/5000 (68%)\n",
      "\n",
      "Train Epoch: 10 [0/113287 (0%)]\tLoss: 1.194415\n",
      "Train Epoch: 10 [1280/113287 (1%)]\tLoss: 1.058420\n",
      "Train Epoch: 10 [2560/113287 (2%)]\tLoss: 1.197252\n",
      "Train Epoch: 10 [3840/113287 (3%)]\tLoss: 1.209616\n",
      "Train Epoch: 10 [5120/113287 (5%)]\tLoss: 1.016719\n",
      "Train Epoch: 10 [6400/113287 (6%)]\tLoss: 1.126797\n",
      "Train Epoch: 10 [7680/113287 (7%)]\tLoss: 1.170979\n",
      "Train Epoch: 10 [8960/113287 (8%)]\tLoss: 1.106292\n",
      "Train Epoch: 10 [10240/113287 (9%)]\tLoss: 1.109405\n",
      "Train Epoch: 10 [11520/113287 (10%)]\tLoss: 1.066241\n",
      "Train Epoch: 10 [12800/113287 (11%)]\tLoss: 1.239057\n",
      "Train Epoch: 10 [14080/113287 (12%)]\tLoss: 1.010190\n",
      "Train Epoch: 10 [15360/113287 (14%)]\tLoss: 1.187735\n",
      "Train Epoch: 10 [16640/113287 (15%)]\tLoss: 1.144817\n",
      "Train Epoch: 10 [17920/113287 (16%)]\tLoss: 1.258822\n",
      "Train Epoch: 10 [19200/113287 (17%)]\tLoss: 1.118000\n",
      "Train Epoch: 10 [20480/113287 (18%)]\tLoss: 1.182801\n",
      "Train Epoch: 10 [21760/113287 (19%)]\tLoss: 1.125722\n",
      "Train Epoch: 10 [23040/113287 (20%)]\tLoss: 1.218701\n",
      "Train Epoch: 10 [24320/113287 (21%)]\tLoss: 1.122457\n",
      "Train Epoch: 10 [25600/113287 (23%)]\tLoss: 0.949073\n",
      "Train Epoch: 10 [26880/113287 (24%)]\tLoss: 1.097957\n",
      "Train Epoch: 10 [28160/113287 (25%)]\tLoss: 0.861235\n",
      "Train Epoch: 10 [29440/113287 (26%)]\tLoss: 1.095739\n",
      "Train Epoch: 10 [30720/113287 (27%)]\tLoss: 1.130200\n",
      "Train Epoch: 10 [32000/113287 (28%)]\tLoss: 1.050828\n",
      "Train Epoch: 10 [33280/113287 (29%)]\tLoss: 1.012793\n",
      "Train Epoch: 10 [34560/113287 (30%)]\tLoss: 1.136624\n",
      "Train Epoch: 10 [35840/113287 (32%)]\tLoss: 1.051168\n",
      "Train Epoch: 10 [37120/113287 (33%)]\tLoss: 1.082519\n",
      "Train Epoch: 10 [38400/113287 (34%)]\tLoss: 1.201653\n",
      "Train Epoch: 10 [39680/113287 (35%)]\tLoss: 1.206493\n",
      "Train Epoch: 10 [40960/113287 (36%)]\tLoss: 1.055784\n",
      "Train Epoch: 10 [42240/113287 (37%)]\tLoss: 1.089169\n",
      "Train Epoch: 10 [43520/113287 (38%)]\tLoss: 0.939068\n",
      "Train Epoch: 10 [44800/113287 (40%)]\tLoss: 1.279014\n",
      "Train Epoch: 10 [46080/113287 (41%)]\tLoss: 1.269243\n",
      "Train Epoch: 10 [47360/113287 (42%)]\tLoss: 1.079435\n",
      "Train Epoch: 10 [48640/113287 (43%)]\tLoss: 1.131614\n",
      "Train Epoch: 10 [49920/113287 (44%)]\tLoss: 1.112189\n",
      "Train Epoch: 10 [51200/113287 (45%)]\tLoss: 1.273257\n",
      "Train Epoch: 10 [52480/113287 (46%)]\tLoss: 1.183945\n",
      "Train Epoch: 10 [53760/113287 (47%)]\tLoss: 0.915305\n",
      "Train Epoch: 10 [55040/113287 (49%)]\tLoss: 1.104037\n",
      "Train Epoch: 10 [56320/113287 (50%)]\tLoss: 1.141506\n",
      "Train Epoch: 10 [57600/113287 (51%)]\tLoss: 1.053314\n",
      "Train Epoch: 10 [58880/113287 (52%)]\tLoss: 1.079636\n",
      "Train Epoch: 10 [60160/113287 (53%)]\tLoss: 1.244334\n",
      "Train Epoch: 10 [61440/113287 (54%)]\tLoss: 1.052953\n",
      "Train Epoch: 10 [62720/113287 (55%)]\tLoss: 1.002716\n",
      "Train Epoch: 10 [64000/113287 (56%)]\tLoss: 1.131837\n",
      "Train Epoch: 10 [65280/113287 (58%)]\tLoss: 1.218882\n",
      "Train Epoch: 10 [66560/113287 (59%)]\tLoss: 1.173377\n",
      "Train Epoch: 10 [67840/113287 (60%)]\tLoss: 0.968411\n",
      "Train Epoch: 10 [69120/113287 (61%)]\tLoss: 1.190061\n",
      "Train Epoch: 10 [70400/113287 (62%)]\tLoss: 1.057590\n",
      "Train Epoch: 10 [71680/113287 (63%)]\tLoss: 1.152009\n",
      "Train Epoch: 10 [72960/113287 (64%)]\tLoss: 0.930080\n",
      "Train Epoch: 10 [74240/113287 (65%)]\tLoss: 0.985607\n",
      "Train Epoch: 10 [75520/113287 (67%)]\tLoss: 1.185266\n",
      "Train Epoch: 10 [76800/113287 (68%)]\tLoss: 1.123669\n",
      "Train Epoch: 10 [78080/113287 (69%)]\tLoss: 1.139282\n",
      "Train Epoch: 10 [79360/113287 (70%)]\tLoss: 1.246716\n",
      "Train Epoch: 10 [80640/113287 (71%)]\tLoss: 1.079811\n",
      "Train Epoch: 10 [81920/113287 (72%)]\tLoss: 1.123359\n",
      "Train Epoch: 10 [83200/113287 (73%)]\tLoss: 1.186254\n",
      "Train Epoch: 10 [84480/113287 (74%)]\tLoss: 1.109529\n",
      "Train Epoch: 10 [85760/113287 (76%)]\tLoss: 1.123670\n",
      "Train Epoch: 10 [87040/113287 (77%)]\tLoss: 1.034875\n",
      "Train Epoch: 10 [88320/113287 (78%)]\tLoss: 1.199711\n",
      "Train Epoch: 10 [89600/113287 (79%)]\tLoss: 1.098141\n",
      "Train Epoch: 10 [90880/113287 (80%)]\tLoss: 0.951178\n",
      "Train Epoch: 10 [92160/113287 (81%)]\tLoss: 1.029049\n",
      "Train Epoch: 10 [93440/113287 (82%)]\tLoss: 0.834404\n",
      "Train Epoch: 10 [94720/113287 (84%)]\tLoss: 0.987327\n",
      "Train Epoch: 10 [96000/113287 (85%)]\tLoss: 1.136898\n",
      "Train Epoch: 10 [97280/113287 (86%)]\tLoss: 1.018028\n",
      "Train Epoch: 10 [98560/113287 (87%)]\tLoss: 1.255449\n",
      "Train Epoch: 10 [99840/113287 (88%)]\tLoss: 1.086585\n",
      "Train Epoch: 10 [101120/113287 (89%)]\tLoss: 1.011901\n",
      "Train Epoch: 10 [102400/113287 (90%)]\tLoss: 0.835557\n",
      "Train Epoch: 10 [103680/113287 (91%)]\tLoss: 1.147660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [104960/113287 (93%)]\tLoss: 1.114374\n",
      "Train Epoch: 10 [106240/113287 (94%)]\tLoss: 1.156909\n",
      "Train Epoch: 10 [107520/113287 (95%)]\tLoss: 0.888547\n",
      "Train Epoch: 10 [108800/113287 (96%)]\tLoss: 0.832962\n",
      "Train Epoch: 10 [110080/113287 (97%)]\tLoss: 1.140922\n",
      "Train Epoch: 10 [111360/113287 (98%)]\tLoss: 0.958596\n",
      "Train Epoch: 10 [112640/113287 (99%)]\tLoss: 1.166561\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3417/5000 (68%)\n",
      "\n",
      "Train Epoch: 11 [0/113287 (0%)]\tLoss: 1.118628\n",
      "Train Epoch: 11 [1280/113287 (1%)]\tLoss: 1.120569\n",
      "Train Epoch: 11 [2560/113287 (2%)]\tLoss: 1.165525\n",
      "Train Epoch: 11 [3840/113287 (3%)]\tLoss: 1.128320\n",
      "Train Epoch: 11 [5120/113287 (5%)]\tLoss: 1.117362\n",
      "Train Epoch: 11 [6400/113287 (6%)]\tLoss: 0.950929\n",
      "Train Epoch: 11 [7680/113287 (7%)]\tLoss: 0.908655\n",
      "Train Epoch: 11 [8960/113287 (8%)]\tLoss: 1.056938\n",
      "Train Epoch: 11 [10240/113287 (9%)]\tLoss: 0.955830\n",
      "Train Epoch: 11 [11520/113287 (10%)]\tLoss: 1.162813\n",
      "Train Epoch: 11 [12800/113287 (11%)]\tLoss: 1.069453\n",
      "Train Epoch: 11 [14080/113287 (12%)]\tLoss: 0.982125\n",
      "Train Epoch: 11 [15360/113287 (14%)]\tLoss: 1.156753\n",
      "Train Epoch: 11 [16640/113287 (15%)]\tLoss: 1.269070\n",
      "Train Epoch: 11 [17920/113287 (16%)]\tLoss: 0.902404\n",
      "Train Epoch: 11 [19200/113287 (17%)]\tLoss: 1.005012\n",
      "Train Epoch: 11 [20480/113287 (18%)]\tLoss: 0.872949\n",
      "Train Epoch: 11 [21760/113287 (19%)]\tLoss: 1.009922\n",
      "Train Epoch: 11 [23040/113287 (20%)]\tLoss: 1.253336\n",
      "Train Epoch: 11 [24320/113287 (21%)]\tLoss: 1.175359\n",
      "Train Epoch: 11 [25600/113287 (23%)]\tLoss: 1.113143\n",
      "Train Epoch: 11 [26880/113287 (24%)]\tLoss: 1.019803\n",
      "Train Epoch: 11 [28160/113287 (25%)]\tLoss: 1.096410\n",
      "Train Epoch: 11 [29440/113287 (26%)]\tLoss: 1.151215\n",
      "Train Epoch: 11 [30720/113287 (27%)]\tLoss: 1.178657\n",
      "Train Epoch: 11 [32000/113287 (28%)]\tLoss: 0.747411\n",
      "Train Epoch: 11 [33280/113287 (29%)]\tLoss: 0.988277\n",
      "Train Epoch: 11 [34560/113287 (30%)]\tLoss: 1.219535\n",
      "Train Epoch: 11 [35840/113287 (32%)]\tLoss: 0.996048\n",
      "Train Epoch: 11 [37120/113287 (33%)]\tLoss: 1.099993\n",
      "Train Epoch: 11 [38400/113287 (34%)]\tLoss: 1.111488\n",
      "Train Epoch: 11 [39680/113287 (35%)]\tLoss: 0.979282\n",
      "Train Epoch: 11 [40960/113287 (36%)]\tLoss: 1.049301\n",
      "Train Epoch: 11 [42240/113287 (37%)]\tLoss: 0.866217\n",
      "Train Epoch: 11 [43520/113287 (38%)]\tLoss: 1.138422\n",
      "Train Epoch: 11 [44800/113287 (40%)]\tLoss: 1.104609\n",
      "Train Epoch: 11 [46080/113287 (41%)]\tLoss: 0.832610\n",
      "Train Epoch: 11 [47360/113287 (42%)]\tLoss: 1.240490\n",
      "Train Epoch: 11 [48640/113287 (43%)]\tLoss: 1.102026\n",
      "Train Epoch: 11 [49920/113287 (44%)]\tLoss: 1.068616\n",
      "Train Epoch: 11 [51200/113287 (45%)]\tLoss: 1.410083\n",
      "Train Epoch: 11 [52480/113287 (46%)]\tLoss: 1.017866\n",
      "Train Epoch: 11 [53760/113287 (47%)]\tLoss: 1.036270\n",
      "Train Epoch: 11 [55040/113287 (49%)]\tLoss: 1.108549\n",
      "Train Epoch: 11 [56320/113287 (50%)]\tLoss: 1.330611\n",
      "Train Epoch: 11 [57600/113287 (51%)]\tLoss: 1.075551\n",
      "Train Epoch: 11 [58880/113287 (52%)]\tLoss: 1.282426\n",
      "Train Epoch: 11 [60160/113287 (53%)]\tLoss: 1.257352\n",
      "Train Epoch: 11 [61440/113287 (54%)]\tLoss: 0.962406\n",
      "Train Epoch: 11 [62720/113287 (55%)]\tLoss: 1.070327\n",
      "Train Epoch: 11 [64000/113287 (56%)]\tLoss: 1.148106\n",
      "Train Epoch: 11 [65280/113287 (58%)]\tLoss: 1.063450\n",
      "Train Epoch: 11 [66560/113287 (59%)]\tLoss: 1.330107\n",
      "Train Epoch: 11 [67840/113287 (60%)]\tLoss: 1.200236\n",
      "Train Epoch: 11 [69120/113287 (61%)]\tLoss: 1.121258\n",
      "Train Epoch: 11 [70400/113287 (62%)]\tLoss: 0.959694\n",
      "Train Epoch: 11 [71680/113287 (63%)]\tLoss: 1.132904\n",
      "Train Epoch: 11 [72960/113287 (64%)]\tLoss: 0.968513\n",
      "Train Epoch: 11 [74240/113287 (65%)]\tLoss: 1.034302\n",
      "Train Epoch: 11 [75520/113287 (67%)]\tLoss: 0.924049\n",
      "Train Epoch: 11 [76800/113287 (68%)]\tLoss: 1.141764\n",
      "Train Epoch: 11 [78080/113287 (69%)]\tLoss: 1.119493\n",
      "Train Epoch: 11 [79360/113287 (70%)]\tLoss: 1.184832\n",
      "Train Epoch: 11 [80640/113287 (71%)]\tLoss: 1.077051\n",
      "Train Epoch: 11 [81920/113287 (72%)]\tLoss: 1.089108\n",
      "Train Epoch: 11 [83200/113287 (73%)]\tLoss: 0.946840\n",
      "Train Epoch: 11 [84480/113287 (74%)]\tLoss: 1.095769\n",
      "Train Epoch: 11 [85760/113287 (76%)]\tLoss: 1.000514\n",
      "Train Epoch: 11 [87040/113287 (77%)]\tLoss: 1.186026\n",
      "Train Epoch: 11 [88320/113287 (78%)]\tLoss: 1.148772\n",
      "Train Epoch: 11 [89600/113287 (79%)]\tLoss: 0.972490\n",
      "Train Epoch: 11 [90880/113287 (80%)]\tLoss: 0.998916\n",
      "Train Epoch: 11 [92160/113287 (81%)]\tLoss: 0.907077\n",
      "Train Epoch: 11 [93440/113287 (82%)]\tLoss: 1.313299\n",
      "Train Epoch: 11 [94720/113287 (84%)]\tLoss: 1.237729\n",
      "Train Epoch: 11 [96000/113287 (85%)]\tLoss: 0.964133\n",
      "Train Epoch: 11 [97280/113287 (86%)]\tLoss: 1.324574\n",
      "Train Epoch: 11 [98560/113287 (87%)]\tLoss: 0.927904\n",
      "Train Epoch: 11 [99840/113287 (88%)]\tLoss: 1.287418\n",
      "Train Epoch: 11 [101120/113287 (89%)]\tLoss: 1.005077\n",
      "Train Epoch: 11 [102400/113287 (90%)]\tLoss: 0.894827\n",
      "Train Epoch: 11 [103680/113287 (91%)]\tLoss: 1.129353\n",
      "Train Epoch: 11 [104960/113287 (93%)]\tLoss: 1.085332\n",
      "Train Epoch: 11 [106240/113287 (94%)]\tLoss: 1.004425\n",
      "Train Epoch: 11 [107520/113287 (95%)]\tLoss: 1.038177\n",
      "Train Epoch: 11 [108800/113287 (96%)]\tLoss: 0.793690\n",
      "Train Epoch: 11 [110080/113287 (97%)]\tLoss: 1.084328\n",
      "Train Epoch: 11 [111360/113287 (98%)]\tLoss: 1.121587\n",
      "Train Epoch: 11 [112640/113287 (99%)]\tLoss: 1.054898\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3435/5000 (68%)\n",
      "\n",
      "Train Epoch: 12 [0/113287 (0%)]\tLoss: 1.108806\n",
      "Train Epoch: 12 [1280/113287 (1%)]\tLoss: 1.076609\n",
      "Train Epoch: 12 [2560/113287 (2%)]\tLoss: 1.048123\n",
      "Train Epoch: 12 [3840/113287 (3%)]\tLoss: 1.187265\n",
      "Train Epoch: 12 [5120/113287 (5%)]\tLoss: 1.015207\n",
      "Train Epoch: 12 [6400/113287 (6%)]\tLoss: 1.065439\n",
      "Train Epoch: 12 [7680/113287 (7%)]\tLoss: 0.961122\n",
      "Train Epoch: 12 [8960/113287 (8%)]\tLoss: 1.066875\n",
      "Train Epoch: 12 [10240/113287 (9%)]\tLoss: 1.299566\n",
      "Train Epoch: 12 [11520/113287 (10%)]\tLoss: 0.920086\n",
      "Train Epoch: 12 [12800/113287 (11%)]\tLoss: 1.056806\n",
      "Train Epoch: 12 [14080/113287 (12%)]\tLoss: 1.054281\n",
      "Train Epoch: 12 [15360/113287 (14%)]\tLoss: 1.127321\n",
      "Train Epoch: 12 [16640/113287 (15%)]\tLoss: 1.024017\n",
      "Train Epoch: 12 [17920/113287 (16%)]\tLoss: 1.170689\n",
      "Train Epoch: 12 [19200/113287 (17%)]\tLoss: 1.015052\n",
      "Train Epoch: 12 [20480/113287 (18%)]\tLoss: 1.120625\n",
      "Train Epoch: 12 [21760/113287 (19%)]\tLoss: 1.103186\n",
      "Train Epoch: 12 [23040/113287 (20%)]\tLoss: 0.854609\n",
      "Train Epoch: 12 [24320/113287 (21%)]\tLoss: 1.030227\n",
      "Train Epoch: 12 [25600/113287 (23%)]\tLoss: 1.127764\n",
      "Train Epoch: 12 [26880/113287 (24%)]\tLoss: 1.194844\n",
      "Train Epoch: 12 [28160/113287 (25%)]\tLoss: 1.250867\n",
      "Train Epoch: 12 [29440/113287 (26%)]\tLoss: 1.020154\n",
      "Train Epoch: 12 [30720/113287 (27%)]\tLoss: 1.138674\n",
      "Train Epoch: 12 [32000/113287 (28%)]\tLoss: 1.026379\n",
      "Train Epoch: 12 [33280/113287 (29%)]\tLoss: 1.146022\n",
      "Train Epoch: 12 [34560/113287 (30%)]\tLoss: 1.118741\n",
      "Train Epoch: 12 [35840/113287 (32%)]\tLoss: 1.086518\n",
      "Train Epoch: 12 [37120/113287 (33%)]\tLoss: 1.268379\n",
      "Train Epoch: 12 [38400/113287 (34%)]\tLoss: 0.982654\n",
      "Train Epoch: 12 [39680/113287 (35%)]\tLoss: 1.036811\n",
      "Train Epoch: 12 [40960/113287 (36%)]\tLoss: 0.982412\n",
      "Train Epoch: 12 [42240/113287 (37%)]\tLoss: 1.181677\n",
      "Train Epoch: 12 [43520/113287 (38%)]\tLoss: 0.898626\n",
      "Train Epoch: 12 [44800/113287 (40%)]\tLoss: 0.857789\n",
      "Train Epoch: 12 [46080/113287 (41%)]\tLoss: 0.938064\n",
      "Train Epoch: 12 [47360/113287 (42%)]\tLoss: 1.268924\n",
      "Train Epoch: 12 [48640/113287 (43%)]\tLoss: 0.899391\n",
      "Train Epoch: 12 [49920/113287 (44%)]\tLoss: 1.015970\n",
      "Train Epoch: 12 [51200/113287 (45%)]\tLoss: 1.003321\n",
      "Train Epoch: 12 [52480/113287 (46%)]\tLoss: 0.908096\n",
      "Train Epoch: 12 [53760/113287 (47%)]\tLoss: 0.842915\n",
      "Train Epoch: 12 [55040/113287 (49%)]\tLoss: 1.026046\n",
      "Train Epoch: 12 [56320/113287 (50%)]\tLoss: 0.945153\n",
      "Train Epoch: 12 [57600/113287 (51%)]\tLoss: 0.939149\n",
      "Train Epoch: 12 [58880/113287 (52%)]\tLoss: 1.077289\n",
      "Train Epoch: 12 [60160/113287 (53%)]\tLoss: 1.245360\n",
      "Train Epoch: 12 [61440/113287 (54%)]\tLoss: 1.115607\n",
      "Train Epoch: 12 [62720/113287 (55%)]\tLoss: 1.128474\n",
      "Train Epoch: 12 [64000/113287 (56%)]\tLoss: 1.140034\n",
      "Train Epoch: 12 [65280/113287 (58%)]\tLoss: 1.125017\n",
      "Train Epoch: 12 [66560/113287 (59%)]\tLoss: 1.003963\n",
      "Train Epoch: 12 [67840/113287 (60%)]\tLoss: 1.006225\n",
      "Train Epoch: 12 [69120/113287 (61%)]\tLoss: 1.140246\n",
      "Train Epoch: 12 [70400/113287 (62%)]\tLoss: 0.913705\n",
      "Train Epoch: 12 [71680/113287 (63%)]\tLoss: 1.031000\n",
      "Train Epoch: 12 [72960/113287 (64%)]\tLoss: 0.977242\n",
      "Train Epoch: 12 [74240/113287 (65%)]\tLoss: 1.082485\n",
      "Train Epoch: 12 [75520/113287 (67%)]\tLoss: 0.890602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [76800/113287 (68%)]\tLoss: 1.302469\n",
      "Train Epoch: 12 [78080/113287 (69%)]\tLoss: 0.770319\n",
      "Train Epoch: 12 [79360/113287 (70%)]\tLoss: 1.244990\n",
      "Train Epoch: 12 [80640/113287 (71%)]\tLoss: 1.187038\n",
      "Train Epoch: 12 [81920/113287 (72%)]\tLoss: 0.963503\n",
      "Train Epoch: 12 [83200/113287 (73%)]\tLoss: 1.366244\n",
      "Train Epoch: 12 [84480/113287 (74%)]\tLoss: 1.051473\n",
      "Train Epoch: 12 [85760/113287 (76%)]\tLoss: 0.995887\n",
      "Train Epoch: 12 [87040/113287 (77%)]\tLoss: 1.012987\n",
      "Train Epoch: 12 [88320/113287 (78%)]\tLoss: 1.152420\n",
      "Train Epoch: 12 [89600/113287 (79%)]\tLoss: 1.108552\n",
      "Train Epoch: 12 [90880/113287 (80%)]\tLoss: 0.865787\n",
      "Train Epoch: 12 [92160/113287 (81%)]\tLoss: 0.932055\n",
      "Train Epoch: 12 [93440/113287 (82%)]\tLoss: 1.069630\n",
      "Train Epoch: 12 [94720/113287 (84%)]\tLoss: 1.179709\n",
      "Train Epoch: 12 [96000/113287 (85%)]\tLoss: 0.965313\n",
      "Train Epoch: 12 [97280/113287 (86%)]\tLoss: 1.132759\n",
      "Train Epoch: 12 [98560/113287 (87%)]\tLoss: 0.964755\n",
      "Train Epoch: 12 [99840/113287 (88%)]\tLoss: 1.200147\n",
      "Train Epoch: 12 [101120/113287 (89%)]\tLoss: 1.028078\n",
      "Train Epoch: 12 [102400/113287 (90%)]\tLoss: 1.105516\n",
      "Train Epoch: 12 [103680/113287 (91%)]\tLoss: 1.080824\n",
      "Train Epoch: 12 [104960/113287 (93%)]\tLoss: 1.079349\n",
      "Train Epoch: 12 [106240/113287 (94%)]\tLoss: 0.901198\n",
      "Train Epoch: 12 [107520/113287 (95%)]\tLoss: 1.066385\n",
      "Train Epoch: 12 [108800/113287 (96%)]\tLoss: 1.258733\n",
      "Train Epoch: 12 [110080/113287 (97%)]\tLoss: 1.177432\n",
      "Train Epoch: 12 [111360/113287 (98%)]\tLoss: 0.995089\n",
      "Train Epoch: 12 [112640/113287 (99%)]\tLoss: 1.094058\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3463/5000 (69%)\n",
      "\n",
      "Train Epoch: 13 [0/113287 (0%)]\tLoss: 1.054098\n",
      "Train Epoch: 13 [1280/113287 (1%)]\tLoss: 0.876527\n",
      "Train Epoch: 13 [2560/113287 (2%)]\tLoss: 1.062787\n",
      "Train Epoch: 13 [3840/113287 (3%)]\tLoss: 0.940543\n",
      "Train Epoch: 13 [5120/113287 (5%)]\tLoss: 1.006642\n",
      "Train Epoch: 13 [6400/113287 (6%)]\tLoss: 1.176265\n",
      "Train Epoch: 13 [7680/113287 (7%)]\tLoss: 0.827962\n",
      "Train Epoch: 13 [8960/113287 (8%)]\tLoss: 1.074422\n",
      "Train Epoch: 13 [10240/113287 (9%)]\tLoss: 1.208622\n",
      "Train Epoch: 13 [11520/113287 (10%)]\tLoss: 1.089981\n",
      "Train Epoch: 13 [12800/113287 (11%)]\tLoss: 0.742691\n",
      "Train Epoch: 13 [14080/113287 (12%)]\tLoss: 1.133033\n",
      "Train Epoch: 13 [15360/113287 (14%)]\tLoss: 0.895935\n",
      "Train Epoch: 13 [16640/113287 (15%)]\tLoss: 1.090076\n",
      "Train Epoch: 13 [17920/113287 (16%)]\tLoss: 1.230768\n",
      "Train Epoch: 13 [19200/113287 (17%)]\tLoss: 1.047831\n",
      "Train Epoch: 13 [20480/113287 (18%)]\tLoss: 1.017588\n",
      "Train Epoch: 13 [21760/113287 (19%)]\tLoss: 0.959186\n",
      "Train Epoch: 13 [23040/113287 (20%)]\tLoss: 1.329378\n",
      "Train Epoch: 13 [24320/113287 (21%)]\tLoss: 0.940758\n",
      "Train Epoch: 13 [25600/113287 (23%)]\tLoss: 0.966769\n",
      "Train Epoch: 13 [26880/113287 (24%)]\tLoss: 0.842362\n",
      "Train Epoch: 13 [28160/113287 (25%)]\tLoss: 1.038903\n",
      "Train Epoch: 13 [29440/113287 (26%)]\tLoss: 0.927349\n",
      "Train Epoch: 13 [30720/113287 (27%)]\tLoss: 1.419041\n",
      "Train Epoch: 13 [32000/113287 (28%)]\tLoss: 1.264517\n",
      "Train Epoch: 13 [33280/113287 (29%)]\tLoss: 1.323581\n",
      "Train Epoch: 13 [34560/113287 (30%)]\tLoss: 0.888578\n",
      "Train Epoch: 13 [35840/113287 (32%)]\tLoss: 0.955842\n",
      "Train Epoch: 13 [37120/113287 (33%)]\tLoss: 1.060848\n",
      "Train Epoch: 13 [38400/113287 (34%)]\tLoss: 1.035003\n",
      "Train Epoch: 13 [39680/113287 (35%)]\tLoss: 1.127195\n",
      "Train Epoch: 13 [40960/113287 (36%)]\tLoss: 0.859919\n",
      "Train Epoch: 13 [42240/113287 (37%)]\tLoss: 0.934741\n",
      "Train Epoch: 13 [43520/113287 (38%)]\tLoss: 1.273716\n",
      "Train Epoch: 13 [44800/113287 (40%)]\tLoss: 0.972649\n",
      "Train Epoch: 13 [46080/113287 (41%)]\tLoss: 1.137379\n",
      "Train Epoch: 13 [47360/113287 (42%)]\tLoss: 0.973353\n",
      "Train Epoch: 13 [48640/113287 (43%)]\tLoss: 1.236220\n",
      "Train Epoch: 13 [49920/113287 (44%)]\tLoss: 0.996188\n",
      "Train Epoch: 13 [51200/113287 (45%)]\tLoss: 1.071222\n",
      "Train Epoch: 13 [52480/113287 (46%)]\tLoss: 1.156298\n",
      "Train Epoch: 13 [53760/113287 (47%)]\tLoss: 0.899253\n",
      "Train Epoch: 13 [55040/113287 (49%)]\tLoss: 0.888091\n",
      "Train Epoch: 13 [56320/113287 (50%)]\tLoss: 1.016521\n",
      "Train Epoch: 13 [57600/113287 (51%)]\tLoss: 0.817181\n",
      "Train Epoch: 13 [58880/113287 (52%)]\tLoss: 1.193416\n",
      "Train Epoch: 13 [60160/113287 (53%)]\tLoss: 0.822294\n",
      "Train Epoch: 13 [61440/113287 (54%)]\tLoss: 1.068062\n",
      "Train Epoch: 13 [62720/113287 (55%)]\tLoss: 1.015707\n",
      "Train Epoch: 13 [64000/113287 (56%)]\tLoss: 0.922115\n",
      "Train Epoch: 13 [65280/113287 (58%)]\tLoss: 1.207414\n",
      "Train Epoch: 13 [66560/113287 (59%)]\tLoss: 1.055564\n",
      "Train Epoch: 13 [67840/113287 (60%)]\tLoss: 1.139499\n",
      "Train Epoch: 13 [69120/113287 (61%)]\tLoss: 1.124933\n",
      "Train Epoch: 13 [70400/113287 (62%)]\tLoss: 1.223904\n",
      "Train Epoch: 13 [71680/113287 (63%)]\tLoss: 0.922660\n",
      "Train Epoch: 13 [72960/113287 (64%)]\tLoss: 1.029017\n",
      "Train Epoch: 13 [74240/113287 (65%)]\tLoss: 0.979792\n",
      "Train Epoch: 13 [75520/113287 (67%)]\tLoss: 1.212975\n",
      "Train Epoch: 13 [76800/113287 (68%)]\tLoss: 0.959393\n",
      "Train Epoch: 13 [78080/113287 (69%)]\tLoss: 0.956609\n",
      "Train Epoch: 13 [79360/113287 (70%)]\tLoss: 1.028510\n",
      "Train Epoch: 13 [80640/113287 (71%)]\tLoss: 1.073384\n",
      "Train Epoch: 13 [81920/113287 (72%)]\tLoss: 1.199382\n",
      "Train Epoch: 13 [83200/113287 (73%)]\tLoss: 1.197208\n",
      "Train Epoch: 13 [84480/113287 (74%)]\tLoss: 0.803093\n",
      "Train Epoch: 13 [85760/113287 (76%)]\tLoss: 0.970210\n",
      "Train Epoch: 13 [87040/113287 (77%)]\tLoss: 0.889807\n",
      "Train Epoch: 13 [88320/113287 (78%)]\tLoss: 1.013437\n",
      "Train Epoch: 13 [89600/113287 (79%)]\tLoss: 1.215017\n",
      "Train Epoch: 13 [90880/113287 (80%)]\tLoss: 0.806540\n",
      "Train Epoch: 13 [92160/113287 (81%)]\tLoss: 1.130414\n",
      "Train Epoch: 13 [93440/113287 (82%)]\tLoss: 1.047533\n",
      "Train Epoch: 13 [94720/113287 (84%)]\tLoss: 1.011329\n",
      "Train Epoch: 13 [96000/113287 (85%)]\tLoss: 0.981741\n",
      "Train Epoch: 13 [97280/113287 (86%)]\tLoss: 0.863520\n",
      "Train Epoch: 13 [98560/113287 (87%)]\tLoss: 1.006266\n",
      "Train Epoch: 13 [99840/113287 (88%)]\tLoss: 1.122398\n",
      "Train Epoch: 13 [101120/113287 (89%)]\tLoss: 1.192102\n",
      "Train Epoch: 13 [102400/113287 (90%)]\tLoss: 1.053504\n",
      "Train Epoch: 13 [103680/113287 (91%)]\tLoss: 1.043203\n",
      "Train Epoch: 13 [104960/113287 (93%)]\tLoss: 1.023126\n",
      "Train Epoch: 13 [106240/113287 (94%)]\tLoss: 1.023915\n",
      "Train Epoch: 13 [107520/113287 (95%)]\tLoss: 1.073139\n",
      "Train Epoch: 13 [108800/113287 (96%)]\tLoss: 1.091065\n",
      "Train Epoch: 13 [110080/113287 (97%)]\tLoss: 0.964334\n",
      "Train Epoch: 13 [111360/113287 (98%)]\tLoss: 1.081103\n",
      "Train Epoch: 13 [112640/113287 (99%)]\tLoss: 0.891175\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3425/5000 (68%)\n",
      "\n",
      "Train Epoch: 14 [0/113287 (0%)]\tLoss: 1.328016\n",
      "Train Epoch: 14 [1280/113287 (1%)]\tLoss: 0.844501\n",
      "Train Epoch: 14 [2560/113287 (2%)]\tLoss: 1.135643\n",
      "Train Epoch: 14 [3840/113287 (3%)]\tLoss: 1.103933\n",
      "Train Epoch: 14 [5120/113287 (5%)]\tLoss: 0.879544\n",
      "Train Epoch: 14 [6400/113287 (6%)]\tLoss: 1.015688\n",
      "Train Epoch: 14 [7680/113287 (7%)]\tLoss: 1.345633\n",
      "Train Epoch: 14 [8960/113287 (8%)]\tLoss: 1.163906\n",
      "Train Epoch: 14 [10240/113287 (9%)]\tLoss: 1.001738\n",
      "Train Epoch: 14 [11520/113287 (10%)]\tLoss: 1.017519\n",
      "Train Epoch: 14 [12800/113287 (11%)]\tLoss: 1.066848\n",
      "Train Epoch: 14 [14080/113287 (12%)]\tLoss: 1.082905\n",
      "Train Epoch: 14 [15360/113287 (14%)]\tLoss: 0.913355\n",
      "Train Epoch: 14 [16640/113287 (15%)]\tLoss: 1.185638\n",
      "Train Epoch: 14 [17920/113287 (16%)]\tLoss: 0.941787\n",
      "Train Epoch: 14 [19200/113287 (17%)]\tLoss: 1.235893\n",
      "Train Epoch: 14 [20480/113287 (18%)]\tLoss: 1.028602\n",
      "Train Epoch: 14 [21760/113287 (19%)]\tLoss: 1.169212\n",
      "Train Epoch: 14 [23040/113287 (20%)]\tLoss: 0.962768\n",
      "Train Epoch: 14 [24320/113287 (21%)]\tLoss: 0.953386\n",
      "Train Epoch: 14 [25600/113287 (23%)]\tLoss: 1.253069\n",
      "Train Epoch: 14 [26880/113287 (24%)]\tLoss: 1.050378\n",
      "Train Epoch: 14 [28160/113287 (25%)]\tLoss: 0.973544\n",
      "Train Epoch: 14 [29440/113287 (26%)]\tLoss: 1.201752\n",
      "Train Epoch: 14 [30720/113287 (27%)]\tLoss: 1.038302\n",
      "Train Epoch: 14 [32000/113287 (28%)]\tLoss: 1.018168\n",
      "Train Epoch: 14 [33280/113287 (29%)]\tLoss: 1.278683\n",
      "Train Epoch: 14 [34560/113287 (30%)]\tLoss: 0.903056\n",
      "Train Epoch: 14 [35840/113287 (32%)]\tLoss: 1.208910\n",
      "Train Epoch: 14 [37120/113287 (33%)]\tLoss: 1.154279\n",
      "Train Epoch: 14 [38400/113287 (34%)]\tLoss: 1.165399\n",
      "Train Epoch: 14 [39680/113287 (35%)]\tLoss: 0.919796\n",
      "Train Epoch: 14 [40960/113287 (36%)]\tLoss: 0.992576\n",
      "Train Epoch: 14 [42240/113287 (37%)]\tLoss: 0.909527\n",
      "Train Epoch: 14 [43520/113287 (38%)]\tLoss: 0.961386\n",
      "Train Epoch: 14 [44800/113287 (40%)]\tLoss: 1.265523\n",
      "Train Epoch: 14 [46080/113287 (41%)]\tLoss: 1.260705\n",
      "Train Epoch: 14 [47360/113287 (42%)]\tLoss: 0.883701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [48640/113287 (43%)]\tLoss: 1.133057\n",
      "Train Epoch: 14 [49920/113287 (44%)]\tLoss: 0.989300\n",
      "Train Epoch: 14 [51200/113287 (45%)]\tLoss: 1.018659\n",
      "Train Epoch: 14 [52480/113287 (46%)]\tLoss: 0.957105\n",
      "Train Epoch: 14 [53760/113287 (47%)]\tLoss: 1.095098\n",
      "Train Epoch: 14 [55040/113287 (49%)]\tLoss: 0.933581\n",
      "Train Epoch: 14 [56320/113287 (50%)]\tLoss: 1.086267\n",
      "Train Epoch: 14 [57600/113287 (51%)]\tLoss: 0.968720\n",
      "Train Epoch: 14 [58880/113287 (52%)]\tLoss: 0.948335\n",
      "Train Epoch: 14 [60160/113287 (53%)]\tLoss: 1.041723\n",
      "Train Epoch: 14 [61440/113287 (54%)]\tLoss: 1.317761\n",
      "Train Epoch: 14 [62720/113287 (55%)]\tLoss: 1.406019\n",
      "Train Epoch: 14 [64000/113287 (56%)]\tLoss: 0.889646\n",
      "Train Epoch: 14 [65280/113287 (58%)]\tLoss: 1.183887\n",
      "Train Epoch: 14 [66560/113287 (59%)]\tLoss: 1.058433\n",
      "Train Epoch: 14 [67840/113287 (60%)]\tLoss: 1.007800\n",
      "Train Epoch: 14 [69120/113287 (61%)]\tLoss: 0.946744\n",
      "Train Epoch: 14 [70400/113287 (62%)]\tLoss: 1.374501\n",
      "Train Epoch: 14 [71680/113287 (63%)]\tLoss: 0.927407\n",
      "Train Epoch: 14 [72960/113287 (64%)]\tLoss: 0.934726\n",
      "Train Epoch: 14 [74240/113287 (65%)]\tLoss: 1.195493\n",
      "Train Epoch: 14 [75520/113287 (67%)]\tLoss: 1.139472\n",
      "Train Epoch: 14 [76800/113287 (68%)]\tLoss: 0.961815\n",
      "Train Epoch: 14 [78080/113287 (69%)]\tLoss: 1.224372\n",
      "Train Epoch: 14 [79360/113287 (70%)]\tLoss: 0.895705\n",
      "Train Epoch: 14 [80640/113287 (71%)]\tLoss: 0.938742\n",
      "Train Epoch: 14 [81920/113287 (72%)]\tLoss: 1.075243\n",
      "Train Epoch: 14 [83200/113287 (73%)]\tLoss: 0.914676\n",
      "Train Epoch: 14 [84480/113287 (74%)]\tLoss: 0.978513\n",
      "Train Epoch: 14 [85760/113287 (76%)]\tLoss: 1.189091\n",
      "Train Epoch: 14 [87040/113287 (77%)]\tLoss: 1.119043\n",
      "Train Epoch: 14 [88320/113287 (78%)]\tLoss: 0.966665\n",
      "Train Epoch: 14 [89600/113287 (79%)]\tLoss: 0.977734\n",
      "Train Epoch: 14 [90880/113287 (80%)]\tLoss: 1.406810\n",
      "Train Epoch: 14 [92160/113287 (81%)]\tLoss: 0.880975\n",
      "Train Epoch: 14 [93440/113287 (82%)]\tLoss: 0.959839\n",
      "Train Epoch: 14 [94720/113287 (84%)]\tLoss: 1.168060\n",
      "Train Epoch: 14 [96000/113287 (85%)]\tLoss: 0.932246\n",
      "Train Epoch: 14 [97280/113287 (86%)]\tLoss: 1.121243\n",
      "Train Epoch: 14 [98560/113287 (87%)]\tLoss: 1.071202\n",
      "Train Epoch: 14 [99840/113287 (88%)]\tLoss: 0.993105\n",
      "Train Epoch: 14 [101120/113287 (89%)]\tLoss: 0.988288\n",
      "Train Epoch: 14 [102400/113287 (90%)]\tLoss: 1.078952\n",
      "Train Epoch: 14 [103680/113287 (91%)]\tLoss: 1.138606\n",
      "Train Epoch: 14 [104960/113287 (93%)]\tLoss: 1.042588\n",
      "Train Epoch: 14 [106240/113287 (94%)]\tLoss: 1.095557\n",
      "Train Epoch: 14 [107520/113287 (95%)]\tLoss: 1.244010\n",
      "Train Epoch: 14 [108800/113287 (96%)]\tLoss: 0.948361\n",
      "Train Epoch: 14 [110080/113287 (97%)]\tLoss: 0.937515\n",
      "Train Epoch: 14 [111360/113287 (98%)]\tLoss: 1.063140\n",
      "Train Epoch: 14 [112640/113287 (99%)]\tLoss: 1.255500\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3436/5000 (68%)\n",
      "\n",
      "Train Epoch: 15 [0/113287 (0%)]\tLoss: 1.077310\n",
      "Train Epoch: 15 [1280/113287 (1%)]\tLoss: 1.054505\n",
      "Train Epoch: 15 [2560/113287 (2%)]\tLoss: 0.951054\n",
      "Train Epoch: 15 [3840/113287 (3%)]\tLoss: 1.006505\n",
      "Train Epoch: 15 [5120/113287 (5%)]\tLoss: 0.774662\n",
      "Train Epoch: 15 [6400/113287 (6%)]\tLoss: 0.916298\n",
      "Train Epoch: 15 [7680/113287 (7%)]\tLoss: 1.116194\n",
      "Train Epoch: 15 [8960/113287 (8%)]\tLoss: 1.099972\n",
      "Train Epoch: 15 [10240/113287 (9%)]\tLoss: 1.092304\n",
      "Train Epoch: 15 [11520/113287 (10%)]\tLoss: 1.124143\n",
      "Train Epoch: 15 [12800/113287 (11%)]\tLoss: 0.953556\n",
      "Train Epoch: 15 [14080/113287 (12%)]\tLoss: 1.081237\n",
      "Train Epoch: 15 [15360/113287 (14%)]\tLoss: 1.260250\n",
      "Train Epoch: 15 [16640/113287 (15%)]\tLoss: 0.981724\n",
      "Train Epoch: 15 [17920/113287 (16%)]\tLoss: 1.062971\n",
      "Train Epoch: 15 [19200/113287 (17%)]\tLoss: 1.102026\n",
      "Train Epoch: 15 [20480/113287 (18%)]\tLoss: 1.011738\n",
      "Train Epoch: 15 [21760/113287 (19%)]\tLoss: 0.930260\n",
      "Train Epoch: 15 [23040/113287 (20%)]\tLoss: 1.201815\n",
      "Train Epoch: 15 [24320/113287 (21%)]\tLoss: 1.044707\n",
      "Train Epoch: 15 [25600/113287 (23%)]\tLoss: 1.017150\n",
      "Train Epoch: 15 [26880/113287 (24%)]\tLoss: 1.118443\n",
      "Train Epoch: 15 [28160/113287 (25%)]\tLoss: 1.191679\n",
      "Train Epoch: 15 [29440/113287 (26%)]\tLoss: 1.015166\n",
      "Train Epoch: 15 [30720/113287 (27%)]\tLoss: 1.000738\n",
      "Train Epoch: 15 [32000/113287 (28%)]\tLoss: 0.951536\n",
      "Train Epoch: 15 [33280/113287 (29%)]\tLoss: 1.115204\n",
      "Train Epoch: 15 [34560/113287 (30%)]\tLoss: 1.203895\n",
      "Train Epoch: 15 [35840/113287 (32%)]\tLoss: 0.997263\n",
      "Train Epoch: 15 [37120/113287 (33%)]\tLoss: 1.031145\n",
      "Train Epoch: 15 [38400/113287 (34%)]\tLoss: 1.191771\n",
      "Train Epoch: 15 [39680/113287 (35%)]\tLoss: 0.900615\n",
      "Train Epoch: 15 [40960/113287 (36%)]\tLoss: 1.037920\n",
      "Train Epoch: 15 [42240/113287 (37%)]\tLoss: 1.159568\n",
      "Train Epoch: 15 [43520/113287 (38%)]\tLoss: 1.050697\n",
      "Train Epoch: 15 [44800/113287 (40%)]\tLoss: 1.129894\n",
      "Train Epoch: 15 [46080/113287 (41%)]\tLoss: 0.999593\n",
      "Train Epoch: 15 [47360/113287 (42%)]\tLoss: 1.177829\n",
      "Train Epoch: 15 [48640/113287 (43%)]\tLoss: 0.850118\n",
      "Train Epoch: 15 [49920/113287 (44%)]\tLoss: 0.938538\n",
      "Train Epoch: 15 [51200/113287 (45%)]\tLoss: 1.001784\n",
      "Train Epoch: 15 [52480/113287 (46%)]\tLoss: 1.033488\n",
      "Train Epoch: 15 [53760/113287 (47%)]\tLoss: 1.034058\n",
      "Train Epoch: 15 [55040/113287 (49%)]\tLoss: 1.079081\n",
      "Train Epoch: 15 [56320/113287 (50%)]\tLoss: 0.992292\n",
      "Train Epoch: 15 [57600/113287 (51%)]\tLoss: 0.949422\n",
      "Train Epoch: 15 [58880/113287 (52%)]\tLoss: 1.110690\n",
      "Train Epoch: 15 [60160/113287 (53%)]\tLoss: 1.201973\n",
      "Train Epoch: 15 [61440/113287 (54%)]\tLoss: 0.949888\n",
      "Train Epoch: 15 [62720/113287 (55%)]\tLoss: 0.942797\n",
      "Train Epoch: 15 [64000/113287 (56%)]\tLoss: 1.005560\n",
      "Train Epoch: 15 [65280/113287 (58%)]\tLoss: 0.941322\n",
      "Train Epoch: 15 [66560/113287 (59%)]\tLoss: 1.020344\n",
      "Train Epoch: 15 [67840/113287 (60%)]\tLoss: 1.025189\n",
      "Train Epoch: 15 [69120/113287 (61%)]\tLoss: 1.033342\n",
      "Train Epoch: 15 [70400/113287 (62%)]\tLoss: 0.937653\n",
      "Train Epoch: 15 [71680/113287 (63%)]\tLoss: 1.099702\n",
      "Train Epoch: 15 [72960/113287 (64%)]\tLoss: 0.820816\n",
      "Train Epoch: 15 [74240/113287 (65%)]\tLoss: 1.113721\n",
      "Train Epoch: 15 [75520/113287 (67%)]\tLoss: 0.918708\n",
      "Train Epoch: 15 [76800/113287 (68%)]\tLoss: 0.839661\n",
      "Train Epoch: 15 [78080/113287 (69%)]\tLoss: 0.839194\n",
      "Train Epoch: 15 [79360/113287 (70%)]\tLoss: 1.109814\n",
      "Train Epoch: 15 [80640/113287 (71%)]\tLoss: 0.926054\n",
      "Train Epoch: 15 [81920/113287 (72%)]\tLoss: 1.215018\n",
      "Train Epoch: 15 [83200/113287 (73%)]\tLoss: 0.955767\n",
      "Train Epoch: 15 [84480/113287 (74%)]\tLoss: 1.091231\n",
      "Train Epoch: 15 [85760/113287 (76%)]\tLoss: 1.099363\n",
      "Train Epoch: 15 [87040/113287 (77%)]\tLoss: 1.031244\n",
      "Train Epoch: 15 [88320/113287 (78%)]\tLoss: 1.048584\n",
      "Train Epoch: 15 [89600/113287 (79%)]\tLoss: 1.138325\n",
      "Train Epoch: 15 [90880/113287 (80%)]\tLoss: 0.981987\n",
      "Train Epoch: 15 [92160/113287 (81%)]\tLoss: 1.028144\n",
      "Train Epoch: 15 [93440/113287 (82%)]\tLoss: 1.014384\n",
      "Train Epoch: 15 [94720/113287 (84%)]\tLoss: 1.077243\n",
      "Train Epoch: 15 [96000/113287 (85%)]\tLoss: 1.085979\n",
      "Train Epoch: 15 [97280/113287 (86%)]\tLoss: 0.938663\n",
      "Train Epoch: 15 [98560/113287 (87%)]\tLoss: 0.988116\n",
      "Train Epoch: 15 [99840/113287 (88%)]\tLoss: 0.964526\n",
      "Train Epoch: 15 [101120/113287 (89%)]\tLoss: 0.994125\n",
      "Train Epoch: 15 [102400/113287 (90%)]\tLoss: 1.009357\n",
      "Train Epoch: 15 [103680/113287 (91%)]\tLoss: 0.926029\n",
      "Train Epoch: 15 [104960/113287 (93%)]\tLoss: 1.050933\n",
      "Train Epoch: 15 [106240/113287 (94%)]\tLoss: 1.051172\n",
      "Train Epoch: 15 [107520/113287 (95%)]\tLoss: 1.390197\n",
      "Train Epoch: 15 [108800/113287 (96%)]\tLoss: 1.134386\n",
      "Train Epoch: 15 [110080/113287 (97%)]\tLoss: 0.857020\n",
      "Train Epoch: 15 [111360/113287 (98%)]\tLoss: 1.055721\n",
      "Train Epoch: 15 [112640/113287 (99%)]\tLoss: 1.084350\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3488/5000 (69%)\n",
      "\n",
      "Train Epoch: 16 [0/113287 (0%)]\tLoss: 1.074522\n",
      "Train Epoch: 16 [1280/113287 (1%)]\tLoss: 1.032285\n",
      "Train Epoch: 16 [2560/113287 (2%)]\tLoss: 0.856398\n",
      "Train Epoch: 16 [3840/113287 (3%)]\tLoss: 1.028731\n",
      "Train Epoch: 16 [5120/113287 (5%)]\tLoss: 1.200793\n",
      "Train Epoch: 16 [6400/113287 (6%)]\tLoss: 1.197798\n",
      "Train Epoch: 16 [7680/113287 (7%)]\tLoss: 0.837200\n",
      "Train Epoch: 16 [8960/113287 (8%)]\tLoss: 1.212227\n",
      "Train Epoch: 16 [10240/113287 (9%)]\tLoss: 1.055694\n",
      "Train Epoch: 16 [11520/113287 (10%)]\tLoss: 1.141622\n",
      "Train Epoch: 16 [12800/113287 (11%)]\tLoss: 1.190467\n",
      "Train Epoch: 16 [14080/113287 (12%)]\tLoss: 0.956784\n",
      "Train Epoch: 16 [15360/113287 (14%)]\tLoss: 1.077326\n",
      "Train Epoch: 16 [16640/113287 (15%)]\tLoss: 1.085451\n",
      "Train Epoch: 16 [17920/113287 (16%)]\tLoss: 1.246061\n",
      "Train Epoch: 16 [19200/113287 (17%)]\tLoss: 0.833327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16 [20480/113287 (18%)]\tLoss: 1.301636\n",
      "Train Epoch: 16 [21760/113287 (19%)]\tLoss: 0.989139\n",
      "Train Epoch: 16 [23040/113287 (20%)]\tLoss: 0.914741\n",
      "Train Epoch: 16 [24320/113287 (21%)]\tLoss: 1.140334\n",
      "Train Epoch: 16 [25600/113287 (23%)]\tLoss: 1.257849\n",
      "Train Epoch: 16 [26880/113287 (24%)]\tLoss: 1.294902\n",
      "Train Epoch: 16 [28160/113287 (25%)]\tLoss: 1.138742\n",
      "Train Epoch: 16 [29440/113287 (26%)]\tLoss: 0.976351\n",
      "Train Epoch: 16 [30720/113287 (27%)]\tLoss: 0.909389\n",
      "Train Epoch: 16 [32000/113287 (28%)]\tLoss: 1.063003\n",
      "Train Epoch: 16 [33280/113287 (29%)]\tLoss: 0.875193\n",
      "Train Epoch: 16 [34560/113287 (30%)]\tLoss: 1.114657\n",
      "Train Epoch: 16 [35840/113287 (32%)]\tLoss: 0.930410\n",
      "Train Epoch: 16 [37120/113287 (33%)]\tLoss: 1.082606\n",
      "Train Epoch: 16 [38400/113287 (34%)]\tLoss: 0.864552\n",
      "Train Epoch: 16 [39680/113287 (35%)]\tLoss: 1.036337\n",
      "Train Epoch: 16 [40960/113287 (36%)]\tLoss: 0.752346\n",
      "Train Epoch: 16 [42240/113287 (37%)]\tLoss: 1.055896\n",
      "Train Epoch: 16 [43520/113287 (38%)]\tLoss: 0.935428\n",
      "Train Epoch: 16 [44800/113287 (40%)]\tLoss: 1.151430\n",
      "Train Epoch: 16 [46080/113287 (41%)]\tLoss: 1.091593\n",
      "Train Epoch: 16 [47360/113287 (42%)]\tLoss: 0.816260\n",
      "Train Epoch: 16 [48640/113287 (43%)]\tLoss: 1.003426\n",
      "Train Epoch: 16 [49920/113287 (44%)]\tLoss: 1.170284\n",
      "Train Epoch: 16 [51200/113287 (45%)]\tLoss: 1.046948\n",
      "Train Epoch: 16 [52480/113287 (46%)]\tLoss: 1.043683\n",
      "Train Epoch: 16 [53760/113287 (47%)]\tLoss: 1.023967\n",
      "Train Epoch: 16 [55040/113287 (49%)]\tLoss: 1.204835\n",
      "Train Epoch: 16 [56320/113287 (50%)]\tLoss: 1.141904\n",
      "Train Epoch: 16 [57600/113287 (51%)]\tLoss: 0.844995\n",
      "Train Epoch: 16 [58880/113287 (52%)]\tLoss: 1.094540\n",
      "Train Epoch: 16 [60160/113287 (53%)]\tLoss: 1.066740\n",
      "Train Epoch: 16 [61440/113287 (54%)]\tLoss: 1.030604\n",
      "Train Epoch: 16 [62720/113287 (55%)]\tLoss: 0.958745\n",
      "Train Epoch: 16 [64000/113287 (56%)]\tLoss: 1.266736\n",
      "Train Epoch: 16 [65280/113287 (58%)]\tLoss: 0.948182\n",
      "Train Epoch: 16 [66560/113287 (59%)]\tLoss: 1.005085\n",
      "Train Epoch: 16 [67840/113287 (60%)]\tLoss: 1.075783\n",
      "Train Epoch: 16 [69120/113287 (61%)]\tLoss: 1.094689\n",
      "Train Epoch: 16 [70400/113287 (62%)]\tLoss: 1.153163\n",
      "Train Epoch: 16 [71680/113287 (63%)]\tLoss: 1.042805\n",
      "Train Epoch: 16 [72960/113287 (64%)]\tLoss: 1.358798\n",
      "Train Epoch: 16 [74240/113287 (65%)]\tLoss: 1.097298\n",
      "Train Epoch: 16 [75520/113287 (67%)]\tLoss: 1.257100\n",
      "Train Epoch: 16 [76800/113287 (68%)]\tLoss: 1.053078\n",
      "Train Epoch: 16 [78080/113287 (69%)]\tLoss: 0.897951\n",
      "Train Epoch: 16 [79360/113287 (70%)]\tLoss: 1.097234\n",
      "Train Epoch: 16 [80640/113287 (71%)]\tLoss: 1.102483\n",
      "Train Epoch: 16 [81920/113287 (72%)]\tLoss: 0.872343\n",
      "Train Epoch: 16 [83200/113287 (73%)]\tLoss: 1.146584\n",
      "Train Epoch: 16 [84480/113287 (74%)]\tLoss: 0.927383\n",
      "Train Epoch: 16 [85760/113287 (76%)]\tLoss: 1.022706\n",
      "Train Epoch: 16 [87040/113287 (77%)]\tLoss: 1.205327\n",
      "Train Epoch: 16 [88320/113287 (78%)]\tLoss: 1.015213\n",
      "Train Epoch: 16 [89600/113287 (79%)]\tLoss: 1.014257\n",
      "Train Epoch: 16 [90880/113287 (80%)]\tLoss: 0.950069\n",
      "Train Epoch: 16 [92160/113287 (81%)]\tLoss: 1.026902\n",
      "Train Epoch: 16 [93440/113287 (82%)]\tLoss: 0.788004\n",
      "Train Epoch: 16 [94720/113287 (84%)]\tLoss: 1.097143\n",
      "Train Epoch: 16 [96000/113287 (85%)]\tLoss: 1.056023\n",
      "Train Epoch: 16 [97280/113287 (86%)]\tLoss: 0.883353\n",
      "Train Epoch: 16 [98560/113287 (87%)]\tLoss: 1.254784\n",
      "Train Epoch: 16 [99840/113287 (88%)]\tLoss: 0.894283\n",
      "Train Epoch: 16 [101120/113287 (89%)]\tLoss: 1.029825\n",
      "Train Epoch: 16 [102400/113287 (90%)]\tLoss: 0.846768\n",
      "Train Epoch: 16 [103680/113287 (91%)]\tLoss: 0.854276\n",
      "Train Epoch: 16 [104960/113287 (93%)]\tLoss: 1.286075\n",
      "Train Epoch: 16 [106240/113287 (94%)]\tLoss: 1.003830\n",
      "Train Epoch: 16 [107520/113287 (95%)]\tLoss: 1.001875\n",
      "Train Epoch: 16 [108800/113287 (96%)]\tLoss: 1.011276\n",
      "Train Epoch: 16 [110080/113287 (97%)]\tLoss: 1.020475\n",
      "Train Epoch: 16 [111360/113287 (98%)]\tLoss: 0.976380\n",
      "Train Epoch: 16 [112640/113287 (99%)]\tLoss: 1.263684\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3472/5000 (69%)\n",
      "\n",
      "Train Epoch: 17 [0/113287 (0%)]\tLoss: 1.074901\n",
      "Train Epoch: 17 [1280/113287 (1%)]\tLoss: 0.963318\n",
      "Train Epoch: 17 [2560/113287 (2%)]\tLoss: 0.940601\n",
      "Train Epoch: 17 [3840/113287 (3%)]\tLoss: 1.003746\n",
      "Train Epoch: 17 [5120/113287 (5%)]\tLoss: 0.935046\n",
      "Train Epoch: 17 [6400/113287 (6%)]\tLoss: 1.035414\n",
      "Train Epoch: 17 [7680/113287 (7%)]\tLoss: 0.938283\n",
      "Train Epoch: 17 [8960/113287 (8%)]\tLoss: 1.097399\n",
      "Train Epoch: 17 [10240/113287 (9%)]\tLoss: 1.178322\n",
      "Train Epoch: 17 [11520/113287 (10%)]\tLoss: 0.908641\n",
      "Train Epoch: 17 [12800/113287 (11%)]\tLoss: 0.912085\n",
      "Train Epoch: 17 [14080/113287 (12%)]\tLoss: 0.994621\n",
      "Train Epoch: 17 [15360/113287 (14%)]\tLoss: 1.053839\n",
      "Train Epoch: 17 [16640/113287 (15%)]\tLoss: 1.024023\n",
      "Train Epoch: 17 [17920/113287 (16%)]\tLoss: 0.901065\n",
      "Train Epoch: 17 [19200/113287 (17%)]\tLoss: 1.070748\n",
      "Train Epoch: 17 [20480/113287 (18%)]\tLoss: 0.990304\n",
      "Train Epoch: 17 [21760/113287 (19%)]\tLoss: 0.998229\n",
      "Train Epoch: 17 [23040/113287 (20%)]\tLoss: 0.941545\n",
      "Train Epoch: 17 [24320/113287 (21%)]\tLoss: 1.103848\n",
      "Train Epoch: 17 [25600/113287 (23%)]\tLoss: 1.095317\n",
      "Train Epoch: 17 [26880/113287 (24%)]\tLoss: 0.845573\n",
      "Train Epoch: 17 [28160/113287 (25%)]\tLoss: 1.262290\n",
      "Train Epoch: 17 [29440/113287 (26%)]\tLoss: 0.984398\n",
      "Train Epoch: 17 [30720/113287 (27%)]\tLoss: 1.083601\n",
      "Train Epoch: 17 [32000/113287 (28%)]\tLoss: 0.913921\n",
      "Train Epoch: 17 [33280/113287 (29%)]\tLoss: 0.988692\n",
      "Train Epoch: 17 [34560/113287 (30%)]\tLoss: 1.041731\n",
      "Train Epoch: 17 [35840/113287 (32%)]\tLoss: 1.072958\n",
      "Train Epoch: 17 [37120/113287 (33%)]\tLoss: 0.700229\n",
      "Train Epoch: 17 [38400/113287 (34%)]\tLoss: 0.996852\n",
      "Train Epoch: 17 [39680/113287 (35%)]\tLoss: 0.701863\n",
      "Train Epoch: 17 [40960/113287 (36%)]\tLoss: 1.018196\n",
      "Train Epoch: 17 [42240/113287 (37%)]\tLoss: 1.134631\n",
      "Train Epoch: 17 [43520/113287 (38%)]\tLoss: 1.029636\n",
      "Train Epoch: 17 [44800/113287 (40%)]\tLoss: 1.099870\n",
      "Train Epoch: 17 [46080/113287 (41%)]\tLoss: 0.981027\n",
      "Train Epoch: 17 [47360/113287 (42%)]\tLoss: 1.017751\n",
      "Train Epoch: 17 [48640/113287 (43%)]\tLoss: 0.925036\n",
      "Train Epoch: 17 [49920/113287 (44%)]\tLoss: 1.122594\n",
      "Train Epoch: 17 [51200/113287 (45%)]\tLoss: 0.988335\n",
      "Train Epoch: 17 [52480/113287 (46%)]\tLoss: 0.725406\n",
      "Train Epoch: 17 [53760/113287 (47%)]\tLoss: 1.052158\n",
      "Train Epoch: 17 [55040/113287 (49%)]\tLoss: 1.056510\n",
      "Train Epoch: 17 [56320/113287 (50%)]\tLoss: 1.304525\n",
      "Train Epoch: 17 [57600/113287 (51%)]\tLoss: 1.156321\n",
      "Train Epoch: 17 [58880/113287 (52%)]\tLoss: 0.976032\n",
      "Train Epoch: 17 [60160/113287 (53%)]\tLoss: 1.018474\n",
      "Train Epoch: 17 [61440/113287 (54%)]\tLoss: 0.981718\n",
      "Train Epoch: 17 [62720/113287 (55%)]\tLoss: 0.990688\n",
      "Train Epoch: 17 [64000/113287 (56%)]\tLoss: 1.096853\n",
      "Train Epoch: 17 [65280/113287 (58%)]\tLoss: 0.808388\n",
      "Train Epoch: 17 [66560/113287 (59%)]\tLoss: 1.166870\n",
      "Train Epoch: 17 [67840/113287 (60%)]\tLoss: 0.819828\n",
      "Train Epoch: 17 [69120/113287 (61%)]\tLoss: 1.180315\n",
      "Train Epoch: 17 [70400/113287 (62%)]\tLoss: 1.163938\n",
      "Train Epoch: 17 [71680/113287 (63%)]\tLoss: 1.065247\n",
      "Train Epoch: 17 [72960/113287 (64%)]\tLoss: 1.106679\n",
      "Train Epoch: 17 [74240/113287 (65%)]\tLoss: 1.179138\n",
      "Train Epoch: 17 [75520/113287 (67%)]\tLoss: 0.921840\n",
      "Train Epoch: 17 [76800/113287 (68%)]\tLoss: 0.986938\n",
      "Train Epoch: 17 [78080/113287 (69%)]\tLoss: 0.987536\n",
      "Train Epoch: 17 [79360/113287 (70%)]\tLoss: 1.251978\n",
      "Train Epoch: 17 [80640/113287 (71%)]\tLoss: 1.089475\n",
      "Train Epoch: 17 [81920/113287 (72%)]\tLoss: 0.923120\n",
      "Train Epoch: 17 [83200/113287 (73%)]\tLoss: 1.295978\n",
      "Train Epoch: 17 [84480/113287 (74%)]\tLoss: 1.243504\n",
      "Train Epoch: 17 [85760/113287 (76%)]\tLoss: 1.312937\n",
      "Train Epoch: 17 [87040/113287 (77%)]\tLoss: 0.816218\n",
      "Train Epoch: 17 [88320/113287 (78%)]\tLoss: 0.978367\n",
      "Train Epoch: 17 [89600/113287 (79%)]\tLoss: 1.037756\n",
      "Train Epoch: 17 [90880/113287 (80%)]\tLoss: 1.057493\n",
      "Train Epoch: 17 [92160/113287 (81%)]\tLoss: 1.005024\n",
      "Train Epoch: 17 [93440/113287 (82%)]\tLoss: 0.884456\n",
      "Train Epoch: 17 [94720/113287 (84%)]\tLoss: 0.939401\n",
      "Train Epoch: 17 [96000/113287 (85%)]\tLoss: 0.732187\n",
      "Train Epoch: 17 [97280/113287 (86%)]\tLoss: 1.057462\n",
      "Train Epoch: 17 [98560/113287 (87%)]\tLoss: 0.952038\n",
      "Train Epoch: 17 [99840/113287 (88%)]\tLoss: 1.211626\n",
      "Train Epoch: 17 [101120/113287 (89%)]\tLoss: 0.717540\n",
      "Train Epoch: 17 [102400/113287 (90%)]\tLoss: 0.847283\n",
      "Train Epoch: 17 [103680/113287 (91%)]\tLoss: 1.054425\n",
      "Train Epoch: 17 [104960/113287 (93%)]\tLoss: 0.906702\n",
      "Train Epoch: 17 [106240/113287 (94%)]\tLoss: 0.888749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 [107520/113287 (95%)]\tLoss: 1.101048\n",
      "Train Epoch: 17 [108800/113287 (96%)]\tLoss: 0.932613\n",
      "Train Epoch: 17 [110080/113287 (97%)]\tLoss: 1.034218\n",
      "Train Epoch: 17 [111360/113287 (98%)]\tLoss: 0.975955\n",
      "Train Epoch: 17 [112640/113287 (99%)]\tLoss: 1.204316\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3492/5000 (69%)\n",
      "\n",
      "Train Epoch: 18 [0/113287 (0%)]\tLoss: 1.282207\n",
      "Train Epoch: 18 [1280/113287 (1%)]\tLoss: 1.010882\n",
      "Train Epoch: 18 [2560/113287 (2%)]\tLoss: 1.000585\n",
      "Train Epoch: 18 [3840/113287 (3%)]\tLoss: 1.045050\n",
      "Train Epoch: 18 [5120/113287 (5%)]\tLoss: 0.916038\n",
      "Train Epoch: 18 [6400/113287 (6%)]\tLoss: 1.044769\n",
      "Train Epoch: 18 [7680/113287 (7%)]\tLoss: 1.018606\n",
      "Train Epoch: 18 [8960/113287 (8%)]\tLoss: 1.173097\n",
      "Train Epoch: 18 [10240/113287 (9%)]\tLoss: 1.209436\n",
      "Train Epoch: 18 [11520/113287 (10%)]\tLoss: 1.121278\n",
      "Train Epoch: 18 [12800/113287 (11%)]\tLoss: 1.148715\n",
      "Train Epoch: 18 [14080/113287 (12%)]\tLoss: 0.964428\n",
      "Train Epoch: 18 [15360/113287 (14%)]\tLoss: 1.275099\n",
      "Train Epoch: 18 [16640/113287 (15%)]\tLoss: 0.863195\n",
      "Train Epoch: 18 [17920/113287 (16%)]\tLoss: 1.085490\n",
      "Train Epoch: 18 [19200/113287 (17%)]\tLoss: 0.905750\n",
      "Train Epoch: 18 [20480/113287 (18%)]\tLoss: 0.979568\n",
      "Train Epoch: 18 [21760/113287 (19%)]\tLoss: 1.162682\n",
      "Train Epoch: 18 [23040/113287 (20%)]\tLoss: 1.142182\n",
      "Train Epoch: 18 [24320/113287 (21%)]\tLoss: 0.934869\n",
      "Train Epoch: 18 [25600/113287 (23%)]\tLoss: 1.134505\n",
      "Train Epoch: 18 [26880/113287 (24%)]\tLoss: 1.016433\n",
      "Train Epoch: 18 [28160/113287 (25%)]\tLoss: 1.091467\n",
      "Train Epoch: 18 [29440/113287 (26%)]\tLoss: 1.115880\n",
      "Train Epoch: 18 [30720/113287 (27%)]\tLoss: 1.384124\n",
      "Train Epoch: 18 [32000/113287 (28%)]\tLoss: 0.667970\n",
      "Train Epoch: 18 [33280/113287 (29%)]\tLoss: 0.952646\n",
      "Train Epoch: 18 [34560/113287 (30%)]\tLoss: 0.742578\n",
      "Train Epoch: 18 [35840/113287 (32%)]\tLoss: 0.902759\n",
      "Train Epoch: 18 [37120/113287 (33%)]\tLoss: 0.918619\n",
      "Train Epoch: 18 [38400/113287 (34%)]\tLoss: 0.955167\n",
      "Train Epoch: 18 [39680/113287 (35%)]\tLoss: 1.261102\n",
      "Train Epoch: 18 [40960/113287 (36%)]\tLoss: 0.960539\n",
      "Train Epoch: 18 [42240/113287 (37%)]\tLoss: 0.859944\n",
      "Train Epoch: 18 [43520/113287 (38%)]\tLoss: 0.877055\n",
      "Train Epoch: 18 [44800/113287 (40%)]\tLoss: 0.900418\n",
      "Train Epoch: 18 [46080/113287 (41%)]\tLoss: 0.978638\n",
      "Train Epoch: 18 [47360/113287 (42%)]\tLoss: 0.948974\n",
      "Train Epoch: 18 [48640/113287 (43%)]\tLoss: 0.871322\n",
      "Train Epoch: 18 [49920/113287 (44%)]\tLoss: 0.824941\n",
      "Train Epoch: 18 [51200/113287 (45%)]\tLoss: 0.999477\n",
      "Train Epoch: 18 [52480/113287 (46%)]\tLoss: 0.720964\n",
      "Train Epoch: 18 [53760/113287 (47%)]\tLoss: 0.881840\n",
      "Train Epoch: 18 [55040/113287 (49%)]\tLoss: 0.908158\n",
      "Train Epoch: 18 [56320/113287 (50%)]\tLoss: 0.932430\n",
      "Train Epoch: 18 [57600/113287 (51%)]\tLoss: 0.997275\n",
      "Train Epoch: 18 [58880/113287 (52%)]\tLoss: 0.979495\n",
      "Train Epoch: 18 [60160/113287 (53%)]\tLoss: 0.921173\n",
      "Train Epoch: 18 [61440/113287 (54%)]\tLoss: 1.153803\n",
      "Train Epoch: 18 [62720/113287 (55%)]\tLoss: 1.049739\n",
      "Train Epoch: 18 [64000/113287 (56%)]\tLoss: 0.956109\n",
      "Train Epoch: 18 [65280/113287 (58%)]\tLoss: 0.936933\n",
      "Train Epoch: 18 [66560/113287 (59%)]\tLoss: 0.938461\n",
      "Train Epoch: 18 [67840/113287 (60%)]\tLoss: 1.063477\n",
      "Train Epoch: 18 [69120/113287 (61%)]\tLoss: 0.837088\n",
      "Train Epoch: 18 [70400/113287 (62%)]\tLoss: 0.911318\n",
      "Train Epoch: 18 [71680/113287 (63%)]\tLoss: 1.175707\n",
      "Train Epoch: 18 [72960/113287 (64%)]\tLoss: 0.979204\n",
      "Train Epoch: 18 [74240/113287 (65%)]\tLoss: 0.985004\n",
      "Train Epoch: 18 [75520/113287 (67%)]\tLoss: 1.113544\n",
      "Train Epoch: 18 [76800/113287 (68%)]\tLoss: 0.989386\n",
      "Train Epoch: 18 [78080/113287 (69%)]\tLoss: 0.836685\n",
      "Train Epoch: 18 [79360/113287 (70%)]\tLoss: 1.097556\n",
      "Train Epoch: 18 [80640/113287 (71%)]\tLoss: 0.909429\n",
      "Train Epoch: 18 [81920/113287 (72%)]\tLoss: 1.024995\n",
      "Train Epoch: 18 [83200/113287 (73%)]\tLoss: 0.968218\n",
      "Train Epoch: 18 [84480/113287 (74%)]\tLoss: 1.157431\n",
      "Train Epoch: 18 [85760/113287 (76%)]\tLoss: 1.025061\n",
      "Train Epoch: 18 [87040/113287 (77%)]\tLoss: 1.007810\n",
      "Train Epoch: 18 [88320/113287 (78%)]\tLoss: 0.854795\n",
      "Train Epoch: 18 [89600/113287 (79%)]\tLoss: 0.861045\n",
      "Train Epoch: 18 [90880/113287 (80%)]\tLoss: 0.901597\n",
      "Train Epoch: 18 [92160/113287 (81%)]\tLoss: 0.993812\n",
      "Train Epoch: 18 [93440/113287 (82%)]\tLoss: 1.189386\n",
      "Train Epoch: 18 [94720/113287 (84%)]\tLoss: 1.148032\n",
      "Train Epoch: 18 [96000/113287 (85%)]\tLoss: 1.187755\n",
      "Train Epoch: 18 [97280/113287 (86%)]\tLoss: 0.878946\n",
      "Train Epoch: 18 [98560/113287 (87%)]\tLoss: 1.067049\n",
      "Train Epoch: 18 [99840/113287 (88%)]\tLoss: 1.284954\n",
      "Train Epoch: 18 [101120/113287 (89%)]\tLoss: 0.925781\n",
      "Train Epoch: 18 [102400/113287 (90%)]\tLoss: 0.867891\n",
      "Train Epoch: 18 [103680/113287 (91%)]\tLoss: 0.960406\n",
      "Train Epoch: 18 [104960/113287 (93%)]\tLoss: 0.810387\n",
      "Train Epoch: 18 [106240/113287 (94%)]\tLoss: 0.886727\n",
      "Train Epoch: 18 [107520/113287 (95%)]\tLoss: 1.092594\n",
      "Train Epoch: 18 [108800/113287 (96%)]\tLoss: 0.841108\n",
      "Train Epoch: 18 [110080/113287 (97%)]\tLoss: 0.938297\n",
      "Train Epoch: 18 [111360/113287 (98%)]\tLoss: 0.990968\n",
      "Train Epoch: 18 [112640/113287 (99%)]\tLoss: 1.146058\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3521/5000 (70%)\n",
      "\n",
      "Train Epoch: 19 [0/113287 (0%)]\tLoss: 0.981860\n",
      "Train Epoch: 19 [1280/113287 (1%)]\tLoss: 1.034888\n",
      "Train Epoch: 19 [2560/113287 (2%)]\tLoss: 1.010387\n",
      "Train Epoch: 19 [3840/113287 (3%)]\tLoss: 1.110663\n",
      "Train Epoch: 19 [5120/113287 (5%)]\tLoss: 0.905006\n",
      "Train Epoch: 19 [6400/113287 (6%)]\tLoss: 0.748717\n",
      "Train Epoch: 19 [7680/113287 (7%)]\tLoss: 0.975566\n",
      "Train Epoch: 19 [8960/113287 (8%)]\tLoss: 1.240367\n",
      "Train Epoch: 19 [10240/113287 (9%)]\tLoss: 0.889600\n",
      "Train Epoch: 19 [11520/113287 (10%)]\tLoss: 0.987842\n",
      "Train Epoch: 19 [12800/113287 (11%)]\tLoss: 0.963936\n",
      "Train Epoch: 19 [14080/113287 (12%)]\tLoss: 0.918976\n",
      "Train Epoch: 19 [15360/113287 (14%)]\tLoss: 0.885729\n",
      "Train Epoch: 19 [16640/113287 (15%)]\tLoss: 0.961282\n",
      "Train Epoch: 19 [17920/113287 (16%)]\tLoss: 1.140345\n",
      "Train Epoch: 19 [19200/113287 (17%)]\tLoss: 0.916951\n",
      "Train Epoch: 19 [20480/113287 (18%)]\tLoss: 1.228719\n",
      "Train Epoch: 19 [21760/113287 (19%)]\tLoss: 0.923765\n",
      "Train Epoch: 19 [23040/113287 (20%)]\tLoss: 1.088667\n",
      "Train Epoch: 19 [24320/113287 (21%)]\tLoss: 1.037952\n",
      "Train Epoch: 19 [25600/113287 (23%)]\tLoss: 1.282098\n",
      "Train Epoch: 19 [26880/113287 (24%)]\tLoss: 1.021683\n",
      "Train Epoch: 19 [28160/113287 (25%)]\tLoss: 1.297792\n",
      "Train Epoch: 19 [29440/113287 (26%)]\tLoss: 0.835909\n",
      "Train Epoch: 19 [30720/113287 (27%)]\tLoss: 0.822111\n",
      "Train Epoch: 19 [32000/113287 (28%)]\tLoss: 0.956633\n",
      "Train Epoch: 19 [33280/113287 (29%)]\tLoss: 0.831117\n",
      "Train Epoch: 19 [34560/113287 (30%)]\tLoss: 0.946032\n",
      "Train Epoch: 19 [35840/113287 (32%)]\tLoss: 1.043479\n",
      "Train Epoch: 19 [37120/113287 (33%)]\tLoss: 0.885700\n",
      "Train Epoch: 19 [38400/113287 (34%)]\tLoss: 1.218909\n",
      "Train Epoch: 19 [39680/113287 (35%)]\tLoss: 1.270541\n",
      "Train Epoch: 19 [40960/113287 (36%)]\tLoss: 1.072489\n",
      "Train Epoch: 19 [42240/113287 (37%)]\tLoss: 0.723144\n",
      "Train Epoch: 19 [43520/113287 (38%)]\tLoss: 0.972607\n",
      "Train Epoch: 19 [44800/113287 (40%)]\tLoss: 1.284614\n",
      "Train Epoch: 19 [46080/113287 (41%)]\tLoss: 1.098870\n",
      "Train Epoch: 19 [47360/113287 (42%)]\tLoss: 0.951825\n",
      "Train Epoch: 19 [48640/113287 (43%)]\tLoss: 0.878064\n",
      "Train Epoch: 19 [49920/113287 (44%)]\tLoss: 0.888965\n",
      "Train Epoch: 19 [51200/113287 (45%)]\tLoss: 1.103026\n",
      "Train Epoch: 19 [52480/113287 (46%)]\tLoss: 0.903255\n",
      "Train Epoch: 19 [53760/113287 (47%)]\tLoss: 1.084950\n",
      "Train Epoch: 19 [55040/113287 (49%)]\tLoss: 0.879656\n",
      "Train Epoch: 19 [56320/113287 (50%)]\tLoss: 1.066788\n",
      "Train Epoch: 19 [57600/113287 (51%)]\tLoss: 1.049014\n",
      "Train Epoch: 19 [58880/113287 (52%)]\tLoss: 1.151205\n",
      "Train Epoch: 19 [60160/113287 (53%)]\tLoss: 1.066158\n",
      "Train Epoch: 19 [61440/113287 (54%)]\tLoss: 1.054757\n",
      "Train Epoch: 19 [62720/113287 (55%)]\tLoss: 0.810094\n",
      "Train Epoch: 19 [64000/113287 (56%)]\tLoss: 0.959187\n",
      "Train Epoch: 19 [65280/113287 (58%)]\tLoss: 1.031858\n",
      "Train Epoch: 19 [66560/113287 (59%)]\tLoss: 1.041641\n",
      "Train Epoch: 19 [67840/113287 (60%)]\tLoss: 1.215728\n",
      "Train Epoch: 19 [69120/113287 (61%)]\tLoss: 1.032463\n",
      "Train Epoch: 19 [70400/113287 (62%)]\tLoss: 1.117182\n",
      "Train Epoch: 19 [71680/113287 (63%)]\tLoss: 0.814211\n",
      "Train Epoch: 19 [72960/113287 (64%)]\tLoss: 0.960398\n",
      "Train Epoch: 19 [74240/113287 (65%)]\tLoss: 1.038829\n",
      "Train Epoch: 19 [75520/113287 (67%)]\tLoss: 0.907401\n",
      "Train Epoch: 19 [76800/113287 (68%)]\tLoss: 0.955016\n",
      "Train Epoch: 19 [78080/113287 (69%)]\tLoss: 1.100164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 [79360/113287 (70%)]\tLoss: 1.150311\n",
      "Train Epoch: 19 [80640/113287 (71%)]\tLoss: 0.982299\n",
      "Train Epoch: 19 [81920/113287 (72%)]\tLoss: 0.892873\n",
      "Train Epoch: 19 [83200/113287 (73%)]\tLoss: 1.056179\n",
      "Train Epoch: 19 [84480/113287 (74%)]\tLoss: 0.963168\n",
      "Train Epoch: 19 [85760/113287 (76%)]\tLoss: 1.084064\n",
      "Train Epoch: 19 [87040/113287 (77%)]\tLoss: 1.319014\n",
      "Train Epoch: 19 [88320/113287 (78%)]\tLoss: 0.902393\n",
      "Train Epoch: 19 [89600/113287 (79%)]\tLoss: 0.885304\n",
      "Train Epoch: 19 [90880/113287 (80%)]\tLoss: 1.077088\n",
      "Train Epoch: 19 [92160/113287 (81%)]\tLoss: 0.946168\n",
      "Train Epoch: 19 [93440/113287 (82%)]\tLoss: 1.013409\n",
      "Train Epoch: 19 [94720/113287 (84%)]\tLoss: 1.042600\n",
      "Train Epoch: 19 [96000/113287 (85%)]\tLoss: 1.044923\n",
      "Train Epoch: 19 [97280/113287 (86%)]\tLoss: 0.993628\n",
      "Train Epoch: 19 [98560/113287 (87%)]\tLoss: 0.899329\n",
      "Train Epoch: 19 [99840/113287 (88%)]\tLoss: 0.965797\n",
      "Train Epoch: 19 [101120/113287 (89%)]\tLoss: 0.934565\n",
      "Train Epoch: 19 [102400/113287 (90%)]\tLoss: 0.981143\n",
      "Train Epoch: 19 [103680/113287 (91%)]\tLoss: 0.984428\n",
      "Train Epoch: 19 [104960/113287 (93%)]\tLoss: 1.038445\n",
      "Train Epoch: 19 [106240/113287 (94%)]\tLoss: 0.986755\n",
      "Train Epoch: 19 [107520/113287 (95%)]\tLoss: 0.929576\n",
      "Train Epoch: 19 [108800/113287 (96%)]\tLoss: 0.858810\n",
      "Train Epoch: 19 [110080/113287 (97%)]\tLoss: 1.132307\n",
      "Train Epoch: 19 [111360/113287 (98%)]\tLoss: 1.155518\n",
      "Train Epoch: 19 [112640/113287 (99%)]\tLoss: 0.972243\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3511/5000 (70%)\n",
      "\n",
      "Train Epoch: 20 [0/113287 (0%)]\tLoss: 1.081424\n",
      "Train Epoch: 20 [1280/113287 (1%)]\tLoss: 1.197415\n",
      "Train Epoch: 20 [2560/113287 (2%)]\tLoss: 0.793418\n",
      "Train Epoch: 20 [3840/113287 (3%)]\tLoss: 1.005577\n",
      "Train Epoch: 20 [5120/113287 (5%)]\tLoss: 1.026235\n",
      "Train Epoch: 20 [6400/113287 (6%)]\tLoss: 0.947886\n",
      "Train Epoch: 20 [7680/113287 (7%)]\tLoss: 0.654416\n",
      "Train Epoch: 20 [8960/113287 (8%)]\tLoss: 0.807638\n",
      "Train Epoch: 20 [10240/113287 (9%)]\tLoss: 0.880325\n",
      "Train Epoch: 20 [11520/113287 (10%)]\tLoss: 1.121932\n",
      "Train Epoch: 20 [12800/113287 (11%)]\tLoss: 0.857543\n",
      "Train Epoch: 20 [14080/113287 (12%)]\tLoss: 1.206174\n",
      "Train Epoch: 20 [15360/113287 (14%)]\tLoss: 0.820401\n",
      "Train Epoch: 20 [16640/113287 (15%)]\tLoss: 1.153635\n",
      "Train Epoch: 20 [17920/113287 (16%)]\tLoss: 1.058055\n",
      "Train Epoch: 20 [19200/113287 (17%)]\tLoss: 1.039607\n",
      "Train Epoch: 20 [20480/113287 (18%)]\tLoss: 1.109368\n",
      "Train Epoch: 20 [21760/113287 (19%)]\tLoss: 0.887260\n",
      "Train Epoch: 20 [23040/113287 (20%)]\tLoss: 1.263941\n",
      "Train Epoch: 20 [24320/113287 (21%)]\tLoss: 0.950496\n",
      "Train Epoch: 20 [25600/113287 (23%)]\tLoss: 0.893910\n",
      "Train Epoch: 20 [26880/113287 (24%)]\tLoss: 0.883964\n",
      "Train Epoch: 20 [28160/113287 (25%)]\tLoss: 1.034095\n",
      "Train Epoch: 20 [29440/113287 (26%)]\tLoss: 1.218946\n",
      "Train Epoch: 20 [30720/113287 (27%)]\tLoss: 1.171396\n",
      "Train Epoch: 20 [32000/113287 (28%)]\tLoss: 0.924905\n",
      "Train Epoch: 20 [33280/113287 (29%)]\tLoss: 1.128122\n",
      "Train Epoch: 20 [34560/113287 (30%)]\tLoss: 0.929474\n",
      "Train Epoch: 20 [35840/113287 (32%)]\tLoss: 1.121148\n",
      "Train Epoch: 20 [37120/113287 (33%)]\tLoss: 1.084183\n",
      "Train Epoch: 20 [38400/113287 (34%)]\tLoss: 0.932095\n",
      "Train Epoch: 20 [39680/113287 (35%)]\tLoss: 1.001301\n",
      "Train Epoch: 20 [40960/113287 (36%)]\tLoss: 0.893529\n",
      "Train Epoch: 20 [42240/113287 (37%)]\tLoss: 1.200146\n",
      "Train Epoch: 20 [43520/113287 (38%)]\tLoss: 1.132671\n",
      "Train Epoch: 20 [44800/113287 (40%)]\tLoss: 1.140722\n",
      "Train Epoch: 20 [46080/113287 (41%)]\tLoss: 1.201885\n",
      "Train Epoch: 20 [47360/113287 (42%)]\tLoss: 0.945934\n",
      "Train Epoch: 20 [48640/113287 (43%)]\tLoss: 0.908330\n",
      "Train Epoch: 20 [49920/113287 (44%)]\tLoss: 1.212612\n",
      "Train Epoch: 20 [51200/113287 (45%)]\tLoss: 0.923426\n",
      "Train Epoch: 20 [52480/113287 (46%)]\tLoss: 1.089991\n",
      "Train Epoch: 20 [53760/113287 (47%)]\tLoss: 1.072819\n",
      "Train Epoch: 20 [55040/113287 (49%)]\tLoss: 1.315015\n",
      "Train Epoch: 20 [56320/113287 (50%)]\tLoss: 1.224005\n",
      "Train Epoch: 20 [57600/113287 (51%)]\tLoss: 0.925186\n",
      "Train Epoch: 20 [58880/113287 (52%)]\tLoss: 1.113559\n",
      "Train Epoch: 20 [60160/113287 (53%)]\tLoss: 1.278648\n",
      "Train Epoch: 20 [61440/113287 (54%)]\tLoss: 1.020093\n",
      "Train Epoch: 20 [62720/113287 (55%)]\tLoss: 0.921920\n",
      "Train Epoch: 20 [64000/113287 (56%)]\tLoss: 0.890000\n",
      "Train Epoch: 20 [65280/113287 (58%)]\tLoss: 1.006070\n",
      "Train Epoch: 20 [66560/113287 (59%)]\tLoss: 0.974388\n",
      "Train Epoch: 20 [67840/113287 (60%)]\tLoss: 1.145500\n",
      "Train Epoch: 20 [69120/113287 (61%)]\tLoss: 1.064638\n",
      "Train Epoch: 20 [70400/113287 (62%)]\tLoss: 1.010942\n",
      "Train Epoch: 20 [71680/113287 (63%)]\tLoss: 0.924664\n",
      "Train Epoch: 20 [72960/113287 (64%)]\tLoss: 0.889386\n",
      "Train Epoch: 20 [74240/113287 (65%)]\tLoss: 0.952056\n",
      "Train Epoch: 20 [75520/113287 (67%)]\tLoss: 0.988187\n",
      "Train Epoch: 20 [76800/113287 (68%)]\tLoss: 1.109201\n",
      "Train Epoch: 20 [78080/113287 (69%)]\tLoss: 1.219657\n",
      "Train Epoch: 20 [79360/113287 (70%)]\tLoss: 0.687392\n",
      "Train Epoch: 20 [80640/113287 (71%)]\tLoss: 1.220652\n",
      "Train Epoch: 20 [81920/113287 (72%)]\tLoss: 1.035592\n",
      "Train Epoch: 20 [83200/113287 (73%)]\tLoss: 1.024634\n",
      "Train Epoch: 20 [84480/113287 (74%)]\tLoss: 0.936702\n",
      "Train Epoch: 20 [85760/113287 (76%)]\tLoss: 1.081325\n",
      "Train Epoch: 20 [87040/113287 (77%)]\tLoss: 0.915680\n",
      "Train Epoch: 20 [88320/113287 (78%)]\tLoss: 1.037215\n",
      "Train Epoch: 20 [89600/113287 (79%)]\tLoss: 1.094992\n",
      "Train Epoch: 20 [90880/113287 (80%)]\tLoss: 0.933779\n",
      "Train Epoch: 20 [92160/113287 (81%)]\tLoss: 0.862619\n",
      "Train Epoch: 20 [93440/113287 (82%)]\tLoss: 1.036432\n",
      "Train Epoch: 20 [94720/113287 (84%)]\tLoss: 0.689101\n",
      "Train Epoch: 20 [96000/113287 (85%)]\tLoss: 1.085500\n",
      "Train Epoch: 20 [97280/113287 (86%)]\tLoss: 1.008623\n",
      "Train Epoch: 20 [98560/113287 (87%)]\tLoss: 1.097338\n",
      "Train Epoch: 20 [99840/113287 (88%)]\tLoss: 1.036291\n",
      "Train Epoch: 20 [101120/113287 (89%)]\tLoss: 0.979429\n",
      "Train Epoch: 20 [102400/113287 (90%)]\tLoss: 0.947688\n",
      "Train Epoch: 20 [103680/113287 (91%)]\tLoss: 1.045929\n",
      "Train Epoch: 20 [104960/113287 (93%)]\tLoss: 1.156540\n",
      "Train Epoch: 20 [106240/113287 (94%)]\tLoss: 1.083588\n",
      "Train Epoch: 20 [107520/113287 (95%)]\tLoss: 1.019604\n",
      "Train Epoch: 20 [108800/113287 (96%)]\tLoss: 1.064536\n",
      "Train Epoch: 20 [110080/113287 (97%)]\tLoss: 0.867854\n",
      "Train Epoch: 20 [111360/113287 (98%)]\tLoss: 1.081559\n",
      "Train Epoch: 20 [112640/113287 (99%)]\tLoss: 1.008442\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3498/5000 (69%)\n",
      "\n",
      "Train Epoch: 21 [0/113287 (0%)]\tLoss: 0.905115\n",
      "Train Epoch: 21 [1280/113287 (1%)]\tLoss: 1.050489\n",
      "Train Epoch: 21 [2560/113287 (2%)]\tLoss: 1.128945\n",
      "Train Epoch: 21 [3840/113287 (3%)]\tLoss: 1.180783\n",
      "Train Epoch: 21 [5120/113287 (5%)]\tLoss: 1.017025\n",
      "Train Epoch: 21 [6400/113287 (6%)]\tLoss: 1.094076\n",
      "Train Epoch: 21 [7680/113287 (7%)]\tLoss: 1.034847\n",
      "Train Epoch: 21 [8960/113287 (8%)]\tLoss: 0.987670\n",
      "Train Epoch: 21 [10240/113287 (9%)]\tLoss: 0.982729\n",
      "Train Epoch: 21 [11520/113287 (10%)]\tLoss: 1.127699\n",
      "Train Epoch: 21 [12800/113287 (11%)]\tLoss: 0.989313\n",
      "Train Epoch: 21 [14080/113287 (12%)]\tLoss: 1.083225\n",
      "Train Epoch: 21 [15360/113287 (14%)]\tLoss: 0.980603\n",
      "Train Epoch: 21 [16640/113287 (15%)]\tLoss: 1.173604\n",
      "Train Epoch: 21 [17920/113287 (16%)]\tLoss: 0.909594\n",
      "Train Epoch: 21 [19200/113287 (17%)]\tLoss: 1.067524\n",
      "Train Epoch: 21 [20480/113287 (18%)]\tLoss: 0.972166\n",
      "Train Epoch: 21 [21760/113287 (19%)]\tLoss: 1.062747\n",
      "Train Epoch: 21 [23040/113287 (20%)]\tLoss: 1.003818\n",
      "Train Epoch: 21 [24320/113287 (21%)]\tLoss: 0.952173\n",
      "Train Epoch: 21 [25600/113287 (23%)]\tLoss: 0.952664\n",
      "Train Epoch: 21 [26880/113287 (24%)]\tLoss: 1.035430\n",
      "Train Epoch: 21 [28160/113287 (25%)]\tLoss: 1.147386\n",
      "Train Epoch: 21 [29440/113287 (26%)]\tLoss: 0.892186\n",
      "Train Epoch: 21 [30720/113287 (27%)]\tLoss: 0.793259\n",
      "Train Epoch: 21 [32000/113287 (28%)]\tLoss: 1.260503\n",
      "Train Epoch: 21 [33280/113287 (29%)]\tLoss: 1.004783\n",
      "Train Epoch: 21 [34560/113287 (30%)]\tLoss: 1.005198\n",
      "Train Epoch: 21 [35840/113287 (32%)]\tLoss: 1.057351\n",
      "Train Epoch: 21 [37120/113287 (33%)]\tLoss: 1.024022\n",
      "Train Epoch: 21 [38400/113287 (34%)]\tLoss: 1.212139\n",
      "Train Epoch: 21 [39680/113287 (35%)]\tLoss: 0.978758\n",
      "Train Epoch: 21 [40960/113287 (36%)]\tLoss: 0.915202\n",
      "Train Epoch: 21 [42240/113287 (37%)]\tLoss: 0.795519\n",
      "Train Epoch: 21 [43520/113287 (38%)]\tLoss: 0.926914\n",
      "Train Epoch: 21 [44800/113287 (40%)]\tLoss: 1.148337\n",
      "Train Epoch: 21 [46080/113287 (41%)]\tLoss: 1.018796\n",
      "Train Epoch: 21 [47360/113287 (42%)]\tLoss: 0.902084\n",
      "Train Epoch: 21 [48640/113287 (43%)]\tLoss: 0.945948\n",
      "Train Epoch: 21 [49920/113287 (44%)]\tLoss: 1.123756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21 [51200/113287 (45%)]\tLoss: 0.880237\n",
      "Train Epoch: 21 [52480/113287 (46%)]\tLoss: 1.236849\n",
      "Train Epoch: 21 [53760/113287 (47%)]\tLoss: 0.973034\n",
      "Train Epoch: 21 [55040/113287 (49%)]\tLoss: 0.774452\n",
      "Train Epoch: 21 [56320/113287 (50%)]\tLoss: 0.944183\n",
      "Train Epoch: 21 [57600/113287 (51%)]\tLoss: 1.048760\n",
      "Train Epoch: 21 [58880/113287 (52%)]\tLoss: 0.823117\n",
      "Train Epoch: 21 [60160/113287 (53%)]\tLoss: 1.064647\n",
      "Train Epoch: 21 [61440/113287 (54%)]\tLoss: 0.765819\n",
      "Train Epoch: 21 [62720/113287 (55%)]\tLoss: 0.824833\n",
      "Train Epoch: 21 [64000/113287 (56%)]\tLoss: 1.105439\n",
      "Train Epoch: 21 [65280/113287 (58%)]\tLoss: 0.850734\n",
      "Train Epoch: 21 [66560/113287 (59%)]\tLoss: 0.872761\n",
      "Train Epoch: 21 [67840/113287 (60%)]\tLoss: 1.057285\n",
      "Train Epoch: 21 [69120/113287 (61%)]\tLoss: 0.884570\n",
      "Train Epoch: 21 [70400/113287 (62%)]\tLoss: 0.980256\n",
      "Train Epoch: 21 [71680/113287 (63%)]\tLoss: 1.107328\n",
      "Train Epoch: 21 [72960/113287 (64%)]\tLoss: 0.905050\n",
      "Train Epoch: 21 [74240/113287 (65%)]\tLoss: 1.111780\n",
      "Train Epoch: 21 [75520/113287 (67%)]\tLoss: 0.718074\n",
      "Train Epoch: 21 [76800/113287 (68%)]\tLoss: 1.111230\n",
      "Train Epoch: 21 [78080/113287 (69%)]\tLoss: 1.054255\n",
      "Train Epoch: 21 [79360/113287 (70%)]\tLoss: 1.221495\n",
      "Train Epoch: 21 [80640/113287 (71%)]\tLoss: 1.121963\n",
      "Train Epoch: 21 [81920/113287 (72%)]\tLoss: 1.041830\n",
      "Train Epoch: 21 [83200/113287 (73%)]\tLoss: 1.091994\n",
      "Train Epoch: 21 [84480/113287 (74%)]\tLoss: 1.080445\n",
      "Train Epoch: 21 [85760/113287 (76%)]\tLoss: 0.972938\n",
      "Train Epoch: 21 [87040/113287 (77%)]\tLoss: 0.894428\n",
      "Train Epoch: 21 [88320/113287 (78%)]\tLoss: 1.064286\n",
      "Train Epoch: 21 [89600/113287 (79%)]\tLoss: 1.049618\n",
      "Train Epoch: 21 [90880/113287 (80%)]\tLoss: 1.115126\n",
      "Train Epoch: 21 [92160/113287 (81%)]\tLoss: 1.115595\n",
      "Train Epoch: 21 [93440/113287 (82%)]\tLoss: 1.142432\n",
      "Train Epoch: 21 [94720/113287 (84%)]\tLoss: 0.808375\n",
      "Train Epoch: 21 [96000/113287 (85%)]\tLoss: 1.055526\n",
      "Train Epoch: 21 [97280/113287 (86%)]\tLoss: 0.884168\n",
      "Train Epoch: 21 [98560/113287 (87%)]\tLoss: 1.062945\n",
      "Train Epoch: 21 [99840/113287 (88%)]\tLoss: 0.893269\n",
      "Train Epoch: 21 [101120/113287 (89%)]\tLoss: 1.112444\n",
      "Train Epoch: 21 [102400/113287 (90%)]\tLoss: 1.141712\n",
      "Train Epoch: 21 [103680/113287 (91%)]\tLoss: 0.752692\n",
      "Train Epoch: 21 [104960/113287 (93%)]\tLoss: 1.045799\n",
      "Train Epoch: 21 [106240/113287 (94%)]\tLoss: 0.810368\n",
      "Train Epoch: 21 [107520/113287 (95%)]\tLoss: 0.963455\n",
      "Train Epoch: 21 [108800/113287 (96%)]\tLoss: 1.071246\n",
      "Train Epoch: 21 [110080/113287 (97%)]\tLoss: 0.972918\n",
      "Train Epoch: 21 [111360/113287 (98%)]\tLoss: 1.143879\n",
      "Train Epoch: 21 [112640/113287 (99%)]\tLoss: 1.182259\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3523/5000 (70%)\n",
      "\n",
      "Train Epoch: 22 [0/113287 (0%)]\tLoss: 0.825201\n",
      "Train Epoch: 22 [1280/113287 (1%)]\tLoss: 0.969934\n",
      "Train Epoch: 22 [2560/113287 (2%)]\tLoss: 0.981423\n",
      "Train Epoch: 22 [3840/113287 (3%)]\tLoss: 0.977605\n",
      "Train Epoch: 22 [5120/113287 (5%)]\tLoss: 1.011481\n",
      "Train Epoch: 22 [6400/113287 (6%)]\tLoss: 0.927147\n",
      "Train Epoch: 22 [7680/113287 (7%)]\tLoss: 0.991865\n",
      "Train Epoch: 22 [8960/113287 (8%)]\tLoss: 0.970662\n",
      "Train Epoch: 22 [10240/113287 (9%)]\tLoss: 0.985693\n",
      "Train Epoch: 22 [11520/113287 (10%)]\tLoss: 1.119022\n",
      "Train Epoch: 22 [12800/113287 (11%)]\tLoss: 1.076689\n",
      "Train Epoch: 22 [14080/113287 (12%)]\tLoss: 1.016320\n",
      "Train Epoch: 22 [15360/113287 (14%)]\tLoss: 1.056606\n",
      "Train Epoch: 22 [16640/113287 (15%)]\tLoss: 1.112015\n",
      "Train Epoch: 22 [17920/113287 (16%)]\tLoss: 1.116807\n",
      "Train Epoch: 22 [19200/113287 (17%)]\tLoss: 1.097994\n",
      "Train Epoch: 22 [20480/113287 (18%)]\tLoss: 1.029365\n",
      "Train Epoch: 22 [21760/113287 (19%)]\tLoss: 0.854349\n",
      "Train Epoch: 22 [23040/113287 (20%)]\tLoss: 0.902187\n",
      "Train Epoch: 22 [24320/113287 (21%)]\tLoss: 1.148547\n",
      "Train Epoch: 22 [25600/113287 (23%)]\tLoss: 1.129317\n",
      "Train Epoch: 22 [26880/113287 (24%)]\tLoss: 1.121205\n",
      "Train Epoch: 22 [28160/113287 (25%)]\tLoss: 1.081259\n",
      "Train Epoch: 22 [29440/113287 (26%)]\tLoss: 1.032689\n",
      "Train Epoch: 22 [30720/113287 (27%)]\tLoss: 1.229635\n",
      "Train Epoch: 22 [32000/113287 (28%)]\tLoss: 1.013013\n",
      "Train Epoch: 22 [33280/113287 (29%)]\tLoss: 0.961677\n",
      "Train Epoch: 22 [34560/113287 (30%)]\tLoss: 1.150348\n",
      "Train Epoch: 22 [35840/113287 (32%)]\tLoss: 0.919619\n",
      "Train Epoch: 22 [37120/113287 (33%)]\tLoss: 1.026179\n",
      "Train Epoch: 22 [38400/113287 (34%)]\tLoss: 0.837562\n",
      "Train Epoch: 22 [39680/113287 (35%)]\tLoss: 0.969615\n",
      "Train Epoch: 22 [40960/113287 (36%)]\tLoss: 0.989905\n",
      "Train Epoch: 22 [42240/113287 (37%)]\tLoss: 1.260001\n",
      "Train Epoch: 22 [43520/113287 (38%)]\tLoss: 1.283108\n",
      "Train Epoch: 22 [44800/113287 (40%)]\tLoss: 1.016138\n",
      "Train Epoch: 22 [46080/113287 (41%)]\tLoss: 1.059264\n",
      "Train Epoch: 22 [47360/113287 (42%)]\tLoss: 0.925249\n",
      "Train Epoch: 22 [48640/113287 (43%)]\tLoss: 0.981071\n",
      "Train Epoch: 22 [49920/113287 (44%)]\tLoss: 1.020679\n",
      "Train Epoch: 22 [51200/113287 (45%)]\tLoss: 1.150290\n",
      "Train Epoch: 22 [52480/113287 (46%)]\tLoss: 0.810383\n",
      "Train Epoch: 22 [53760/113287 (47%)]\tLoss: 0.916531\n",
      "Train Epoch: 22 [55040/113287 (49%)]\tLoss: 1.077537\n",
      "Train Epoch: 22 [56320/113287 (50%)]\tLoss: 1.139427\n",
      "Train Epoch: 22 [57600/113287 (51%)]\tLoss: 0.779154\n",
      "Train Epoch: 22 [58880/113287 (52%)]\tLoss: 0.783777\n",
      "Train Epoch: 22 [60160/113287 (53%)]\tLoss: 0.804226\n",
      "Train Epoch: 22 [61440/113287 (54%)]\tLoss: 1.103500\n",
      "Train Epoch: 22 [62720/113287 (55%)]\tLoss: 0.849031\n",
      "Train Epoch: 22 [64000/113287 (56%)]\tLoss: 0.963576\n",
      "Train Epoch: 22 [65280/113287 (58%)]\tLoss: 0.929880\n",
      "Train Epoch: 22 [66560/113287 (59%)]\tLoss: 1.142002\n",
      "Train Epoch: 22 [67840/113287 (60%)]\tLoss: 1.060018\n",
      "Train Epoch: 22 [69120/113287 (61%)]\tLoss: 0.892634\n",
      "Train Epoch: 22 [70400/113287 (62%)]\tLoss: 1.062458\n",
      "Train Epoch: 22 [71680/113287 (63%)]\tLoss: 0.756790\n",
      "Train Epoch: 22 [72960/113287 (64%)]\tLoss: 0.837625\n",
      "Train Epoch: 22 [74240/113287 (65%)]\tLoss: 1.042711\n",
      "Train Epoch: 22 [75520/113287 (67%)]\tLoss: 0.915993\n",
      "Train Epoch: 22 [76800/113287 (68%)]\tLoss: 0.869199\n",
      "Train Epoch: 22 [78080/113287 (69%)]\tLoss: 0.906638\n",
      "Train Epoch: 22 [79360/113287 (70%)]\tLoss: 1.002650\n",
      "Train Epoch: 22 [80640/113287 (71%)]\tLoss: 1.068797\n",
      "Train Epoch: 22 [81920/113287 (72%)]\tLoss: 1.093956\n",
      "Train Epoch: 22 [83200/113287 (73%)]\tLoss: 1.031559\n",
      "Train Epoch: 22 [84480/113287 (74%)]\tLoss: 0.765627\n",
      "Train Epoch: 22 [85760/113287 (76%)]\tLoss: 0.986842\n",
      "Train Epoch: 22 [87040/113287 (77%)]\tLoss: 0.775331\n",
      "Train Epoch: 22 [88320/113287 (78%)]\tLoss: 0.981866\n",
      "Train Epoch: 22 [89600/113287 (79%)]\tLoss: 1.138992\n",
      "Train Epoch: 22 [90880/113287 (80%)]\tLoss: 0.751763\n",
      "Train Epoch: 22 [92160/113287 (81%)]\tLoss: 0.982031\n",
      "Train Epoch: 22 [93440/113287 (82%)]\tLoss: 0.978095\n",
      "Train Epoch: 22 [94720/113287 (84%)]\tLoss: 1.184431\n",
      "Train Epoch: 22 [96000/113287 (85%)]\tLoss: 0.964419\n",
      "Train Epoch: 22 [97280/113287 (86%)]\tLoss: 0.951216\n",
      "Train Epoch: 22 [98560/113287 (87%)]\tLoss: 0.964944\n",
      "Train Epoch: 22 [99840/113287 (88%)]\tLoss: 0.804580\n",
      "Train Epoch: 22 [101120/113287 (89%)]\tLoss: 1.019774\n",
      "Train Epoch: 22 [102400/113287 (90%)]\tLoss: 0.717279\n",
      "Train Epoch: 22 [103680/113287 (91%)]\tLoss: 0.889405\n",
      "Train Epoch: 22 [104960/113287 (93%)]\tLoss: 1.083728\n",
      "Train Epoch: 22 [106240/113287 (94%)]\tLoss: 0.921933\n",
      "Train Epoch: 22 [107520/113287 (95%)]\tLoss: 0.908287\n",
      "Train Epoch: 22 [108800/113287 (96%)]\tLoss: 1.072928\n",
      "Train Epoch: 22 [110080/113287 (97%)]\tLoss: 0.829112\n",
      "Train Epoch: 22 [111360/113287 (98%)]\tLoss: 0.877256\n",
      "Train Epoch: 22 [112640/113287 (99%)]\tLoss: 0.868033\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3544/5000 (70%)\n",
      "\n",
      "Train Epoch: 23 [0/113287 (0%)]\tLoss: 1.088590\n",
      "Train Epoch: 23 [1280/113287 (1%)]\tLoss: 1.135615\n",
      "Train Epoch: 23 [2560/113287 (2%)]\tLoss: 1.129653\n",
      "Train Epoch: 23 [3840/113287 (3%)]\tLoss: 0.915771\n",
      "Train Epoch: 23 [5120/113287 (5%)]\tLoss: 0.855965\n",
      "Train Epoch: 23 [6400/113287 (6%)]\tLoss: 0.786564\n",
      "Train Epoch: 23 [7680/113287 (7%)]\tLoss: 1.153281\n",
      "Train Epoch: 23 [8960/113287 (8%)]\tLoss: 0.955931\n",
      "Train Epoch: 23 [10240/113287 (9%)]\tLoss: 0.946074\n",
      "Train Epoch: 23 [11520/113287 (10%)]\tLoss: 1.004463\n",
      "Train Epoch: 23 [12800/113287 (11%)]\tLoss: 0.974249\n",
      "Train Epoch: 23 [14080/113287 (12%)]\tLoss: 0.929686\n",
      "Train Epoch: 23 [15360/113287 (14%)]\tLoss: 1.081107\n",
      "Train Epoch: 23 [16640/113287 (15%)]\tLoss: 1.133154\n",
      "Train Epoch: 23 [17920/113287 (16%)]\tLoss: 1.030208\n",
      "Train Epoch: 23 [19200/113287 (17%)]\tLoss: 0.867820\n",
      "Train Epoch: 23 [20480/113287 (18%)]\tLoss: 0.747913\n",
      "Train Epoch: 23 [21760/113287 (19%)]\tLoss: 1.001042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23 [23040/113287 (20%)]\tLoss: 1.204350\n",
      "Train Epoch: 23 [24320/113287 (21%)]\tLoss: 0.972012\n",
      "Train Epoch: 23 [25600/113287 (23%)]\tLoss: 1.093350\n",
      "Train Epoch: 23 [26880/113287 (24%)]\tLoss: 1.055296\n",
      "Train Epoch: 23 [28160/113287 (25%)]\tLoss: 0.854132\n",
      "Train Epoch: 23 [29440/113287 (26%)]\tLoss: 1.011458\n",
      "Train Epoch: 23 [30720/113287 (27%)]\tLoss: 1.217582\n",
      "Train Epoch: 23 [32000/113287 (28%)]\tLoss: 0.946420\n",
      "Train Epoch: 23 [33280/113287 (29%)]\tLoss: 0.968212\n",
      "Train Epoch: 23 [34560/113287 (30%)]\tLoss: 1.098182\n",
      "Train Epoch: 23 [35840/113287 (32%)]\tLoss: 0.931491\n",
      "Train Epoch: 23 [37120/113287 (33%)]\tLoss: 1.033978\n",
      "Train Epoch: 23 [38400/113287 (34%)]\tLoss: 1.014676\n",
      "Train Epoch: 23 [39680/113287 (35%)]\tLoss: 1.012864\n",
      "Train Epoch: 23 [40960/113287 (36%)]\tLoss: 1.338852\n",
      "Train Epoch: 23 [42240/113287 (37%)]\tLoss: 1.182480\n",
      "Train Epoch: 23 [43520/113287 (38%)]\tLoss: 1.111675\n",
      "Train Epoch: 23 [44800/113287 (40%)]\tLoss: 0.971685\n",
      "Train Epoch: 23 [46080/113287 (41%)]\tLoss: 0.959990\n",
      "Train Epoch: 23 [47360/113287 (42%)]\tLoss: 0.946948\n",
      "Train Epoch: 23 [48640/113287 (43%)]\tLoss: 0.877591\n",
      "Train Epoch: 23 [49920/113287 (44%)]\tLoss: 0.994945\n",
      "Train Epoch: 23 [51200/113287 (45%)]\tLoss: 0.815288\n",
      "Train Epoch: 23 [52480/113287 (46%)]\tLoss: 1.145736\n",
      "Train Epoch: 23 [53760/113287 (47%)]\tLoss: 0.965654\n",
      "Train Epoch: 23 [55040/113287 (49%)]\tLoss: 1.171753\n",
      "Train Epoch: 23 [56320/113287 (50%)]\tLoss: 0.917696\n",
      "Train Epoch: 23 [57600/113287 (51%)]\tLoss: 0.817136\n",
      "Train Epoch: 23 [58880/113287 (52%)]\tLoss: 1.162310\n",
      "Train Epoch: 23 [60160/113287 (53%)]\tLoss: 1.248917\n",
      "Train Epoch: 23 [61440/113287 (54%)]\tLoss: 0.971375\n",
      "Train Epoch: 23 [62720/113287 (55%)]\tLoss: 0.870406\n",
      "Train Epoch: 23 [64000/113287 (56%)]\tLoss: 1.042913\n",
      "Train Epoch: 23 [65280/113287 (58%)]\tLoss: 0.865495\n",
      "Train Epoch: 23 [66560/113287 (59%)]\tLoss: 0.902950\n",
      "Train Epoch: 23 [67840/113287 (60%)]\tLoss: 1.103298\n",
      "Train Epoch: 23 [69120/113287 (61%)]\tLoss: 1.071984\n",
      "Train Epoch: 23 [70400/113287 (62%)]\tLoss: 0.817669\n",
      "Train Epoch: 23 [71680/113287 (63%)]\tLoss: 0.902615\n",
      "Train Epoch: 23 [72960/113287 (64%)]\tLoss: 0.943830\n",
      "Train Epoch: 23 [74240/113287 (65%)]\tLoss: 0.817676\n",
      "Train Epoch: 23 [75520/113287 (67%)]\tLoss: 0.944046\n",
      "Train Epoch: 23 [76800/113287 (68%)]\tLoss: 0.813609\n",
      "Train Epoch: 23 [78080/113287 (69%)]\tLoss: 1.257443\n",
      "Train Epoch: 23 [79360/113287 (70%)]\tLoss: 1.066741\n",
      "Train Epoch: 23 [80640/113287 (71%)]\tLoss: 1.017848\n",
      "Train Epoch: 23 [81920/113287 (72%)]\tLoss: 1.083681\n",
      "Train Epoch: 23 [83200/113287 (73%)]\tLoss: 1.120553\n",
      "Train Epoch: 23 [84480/113287 (74%)]\tLoss: 0.890637\n",
      "Train Epoch: 23 [85760/113287 (76%)]\tLoss: 1.142052\n",
      "Train Epoch: 23 [87040/113287 (77%)]\tLoss: 0.914500\n",
      "Train Epoch: 23 [88320/113287 (78%)]\tLoss: 0.757710\n",
      "Train Epoch: 23 [89600/113287 (79%)]\tLoss: 1.084555\n",
      "Train Epoch: 23 [90880/113287 (80%)]\tLoss: 0.971270\n",
      "Train Epoch: 23 [92160/113287 (81%)]\tLoss: 1.136187\n",
      "Train Epoch: 23 [93440/113287 (82%)]\tLoss: 0.920085\n",
      "Train Epoch: 23 [94720/113287 (84%)]\tLoss: 0.896331\n",
      "Train Epoch: 23 [96000/113287 (85%)]\tLoss: 0.982746\n",
      "Train Epoch: 23 [97280/113287 (86%)]\tLoss: 1.037594\n",
      "Train Epoch: 23 [98560/113287 (87%)]\tLoss: 1.000398\n",
      "Train Epoch: 23 [99840/113287 (88%)]\tLoss: 0.788366\n",
      "Train Epoch: 23 [101120/113287 (89%)]\tLoss: 1.093792\n",
      "Train Epoch: 23 [102400/113287 (90%)]\tLoss: 1.143691\n",
      "Train Epoch: 23 [103680/113287 (91%)]\tLoss: 1.098855\n",
      "Train Epoch: 23 [104960/113287 (93%)]\tLoss: 1.060086\n",
      "Train Epoch: 23 [106240/113287 (94%)]\tLoss: 0.776812\n",
      "Train Epoch: 23 [107520/113287 (95%)]\tLoss: 1.070493\n",
      "Train Epoch: 23 [108800/113287 (96%)]\tLoss: 1.028168\n",
      "Train Epoch: 23 [110080/113287 (97%)]\tLoss: 1.265308\n",
      "Train Epoch: 23 [111360/113287 (98%)]\tLoss: 1.202216\n",
      "Train Epoch: 23 [112640/113287 (99%)]\tLoss: 1.035757\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3513/5000 (70%)\n",
      "\n",
      "Train Epoch: 24 [0/113287 (0%)]\tLoss: 0.926994\n",
      "Train Epoch: 24 [1280/113287 (1%)]\tLoss: 0.887706\n",
      "Train Epoch: 24 [2560/113287 (2%)]\tLoss: 1.237874\n",
      "Train Epoch: 24 [3840/113287 (3%)]\tLoss: 1.029699\n",
      "Train Epoch: 24 [5120/113287 (5%)]\tLoss: 0.865319\n",
      "Train Epoch: 24 [6400/113287 (6%)]\tLoss: 1.028290\n",
      "Train Epoch: 24 [7680/113287 (7%)]\tLoss: 0.890331\n",
      "Train Epoch: 24 [8960/113287 (8%)]\tLoss: 0.863516\n",
      "Train Epoch: 24 [10240/113287 (9%)]\tLoss: 1.022166\n",
      "Train Epoch: 24 [11520/113287 (10%)]\tLoss: 0.796269\n",
      "Train Epoch: 24 [12800/113287 (11%)]\tLoss: 0.877379\n",
      "Train Epoch: 24 [14080/113287 (12%)]\tLoss: 0.952762\n",
      "Train Epoch: 24 [15360/113287 (14%)]\tLoss: 0.927305\n",
      "Train Epoch: 24 [16640/113287 (15%)]\tLoss: 1.040793\n",
      "Train Epoch: 24 [17920/113287 (16%)]\tLoss: 1.065891\n",
      "Train Epoch: 24 [19200/113287 (17%)]\tLoss: 1.014707\n",
      "Train Epoch: 24 [20480/113287 (18%)]\tLoss: 0.706745\n",
      "Train Epoch: 24 [21760/113287 (19%)]\tLoss: 0.985622\n",
      "Train Epoch: 24 [23040/113287 (20%)]\tLoss: 0.887420\n",
      "Train Epoch: 24 [24320/113287 (21%)]\tLoss: 1.224213\n",
      "Train Epoch: 24 [25600/113287 (23%)]\tLoss: 0.842001\n",
      "Train Epoch: 24 [26880/113287 (24%)]\tLoss: 1.031148\n",
      "Train Epoch: 24 [28160/113287 (25%)]\tLoss: 1.021300\n",
      "Train Epoch: 24 [29440/113287 (26%)]\tLoss: 0.876757\n",
      "Train Epoch: 24 [30720/113287 (27%)]\tLoss: 1.023324\n",
      "Train Epoch: 24 [32000/113287 (28%)]\tLoss: 0.950808\n",
      "Train Epoch: 24 [33280/113287 (29%)]\tLoss: 1.083317\n",
      "Train Epoch: 24 [34560/113287 (30%)]\tLoss: 0.935775\n",
      "Train Epoch: 24 [35840/113287 (32%)]\tLoss: 0.809080\n",
      "Train Epoch: 24 [37120/113287 (33%)]\tLoss: 0.971509\n",
      "Train Epoch: 24 [38400/113287 (34%)]\tLoss: 0.739668\n",
      "Train Epoch: 24 [39680/113287 (35%)]\tLoss: 0.738381\n",
      "Train Epoch: 24 [40960/113287 (36%)]\tLoss: 1.013843\n",
      "Train Epoch: 24 [42240/113287 (37%)]\tLoss: 0.958383\n",
      "Train Epoch: 24 [43520/113287 (38%)]\tLoss: 0.961549\n",
      "Train Epoch: 24 [44800/113287 (40%)]\tLoss: 1.100197\n",
      "Train Epoch: 24 [46080/113287 (41%)]\tLoss: 1.158943\n",
      "Train Epoch: 24 [47360/113287 (42%)]\tLoss: 0.971177\n",
      "Train Epoch: 24 [48640/113287 (43%)]\tLoss: 0.893827\n",
      "Train Epoch: 24 [49920/113287 (44%)]\tLoss: 1.242925\n",
      "Train Epoch: 24 [51200/113287 (45%)]\tLoss: 1.025380\n",
      "Train Epoch: 24 [52480/113287 (46%)]\tLoss: 0.967108\n",
      "Train Epoch: 24 [53760/113287 (47%)]\tLoss: 0.869304\n",
      "Train Epoch: 24 [55040/113287 (49%)]\tLoss: 1.076650\n",
      "Train Epoch: 24 [56320/113287 (50%)]\tLoss: 0.699925\n",
      "Train Epoch: 24 [57600/113287 (51%)]\tLoss: 1.096161\n",
      "Train Epoch: 24 [58880/113287 (52%)]\tLoss: 1.084257\n",
      "Train Epoch: 24 [60160/113287 (53%)]\tLoss: 1.170768\n",
      "Train Epoch: 24 [61440/113287 (54%)]\tLoss: 0.967381\n",
      "Train Epoch: 24 [62720/113287 (55%)]\tLoss: 1.015296\n",
      "Train Epoch: 24 [64000/113287 (56%)]\tLoss: 0.895977\n",
      "Train Epoch: 24 [65280/113287 (58%)]\tLoss: 0.906170\n",
      "Train Epoch: 24 [66560/113287 (59%)]\tLoss: 1.177906\n",
      "Train Epoch: 24 [67840/113287 (60%)]\tLoss: 1.056670\n",
      "Train Epoch: 24 [69120/113287 (61%)]\tLoss: 0.898817\n",
      "Train Epoch: 24 [70400/113287 (62%)]\tLoss: 1.036747\n",
      "Train Epoch: 24 [71680/113287 (63%)]\tLoss: 0.919992\n",
      "Train Epoch: 24 [72960/113287 (64%)]\tLoss: 1.342933\n",
      "Train Epoch: 24 [74240/113287 (65%)]\tLoss: 0.979923\n",
      "Train Epoch: 24 [75520/113287 (67%)]\tLoss: 0.776573\n",
      "Train Epoch: 24 [76800/113287 (68%)]\tLoss: 1.022053\n",
      "Train Epoch: 24 [78080/113287 (69%)]\tLoss: 1.188873\n",
      "Train Epoch: 24 [79360/113287 (70%)]\tLoss: 1.091558\n",
      "Train Epoch: 24 [80640/113287 (71%)]\tLoss: 1.144009\n",
      "Train Epoch: 24 [81920/113287 (72%)]\tLoss: 1.083127\n",
      "Train Epoch: 24 [83200/113287 (73%)]\tLoss: 0.986123\n",
      "Train Epoch: 24 [84480/113287 (74%)]\tLoss: 1.156371\n",
      "Train Epoch: 24 [85760/113287 (76%)]\tLoss: 0.873050\n",
      "Train Epoch: 24 [87040/113287 (77%)]\tLoss: 0.937630\n",
      "Train Epoch: 24 [88320/113287 (78%)]\tLoss: 1.267589\n",
      "Train Epoch: 24 [89600/113287 (79%)]\tLoss: 0.949028\n",
      "Train Epoch: 24 [90880/113287 (80%)]\tLoss: 0.827313\n",
      "Train Epoch: 24 [92160/113287 (81%)]\tLoss: 0.973675\n",
      "Train Epoch: 24 [93440/113287 (82%)]\tLoss: 1.047550\n",
      "Train Epoch: 24 [94720/113287 (84%)]\tLoss: 0.990359\n",
      "Train Epoch: 24 [96000/113287 (85%)]\tLoss: 0.760564\n",
      "Train Epoch: 24 [97280/113287 (86%)]\tLoss: 0.963349\n",
      "Train Epoch: 24 [98560/113287 (87%)]\tLoss: 0.824715\n",
      "Train Epoch: 24 [99840/113287 (88%)]\tLoss: 0.935292\n",
      "Train Epoch: 24 [101120/113287 (89%)]\tLoss: 0.825328\n",
      "Train Epoch: 24 [102400/113287 (90%)]\tLoss: 1.119532\n",
      "Train Epoch: 24 [103680/113287 (91%)]\tLoss: 0.976402\n",
      "Train Epoch: 24 [104960/113287 (93%)]\tLoss: 1.001065\n",
      "Train Epoch: 24 [106240/113287 (94%)]\tLoss: 0.857309\n",
      "Train Epoch: 24 [107520/113287 (95%)]\tLoss: 0.974370\n",
      "Train Epoch: 24 [108800/113287 (96%)]\tLoss: 1.032732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24 [110080/113287 (97%)]\tLoss: 0.726717\n",
      "Train Epoch: 24 [111360/113287 (98%)]\tLoss: 0.993928\n",
      "Train Epoch: 24 [112640/113287 (99%)]\tLoss: 0.898458\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3553/5000 (71%)\n",
      "\n",
      "Train Epoch: 25 [0/113287 (0%)]\tLoss: 1.118571\n",
      "Train Epoch: 25 [1280/113287 (1%)]\tLoss: 1.060167\n",
      "Train Epoch: 25 [2560/113287 (2%)]\tLoss: 1.126637\n",
      "Train Epoch: 25 [3840/113287 (3%)]\tLoss: 0.814204\n",
      "Train Epoch: 25 [5120/113287 (5%)]\tLoss: 0.867217\n",
      "Train Epoch: 25 [6400/113287 (6%)]\tLoss: 0.843055\n",
      "Train Epoch: 25 [7680/113287 (7%)]\tLoss: 0.953584\n",
      "Train Epoch: 25 [8960/113287 (8%)]\tLoss: 1.031953\n",
      "Train Epoch: 25 [10240/113287 (9%)]\tLoss: 1.065772\n",
      "Train Epoch: 25 [11520/113287 (10%)]\tLoss: 0.929189\n",
      "Train Epoch: 25 [12800/113287 (11%)]\tLoss: 1.323931\n",
      "Train Epoch: 25 [14080/113287 (12%)]\tLoss: 1.226348\n",
      "Train Epoch: 25 [15360/113287 (14%)]\tLoss: 1.135953\n",
      "Train Epoch: 25 [16640/113287 (15%)]\tLoss: 1.250735\n",
      "Train Epoch: 25 [17920/113287 (16%)]\tLoss: 0.738072\n",
      "Train Epoch: 25 [19200/113287 (17%)]\tLoss: 0.880743\n",
      "Train Epoch: 25 [20480/113287 (18%)]\tLoss: 0.933635\n",
      "Train Epoch: 25 [21760/113287 (19%)]\tLoss: 0.952385\n",
      "Train Epoch: 25 [23040/113287 (20%)]\tLoss: 1.128017\n",
      "Train Epoch: 25 [24320/113287 (21%)]\tLoss: 0.993741\n",
      "Train Epoch: 25 [25600/113287 (23%)]\tLoss: 0.958211\n",
      "Train Epoch: 25 [26880/113287 (24%)]\tLoss: 1.020756\n",
      "Train Epoch: 25 [28160/113287 (25%)]\tLoss: 0.748476\n",
      "Train Epoch: 25 [29440/113287 (26%)]\tLoss: 1.075553\n",
      "Train Epoch: 25 [30720/113287 (27%)]\tLoss: 1.101879\n",
      "Train Epoch: 25 [32000/113287 (28%)]\tLoss: 0.969834\n",
      "Train Epoch: 25 [33280/113287 (29%)]\tLoss: 1.033726\n",
      "Train Epoch: 25 [34560/113287 (30%)]\tLoss: 1.042062\n",
      "Train Epoch: 25 [35840/113287 (32%)]\tLoss: 1.258635\n",
      "Train Epoch: 25 [37120/113287 (33%)]\tLoss: 0.967173\n",
      "Train Epoch: 25 [38400/113287 (34%)]\tLoss: 0.961436\n",
      "Train Epoch: 25 [39680/113287 (35%)]\tLoss: 0.905022\n",
      "Train Epoch: 25 [40960/113287 (36%)]\tLoss: 0.972308\n",
      "Train Epoch: 25 [42240/113287 (37%)]\tLoss: 1.037300\n",
      "Train Epoch: 25 [43520/113287 (38%)]\tLoss: 1.151340\n",
      "Train Epoch: 25 [44800/113287 (40%)]\tLoss: 0.914774\n",
      "Train Epoch: 25 [46080/113287 (41%)]\tLoss: 1.176916\n",
      "Train Epoch: 25 [47360/113287 (42%)]\tLoss: 1.002346\n",
      "Train Epoch: 25 [48640/113287 (43%)]\tLoss: 1.004131\n",
      "Train Epoch: 25 [49920/113287 (44%)]\tLoss: 1.130861\n",
      "Train Epoch: 25 [51200/113287 (45%)]\tLoss: 0.851772\n",
      "Train Epoch: 25 [52480/113287 (46%)]\tLoss: 0.850438\n",
      "Train Epoch: 25 [53760/113287 (47%)]\tLoss: 1.104277\n",
      "Train Epoch: 25 [55040/113287 (49%)]\tLoss: 1.062540\n",
      "Train Epoch: 25 [56320/113287 (50%)]\tLoss: 1.054171\n",
      "Train Epoch: 25 [57600/113287 (51%)]\tLoss: 0.973885\n",
      "Train Epoch: 25 [58880/113287 (52%)]\tLoss: 1.137716\n",
      "Train Epoch: 25 [60160/113287 (53%)]\tLoss: 0.910513\n",
      "Train Epoch: 25 [61440/113287 (54%)]\tLoss: 0.829991\n",
      "Train Epoch: 25 [62720/113287 (55%)]\tLoss: 0.960870\n",
      "Train Epoch: 25 [64000/113287 (56%)]\tLoss: 1.086588\n",
      "Train Epoch: 25 [65280/113287 (58%)]\tLoss: 0.944879\n",
      "Train Epoch: 25 [66560/113287 (59%)]\tLoss: 0.987132\n",
      "Train Epoch: 25 [67840/113287 (60%)]\tLoss: 0.899816\n",
      "Train Epoch: 25 [69120/113287 (61%)]\tLoss: 0.756887\n",
      "Train Epoch: 25 [70400/113287 (62%)]\tLoss: 0.952309\n",
      "Train Epoch: 25 [71680/113287 (63%)]\tLoss: 0.967783\n",
      "Train Epoch: 25 [72960/113287 (64%)]\tLoss: 1.167301\n",
      "Train Epoch: 25 [74240/113287 (65%)]\tLoss: 0.802156\n",
      "Train Epoch: 25 [75520/113287 (67%)]\tLoss: 1.091011\n",
      "Train Epoch: 25 [76800/113287 (68%)]\tLoss: 0.970193\n",
      "Train Epoch: 25 [78080/113287 (69%)]\tLoss: 0.874163\n",
      "Train Epoch: 25 [79360/113287 (70%)]\tLoss: 0.864247\n",
      "Train Epoch: 25 [80640/113287 (71%)]\tLoss: 0.960867\n",
      "Train Epoch: 25 [81920/113287 (72%)]\tLoss: 1.024973\n",
      "Train Epoch: 25 [83200/113287 (73%)]\tLoss: 0.890742\n",
      "Train Epoch: 25 [84480/113287 (74%)]\tLoss: 1.133132\n",
      "Train Epoch: 25 [85760/113287 (76%)]\tLoss: 0.942967\n",
      "Train Epoch: 25 [87040/113287 (77%)]\tLoss: 1.004537\n",
      "Train Epoch: 25 [88320/113287 (78%)]\tLoss: 0.866121\n",
      "Train Epoch: 25 [89600/113287 (79%)]\tLoss: 0.953043\n",
      "Train Epoch: 25 [90880/113287 (80%)]\tLoss: 0.890652\n",
      "Train Epoch: 25 [92160/113287 (81%)]\tLoss: 0.941187\n",
      "Train Epoch: 25 [93440/113287 (82%)]\tLoss: 1.036753\n",
      "Train Epoch: 25 [94720/113287 (84%)]\tLoss: 1.058444\n",
      "Train Epoch: 25 [96000/113287 (85%)]\tLoss: 0.819006\n",
      "Train Epoch: 25 [97280/113287 (86%)]\tLoss: 0.815195\n",
      "Train Epoch: 25 [98560/113287 (87%)]\tLoss: 1.210829\n",
      "Train Epoch: 25 [99840/113287 (88%)]\tLoss: 0.808915\n",
      "Train Epoch: 25 [101120/113287 (89%)]\tLoss: 0.987126\n",
      "Train Epoch: 25 [102400/113287 (90%)]\tLoss: 1.063353\n",
      "Train Epoch: 25 [103680/113287 (91%)]\tLoss: 0.983196\n",
      "Train Epoch: 25 [104960/113287 (93%)]\tLoss: 0.931557\n",
      "Train Epoch: 25 [106240/113287 (94%)]\tLoss: 1.041890\n",
      "Train Epoch: 25 [107520/113287 (95%)]\tLoss: 1.107927\n",
      "Train Epoch: 25 [108800/113287 (96%)]\tLoss: 1.026247\n",
      "Train Epoch: 25 [110080/113287 (97%)]\tLoss: 0.974778\n",
      "Train Epoch: 25 [111360/113287 (98%)]\tLoss: 1.149145\n",
      "Train Epoch: 25 [112640/113287 (99%)]\tLoss: 1.231250\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3566/5000 (71%)\n",
      "\n",
      "Train Epoch: 26 [0/113287 (0%)]\tLoss: 1.004128\n",
      "Train Epoch: 26 [1280/113287 (1%)]\tLoss: 1.105780\n",
      "Train Epoch: 26 [2560/113287 (2%)]\tLoss: 0.934535\n",
      "Train Epoch: 26 [3840/113287 (3%)]\tLoss: 1.031125\n",
      "Train Epoch: 26 [5120/113287 (5%)]\tLoss: 1.224194\n",
      "Train Epoch: 26 [6400/113287 (6%)]\tLoss: 1.136958\n",
      "Train Epoch: 26 [7680/113287 (7%)]\tLoss: 0.790096\n",
      "Train Epoch: 26 [8960/113287 (8%)]\tLoss: 0.975653\n",
      "Train Epoch: 26 [10240/113287 (9%)]\tLoss: 0.912714\n",
      "Train Epoch: 26 [11520/113287 (10%)]\tLoss: 1.027917\n",
      "Train Epoch: 26 [12800/113287 (11%)]\tLoss: 0.830356\n",
      "Train Epoch: 26 [14080/113287 (12%)]\tLoss: 0.892527\n",
      "Train Epoch: 26 [15360/113287 (14%)]\tLoss: 1.154233\n",
      "Train Epoch: 26 [16640/113287 (15%)]\tLoss: 0.993718\n",
      "Train Epoch: 26 [17920/113287 (16%)]\tLoss: 0.991875\n",
      "Train Epoch: 26 [19200/113287 (17%)]\tLoss: 0.958524\n",
      "Train Epoch: 26 [20480/113287 (18%)]\tLoss: 0.953331\n",
      "Train Epoch: 26 [21760/113287 (19%)]\tLoss: 0.830385\n",
      "Train Epoch: 26 [23040/113287 (20%)]\tLoss: 0.946642\n",
      "Train Epoch: 26 [24320/113287 (21%)]\tLoss: 1.018538\n",
      "Train Epoch: 26 [25600/113287 (23%)]\tLoss: 1.143431\n",
      "Train Epoch: 26 [26880/113287 (24%)]\tLoss: 1.223116\n",
      "Train Epoch: 26 [28160/113287 (25%)]\tLoss: 0.943811\n",
      "Train Epoch: 26 [29440/113287 (26%)]\tLoss: 0.824714\n",
      "Train Epoch: 26 [30720/113287 (27%)]\tLoss: 0.938291\n",
      "Train Epoch: 26 [32000/113287 (28%)]\tLoss: 1.022170\n",
      "Train Epoch: 26 [33280/113287 (29%)]\tLoss: 0.883601\n",
      "Train Epoch: 26 [34560/113287 (30%)]\tLoss: 1.333817\n",
      "Train Epoch: 26 [35840/113287 (32%)]\tLoss: 0.896157\n",
      "Train Epoch: 26 [37120/113287 (33%)]\tLoss: 1.026636\n",
      "Train Epoch: 26 [38400/113287 (34%)]\tLoss: 1.051269\n",
      "Train Epoch: 26 [39680/113287 (35%)]\tLoss: 0.898913\n",
      "Train Epoch: 26 [40960/113287 (36%)]\tLoss: 0.861572\n",
      "Train Epoch: 26 [42240/113287 (37%)]\tLoss: 1.044943\n",
      "Train Epoch: 26 [43520/113287 (38%)]\tLoss: 0.820189\n",
      "Train Epoch: 26 [44800/113287 (40%)]\tLoss: 1.053443\n",
      "Train Epoch: 26 [46080/113287 (41%)]\tLoss: 0.867386\n",
      "Train Epoch: 26 [47360/113287 (42%)]\tLoss: 1.191185\n",
      "Train Epoch: 26 [48640/113287 (43%)]\tLoss: 0.812573\n",
      "Train Epoch: 26 [49920/113287 (44%)]\tLoss: 0.987881\n",
      "Train Epoch: 26 [51200/113287 (45%)]\tLoss: 1.115986\n",
      "Train Epoch: 26 [52480/113287 (46%)]\tLoss: 1.050006\n",
      "Train Epoch: 26 [53760/113287 (47%)]\tLoss: 0.781170\n",
      "Train Epoch: 26 [55040/113287 (49%)]\tLoss: 1.075592\n",
      "Train Epoch: 26 [56320/113287 (50%)]\tLoss: 1.242290\n",
      "Train Epoch: 26 [57600/113287 (51%)]\tLoss: 1.042839\n",
      "Train Epoch: 26 [58880/113287 (52%)]\tLoss: 1.100161\n",
      "Train Epoch: 26 [60160/113287 (53%)]\tLoss: 0.904763\n",
      "Train Epoch: 26 [61440/113287 (54%)]\tLoss: 0.909863\n",
      "Train Epoch: 26 [62720/113287 (55%)]\tLoss: 0.889885\n",
      "Train Epoch: 26 [64000/113287 (56%)]\tLoss: 1.293794\n",
      "Train Epoch: 26 [65280/113287 (58%)]\tLoss: 1.056680\n",
      "Train Epoch: 26 [66560/113287 (59%)]\tLoss: 0.861872\n",
      "Train Epoch: 26 [67840/113287 (60%)]\tLoss: 0.856705\n",
      "Train Epoch: 26 [69120/113287 (61%)]\tLoss: 1.025313\n",
      "Train Epoch: 26 [70400/113287 (62%)]\tLoss: 1.083100\n",
      "Train Epoch: 26 [71680/113287 (63%)]\tLoss: 1.165839\n",
      "Train Epoch: 26 [72960/113287 (64%)]\tLoss: 0.767704\n",
      "Train Epoch: 26 [74240/113287 (65%)]\tLoss: 1.060724\n",
      "Train Epoch: 26 [75520/113287 (67%)]\tLoss: 0.838834\n",
      "Train Epoch: 26 [76800/113287 (68%)]\tLoss: 1.036618\n",
      "Train Epoch: 26 [78080/113287 (69%)]\tLoss: 0.854971\n",
      "Train Epoch: 26 [79360/113287 (70%)]\tLoss: 0.943633\n",
      "Train Epoch: 26 [80640/113287 (71%)]\tLoss: 0.893837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26 [81920/113287 (72%)]\tLoss: 0.893694\n",
      "Train Epoch: 26 [83200/113287 (73%)]\tLoss: 0.986590\n",
      "Train Epoch: 26 [84480/113287 (74%)]\tLoss: 0.982392\n",
      "Train Epoch: 26 [85760/113287 (76%)]\tLoss: 0.953160\n",
      "Train Epoch: 26 [87040/113287 (77%)]\tLoss: 0.938784\n",
      "Train Epoch: 26 [88320/113287 (78%)]\tLoss: 1.239315\n",
      "Train Epoch: 26 [89600/113287 (79%)]\tLoss: 1.027084\n",
      "Train Epoch: 26 [90880/113287 (80%)]\tLoss: 1.096388\n",
      "Train Epoch: 26 [92160/113287 (81%)]\tLoss: 1.127746\n",
      "Train Epoch: 26 [93440/113287 (82%)]\tLoss: 0.718186\n",
      "Train Epoch: 26 [94720/113287 (84%)]\tLoss: 1.029915\n",
      "Train Epoch: 26 [96000/113287 (85%)]\tLoss: 1.102729\n",
      "Train Epoch: 26 [97280/113287 (86%)]\tLoss: 0.957176\n",
      "Train Epoch: 26 [98560/113287 (87%)]\tLoss: 0.941880\n",
      "Train Epoch: 26 [99840/113287 (88%)]\tLoss: 0.806299\n",
      "Train Epoch: 26 [101120/113287 (89%)]\tLoss: 0.944423\n",
      "Train Epoch: 26 [102400/113287 (90%)]\tLoss: 0.990725\n",
      "Train Epoch: 26 [103680/113287 (91%)]\tLoss: 1.307031\n",
      "Train Epoch: 26 [104960/113287 (93%)]\tLoss: 1.281193\n",
      "Train Epoch: 26 [106240/113287 (94%)]\tLoss: 1.146917\n",
      "Train Epoch: 26 [107520/113287 (95%)]\tLoss: 0.755678\n",
      "Train Epoch: 26 [108800/113287 (96%)]\tLoss: 0.905802\n",
      "Train Epoch: 26 [110080/113287 (97%)]\tLoss: 1.074851\n",
      "Train Epoch: 26 [111360/113287 (98%)]\tLoss: 0.907525\n",
      "Train Epoch: 26 [112640/113287 (99%)]\tLoss: 1.212323\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3519/5000 (70%)\n",
      "\n",
      "Train Epoch: 27 [0/113287 (0%)]\tLoss: 1.065907\n",
      "Train Epoch: 27 [1280/113287 (1%)]\tLoss: 0.867315\n",
      "Train Epoch: 27 [2560/113287 (2%)]\tLoss: 1.012298\n",
      "Train Epoch: 27 [3840/113287 (3%)]\tLoss: 1.053280\n",
      "Train Epoch: 27 [5120/113287 (5%)]\tLoss: 0.769891\n",
      "Train Epoch: 27 [6400/113287 (6%)]\tLoss: 0.874963\n",
      "Train Epoch: 27 [7680/113287 (7%)]\tLoss: 0.881424\n",
      "Train Epoch: 27 [8960/113287 (8%)]\tLoss: 1.108826\n",
      "Train Epoch: 27 [10240/113287 (9%)]\tLoss: 0.948046\n",
      "Train Epoch: 27 [11520/113287 (10%)]\tLoss: 0.975930\n",
      "Train Epoch: 27 [12800/113287 (11%)]\tLoss: 0.975628\n",
      "Train Epoch: 27 [14080/113287 (12%)]\tLoss: 0.842453\n",
      "Train Epoch: 27 [15360/113287 (14%)]\tLoss: 0.898368\n",
      "Train Epoch: 27 [16640/113287 (15%)]\tLoss: 1.091262\n",
      "Train Epoch: 27 [17920/113287 (16%)]\tLoss: 0.937858\n",
      "Train Epoch: 27 [19200/113287 (17%)]\tLoss: 0.915065\n",
      "Train Epoch: 27 [20480/113287 (18%)]\tLoss: 1.125460\n",
      "Train Epoch: 27 [21760/113287 (19%)]\tLoss: 1.021481\n",
      "Train Epoch: 27 [23040/113287 (20%)]\tLoss: 1.136150\n",
      "Train Epoch: 27 [24320/113287 (21%)]\tLoss: 1.092171\n",
      "Train Epoch: 27 [25600/113287 (23%)]\tLoss: 0.938717\n",
      "Train Epoch: 27 [26880/113287 (24%)]\tLoss: 1.055311\n",
      "Train Epoch: 27 [28160/113287 (25%)]\tLoss: 0.847674\n",
      "Train Epoch: 27 [29440/113287 (26%)]\tLoss: 0.883636\n",
      "Train Epoch: 27 [30720/113287 (27%)]\tLoss: 1.038779\n",
      "Train Epoch: 27 [32000/113287 (28%)]\tLoss: 0.942978\n",
      "Train Epoch: 27 [33280/113287 (29%)]\tLoss: 0.952057\n",
      "Train Epoch: 27 [34560/113287 (30%)]\tLoss: 0.828346\n",
      "Train Epoch: 27 [35840/113287 (32%)]\tLoss: 1.051683\n",
      "Train Epoch: 27 [37120/113287 (33%)]\tLoss: 0.969832\n",
      "Train Epoch: 27 [38400/113287 (34%)]\tLoss: 0.916392\n",
      "Train Epoch: 27 [39680/113287 (35%)]\tLoss: 0.990040\n",
      "Train Epoch: 27 [40960/113287 (36%)]\tLoss: 1.194176\n",
      "Train Epoch: 27 [42240/113287 (37%)]\tLoss: 1.113955\n",
      "Train Epoch: 27 [43520/113287 (38%)]\tLoss: 1.127890\n",
      "Train Epoch: 27 [44800/113287 (40%)]\tLoss: 0.895386\n",
      "Train Epoch: 27 [46080/113287 (41%)]\tLoss: 0.989241\n",
      "Train Epoch: 27 [47360/113287 (42%)]\tLoss: 0.887479\n",
      "Train Epoch: 27 [48640/113287 (43%)]\tLoss: 1.006765\n",
      "Train Epoch: 27 [49920/113287 (44%)]\tLoss: 1.020982\n",
      "Train Epoch: 27 [51200/113287 (45%)]\tLoss: 0.847963\n",
      "Train Epoch: 27 [52480/113287 (46%)]\tLoss: 1.040722\n",
      "Train Epoch: 27 [53760/113287 (47%)]\tLoss: 1.303384\n",
      "Train Epoch: 27 [55040/113287 (49%)]\tLoss: 1.013654\n",
      "Train Epoch: 27 [56320/113287 (50%)]\tLoss: 1.096807\n",
      "Train Epoch: 27 [57600/113287 (51%)]\tLoss: 1.006463\n",
      "Train Epoch: 27 [58880/113287 (52%)]\tLoss: 0.929057\n",
      "Train Epoch: 27 [60160/113287 (53%)]\tLoss: 0.911533\n",
      "Train Epoch: 27 [61440/113287 (54%)]\tLoss: 1.141314\n",
      "Train Epoch: 27 [62720/113287 (55%)]\tLoss: 0.795885\n",
      "Train Epoch: 27 [64000/113287 (56%)]\tLoss: 1.012056\n",
      "Train Epoch: 27 [65280/113287 (58%)]\tLoss: 0.760748\n",
      "Train Epoch: 27 [66560/113287 (59%)]\tLoss: 1.133323\n",
      "Train Epoch: 27 [67840/113287 (60%)]\tLoss: 0.975534\n",
      "Train Epoch: 27 [69120/113287 (61%)]\tLoss: 0.952011\n",
      "Train Epoch: 27 [70400/113287 (62%)]\tLoss: 1.164713\n",
      "Train Epoch: 27 [71680/113287 (63%)]\tLoss: 0.954696\n",
      "Train Epoch: 27 [72960/113287 (64%)]\tLoss: 0.806117\n",
      "Train Epoch: 27 [74240/113287 (65%)]\tLoss: 0.806211\n",
      "Train Epoch: 27 [75520/113287 (67%)]\tLoss: 0.911207\n",
      "Train Epoch: 27 [76800/113287 (68%)]\tLoss: 1.017989\n",
      "Train Epoch: 27 [78080/113287 (69%)]\tLoss: 0.791398\n",
      "Train Epoch: 27 [79360/113287 (70%)]\tLoss: 0.919849\n",
      "Train Epoch: 27 [80640/113287 (71%)]\tLoss: 0.991615\n",
      "Train Epoch: 27 [81920/113287 (72%)]\tLoss: 1.098526\n",
      "Train Epoch: 27 [83200/113287 (73%)]\tLoss: 0.939570\n",
      "Train Epoch: 27 [84480/113287 (74%)]\tLoss: 0.832199\n",
      "Train Epoch: 27 [85760/113287 (76%)]\tLoss: 1.021881\n",
      "Train Epoch: 27 [87040/113287 (77%)]\tLoss: 0.936755\n",
      "Train Epoch: 27 [88320/113287 (78%)]\tLoss: 0.974592\n",
      "Train Epoch: 27 [89600/113287 (79%)]\tLoss: 0.927857\n",
      "Train Epoch: 27 [90880/113287 (80%)]\tLoss: 1.015916\n",
      "Train Epoch: 27 [92160/113287 (81%)]\tLoss: 1.117486\n",
      "Train Epoch: 27 [93440/113287 (82%)]\tLoss: 1.211170\n",
      "Train Epoch: 27 [94720/113287 (84%)]\tLoss: 0.937832\n",
      "Train Epoch: 27 [96000/113287 (85%)]\tLoss: 0.973786\n",
      "Train Epoch: 27 [97280/113287 (86%)]\tLoss: 1.039587\n",
      "Train Epoch: 27 [98560/113287 (87%)]\tLoss: 0.989781\n",
      "Train Epoch: 27 [99840/113287 (88%)]\tLoss: 1.025245\n",
      "Train Epoch: 27 [101120/113287 (89%)]\tLoss: 1.111805\n",
      "Train Epoch: 27 [102400/113287 (90%)]\tLoss: 0.757213\n",
      "Train Epoch: 27 [103680/113287 (91%)]\tLoss: 1.063312\n",
      "Train Epoch: 27 [104960/113287 (93%)]\tLoss: 1.043735\n",
      "Train Epoch: 27 [106240/113287 (94%)]\tLoss: 0.741736\n",
      "Train Epoch: 27 [107520/113287 (95%)]\tLoss: 1.118606\n",
      "Train Epoch: 27 [108800/113287 (96%)]\tLoss: 0.917510\n",
      "Train Epoch: 27 [110080/113287 (97%)]\tLoss: 1.186963\n",
      "Train Epoch: 27 [111360/113287 (98%)]\tLoss: 1.060702\n",
      "Train Epoch: 27 [112640/113287 (99%)]\tLoss: 0.907556\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3537/5000 (70%)\n",
      "\n",
      "Train Epoch: 28 [0/113287 (0%)]\tLoss: 0.907615\n",
      "Train Epoch: 28 [1280/113287 (1%)]\tLoss: 0.836157\n",
      "Train Epoch: 28 [2560/113287 (2%)]\tLoss: 0.918819\n",
      "Train Epoch: 28 [3840/113287 (3%)]\tLoss: 0.806937\n",
      "Train Epoch: 28 [5120/113287 (5%)]\tLoss: 1.030633\n",
      "Train Epoch: 28 [6400/113287 (6%)]\tLoss: 0.880141\n",
      "Train Epoch: 28 [7680/113287 (7%)]\tLoss: 0.970058\n",
      "Train Epoch: 28 [8960/113287 (8%)]\tLoss: 0.933822\n",
      "Train Epoch: 28 [10240/113287 (9%)]\tLoss: 0.913266\n",
      "Train Epoch: 28 [11520/113287 (10%)]\tLoss: 1.004354\n",
      "Train Epoch: 28 [12800/113287 (11%)]\tLoss: 1.014974\n",
      "Train Epoch: 28 [14080/113287 (12%)]\tLoss: 0.949869\n",
      "Train Epoch: 28 [15360/113287 (14%)]\tLoss: 1.143901\n",
      "Train Epoch: 28 [16640/113287 (15%)]\tLoss: 1.000817\n",
      "Train Epoch: 28 [17920/113287 (16%)]\tLoss: 1.039885\n",
      "Train Epoch: 28 [19200/113287 (17%)]\tLoss: 0.586330\n",
      "Train Epoch: 28 [20480/113287 (18%)]\tLoss: 0.872129\n",
      "Train Epoch: 28 [21760/113287 (19%)]\tLoss: 0.956889\n",
      "Train Epoch: 28 [23040/113287 (20%)]\tLoss: 0.864198\n",
      "Train Epoch: 28 [24320/113287 (21%)]\tLoss: 0.709206\n",
      "Train Epoch: 28 [25600/113287 (23%)]\tLoss: 0.708414\n",
      "Train Epoch: 28 [26880/113287 (24%)]\tLoss: 0.951209\n",
      "Train Epoch: 28 [28160/113287 (25%)]\tLoss: 0.985887\n",
      "Train Epoch: 28 [29440/113287 (26%)]\tLoss: 1.044664\n",
      "Train Epoch: 28 [30720/113287 (27%)]\tLoss: 0.944885\n",
      "Train Epoch: 28 [32000/113287 (28%)]\tLoss: 1.092510\n",
      "Train Epoch: 28 [33280/113287 (29%)]\tLoss: 1.024312\n",
      "Train Epoch: 28 [34560/113287 (30%)]\tLoss: 0.804003\n",
      "Train Epoch: 28 [35840/113287 (32%)]\tLoss: 0.816756\n",
      "Train Epoch: 28 [37120/113287 (33%)]\tLoss: 1.125723\n",
      "Train Epoch: 28 [38400/113287 (34%)]\tLoss: 0.996721\n",
      "Train Epoch: 28 [39680/113287 (35%)]\tLoss: 0.913178\n",
      "Train Epoch: 28 [40960/113287 (36%)]\tLoss: 0.960550\n",
      "Train Epoch: 28 [42240/113287 (37%)]\tLoss: 1.007361\n",
      "Train Epoch: 28 [43520/113287 (38%)]\tLoss: 1.031221\n",
      "Train Epoch: 28 [44800/113287 (40%)]\tLoss: 0.802325\n",
      "Train Epoch: 28 [46080/113287 (41%)]\tLoss: 0.932792\n",
      "Train Epoch: 28 [47360/113287 (42%)]\tLoss: 0.760995\n",
      "Train Epoch: 28 [48640/113287 (43%)]\tLoss: 0.995194\n",
      "Train Epoch: 28 [49920/113287 (44%)]\tLoss: 1.139008\n",
      "Train Epoch: 28 [51200/113287 (45%)]\tLoss: 0.874009\n",
      "Train Epoch: 28 [52480/113287 (46%)]\tLoss: 1.049102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28 [53760/113287 (47%)]\tLoss: 0.986635\n",
      "Train Epoch: 28 [55040/113287 (49%)]\tLoss: 0.654582\n",
      "Train Epoch: 28 [56320/113287 (50%)]\tLoss: 1.094969\n",
      "Train Epoch: 28 [57600/113287 (51%)]\tLoss: 0.796019\n",
      "Train Epoch: 28 [58880/113287 (52%)]\tLoss: 0.882140\n",
      "Train Epoch: 28 [60160/113287 (53%)]\tLoss: 1.078823\n",
      "Train Epoch: 28 [61440/113287 (54%)]\tLoss: 0.995518\n",
      "Train Epoch: 28 [62720/113287 (55%)]\tLoss: 0.955879\n",
      "Train Epoch: 28 [64000/113287 (56%)]\tLoss: 0.893088\n",
      "Train Epoch: 28 [65280/113287 (58%)]\tLoss: 0.819238\n",
      "Train Epoch: 28 [66560/113287 (59%)]\tLoss: 0.917370\n",
      "Train Epoch: 28 [67840/113287 (60%)]\tLoss: 0.898532\n",
      "Train Epoch: 28 [69120/113287 (61%)]\tLoss: 0.768632\n",
      "Train Epoch: 28 [70400/113287 (62%)]\tLoss: 1.052679\n",
      "Train Epoch: 28 [71680/113287 (63%)]\tLoss: 0.674002\n",
      "Train Epoch: 28 [72960/113287 (64%)]\tLoss: 1.165080\n",
      "Train Epoch: 28 [74240/113287 (65%)]\tLoss: 0.981280\n",
      "Train Epoch: 28 [75520/113287 (67%)]\tLoss: 1.012413\n",
      "Train Epoch: 28 [76800/113287 (68%)]\tLoss: 1.136592\n",
      "Train Epoch: 28 [78080/113287 (69%)]\tLoss: 0.907294\n",
      "Train Epoch: 28 [79360/113287 (70%)]\tLoss: 1.199259\n",
      "Train Epoch: 28 [80640/113287 (71%)]\tLoss: 0.832544\n",
      "Train Epoch: 28 [81920/113287 (72%)]\tLoss: 1.173416\n",
      "Train Epoch: 28 [83200/113287 (73%)]\tLoss: 0.899422\n",
      "Train Epoch: 28 [84480/113287 (74%)]\tLoss: 0.787265\n",
      "Train Epoch: 28 [85760/113287 (76%)]\tLoss: 0.823126\n",
      "Train Epoch: 28 [87040/113287 (77%)]\tLoss: 0.963930\n",
      "Train Epoch: 28 [88320/113287 (78%)]\tLoss: 0.947019\n",
      "Train Epoch: 28 [89600/113287 (79%)]\tLoss: 1.321869\n",
      "Train Epoch: 28 [90880/113287 (80%)]\tLoss: 0.978853\n",
      "Train Epoch: 28 [92160/113287 (81%)]\tLoss: 0.719420\n",
      "Train Epoch: 28 [93440/113287 (82%)]\tLoss: 1.007065\n",
      "Train Epoch: 28 [94720/113287 (84%)]\tLoss: 0.858241\n",
      "Train Epoch: 28 [96000/113287 (85%)]\tLoss: 1.191195\n",
      "Train Epoch: 28 [97280/113287 (86%)]\tLoss: 0.914634\n",
      "Train Epoch: 28 [98560/113287 (87%)]\tLoss: 1.039449\n",
      "Train Epoch: 28 [99840/113287 (88%)]\tLoss: 0.833672\n",
      "Train Epoch: 28 [101120/113287 (89%)]\tLoss: 1.131504\n",
      "Train Epoch: 28 [102400/113287 (90%)]\tLoss: 1.078029\n",
      "Train Epoch: 28 [103680/113287 (91%)]\tLoss: 1.050232\n",
      "Train Epoch: 28 [104960/113287 (93%)]\tLoss: 1.056357\n",
      "Train Epoch: 28 [106240/113287 (94%)]\tLoss: 1.170263\n",
      "Train Epoch: 28 [107520/113287 (95%)]\tLoss: 0.808743\n",
      "Train Epoch: 28 [108800/113287 (96%)]\tLoss: 1.037553\n",
      "Train Epoch: 28 [110080/113287 (97%)]\tLoss: 0.823603\n",
      "Train Epoch: 28 [111360/113287 (98%)]\tLoss: 0.943755\n",
      "Train Epoch: 28 [112640/113287 (99%)]\tLoss: 1.068116\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3559/5000 (71%)\n",
      "\n",
      "Train Epoch: 29 [0/113287 (0%)]\tLoss: 0.967413\n",
      "Train Epoch: 29 [1280/113287 (1%)]\tLoss: 1.071300\n",
      "Train Epoch: 29 [2560/113287 (2%)]\tLoss: 1.132004\n",
      "Train Epoch: 29 [3840/113287 (3%)]\tLoss: 0.877401\n",
      "Train Epoch: 29 [5120/113287 (5%)]\tLoss: 1.062374\n",
      "Train Epoch: 29 [6400/113287 (6%)]\tLoss: 0.836860\n",
      "Train Epoch: 29 [7680/113287 (7%)]\tLoss: 1.113846\n",
      "Train Epoch: 29 [8960/113287 (8%)]\tLoss: 1.118614\n",
      "Train Epoch: 29 [10240/113287 (9%)]\tLoss: 1.016890\n",
      "Train Epoch: 29 [11520/113287 (10%)]\tLoss: 0.660988\n",
      "Train Epoch: 29 [12800/113287 (11%)]\tLoss: 1.066674\n",
      "Train Epoch: 29 [14080/113287 (12%)]\tLoss: 0.866047\n",
      "Train Epoch: 29 [15360/113287 (14%)]\tLoss: 0.811671\n",
      "Train Epoch: 29 [16640/113287 (15%)]\tLoss: 0.949683\n",
      "Train Epoch: 29 [17920/113287 (16%)]\tLoss: 0.884488\n",
      "Train Epoch: 29 [19200/113287 (17%)]\tLoss: 1.040208\n",
      "Train Epoch: 29 [20480/113287 (18%)]\tLoss: 1.047445\n",
      "Train Epoch: 29 [21760/113287 (19%)]\tLoss: 0.804197\n",
      "Train Epoch: 29 [23040/113287 (20%)]\tLoss: 0.778274\n",
      "Train Epoch: 29 [24320/113287 (21%)]\tLoss: 0.914162\n",
      "Train Epoch: 29 [25600/113287 (23%)]\tLoss: 1.090743\n",
      "Train Epoch: 29 [26880/113287 (24%)]\tLoss: 0.907768\n",
      "Train Epoch: 29 [28160/113287 (25%)]\tLoss: 0.983062\n",
      "Train Epoch: 29 [29440/113287 (26%)]\tLoss: 0.952855\n",
      "Train Epoch: 29 [30720/113287 (27%)]\tLoss: 0.799311\n",
      "Train Epoch: 29 [32000/113287 (28%)]\tLoss: 1.029254\n",
      "Train Epoch: 29 [33280/113287 (29%)]\tLoss: 0.987784\n",
      "Train Epoch: 29 [34560/113287 (30%)]\tLoss: 0.959526\n",
      "Train Epoch: 29 [35840/113287 (32%)]\tLoss: 0.858104\n",
      "Train Epoch: 29 [37120/113287 (33%)]\tLoss: 1.044449\n",
      "Train Epoch: 29 [38400/113287 (34%)]\tLoss: 0.914660\n",
      "Train Epoch: 29 [39680/113287 (35%)]\tLoss: 1.117647\n",
      "Train Epoch: 29 [40960/113287 (36%)]\tLoss: 0.837393\n",
      "Train Epoch: 29 [42240/113287 (37%)]\tLoss: 0.948651\n",
      "Train Epoch: 29 [43520/113287 (38%)]\tLoss: 0.966809\n",
      "Train Epoch: 29 [44800/113287 (40%)]\tLoss: 0.808326\n",
      "Train Epoch: 29 [46080/113287 (41%)]\tLoss: 0.959549\n",
      "Train Epoch: 29 [47360/113287 (42%)]\tLoss: 0.896900\n",
      "Train Epoch: 29 [48640/113287 (43%)]\tLoss: 0.891508\n",
      "Train Epoch: 29 [49920/113287 (44%)]\tLoss: 0.787725\n",
      "Train Epoch: 29 [51200/113287 (45%)]\tLoss: 0.851959\n",
      "Train Epoch: 29 [52480/113287 (46%)]\tLoss: 1.158385\n",
      "Train Epoch: 29 [53760/113287 (47%)]\tLoss: 0.817560\n",
      "Train Epoch: 29 [55040/113287 (49%)]\tLoss: 0.938589\n",
      "Train Epoch: 29 [56320/113287 (50%)]\tLoss: 0.699565\n",
      "Train Epoch: 29 [57600/113287 (51%)]\tLoss: 1.123581\n",
      "Train Epoch: 29 [58880/113287 (52%)]\tLoss: 0.856041\n",
      "Train Epoch: 29 [60160/113287 (53%)]\tLoss: 0.919986\n",
      "Train Epoch: 29 [61440/113287 (54%)]\tLoss: 1.022296\n",
      "Train Epoch: 29 [62720/113287 (55%)]\tLoss: 0.954427\n",
      "Train Epoch: 29 [64000/113287 (56%)]\tLoss: 0.853924\n",
      "Train Epoch: 29 [65280/113287 (58%)]\tLoss: 1.105704\n",
      "Train Epoch: 29 [66560/113287 (59%)]\tLoss: 0.931945\n",
      "Train Epoch: 29 [67840/113287 (60%)]\tLoss: 1.025832\n",
      "Train Epoch: 29 [69120/113287 (61%)]\tLoss: 0.767509\n",
      "Train Epoch: 29 [70400/113287 (62%)]\tLoss: 0.770405\n",
      "Train Epoch: 29 [71680/113287 (63%)]\tLoss: 0.927831\n",
      "Train Epoch: 29 [72960/113287 (64%)]\tLoss: 1.030609\n",
      "Train Epoch: 29 [74240/113287 (65%)]\tLoss: 0.819997\n",
      "Train Epoch: 29 [75520/113287 (67%)]\tLoss: 1.127469\n",
      "Train Epoch: 29 [76800/113287 (68%)]\tLoss: 0.967951\n",
      "Train Epoch: 29 [78080/113287 (69%)]\tLoss: 0.906307\n",
      "Train Epoch: 29 [79360/113287 (70%)]\tLoss: 1.028172\n",
      "Train Epoch: 29 [80640/113287 (71%)]\tLoss: 0.925350\n",
      "Train Epoch: 29 [81920/113287 (72%)]\tLoss: 1.003471\n",
      "Train Epoch: 29 [83200/113287 (73%)]\tLoss: 0.932525\n",
      "Train Epoch: 29 [84480/113287 (74%)]\tLoss: 0.873082\n",
      "Train Epoch: 29 [85760/113287 (76%)]\tLoss: 1.041233\n",
      "Train Epoch: 29 [87040/113287 (77%)]\tLoss: 0.988553\n",
      "Train Epoch: 29 [88320/113287 (78%)]\tLoss: 0.910958\n",
      "Train Epoch: 29 [89600/113287 (79%)]\tLoss: 1.003790\n",
      "Train Epoch: 29 [90880/113287 (80%)]\tLoss: 0.872861\n",
      "Train Epoch: 29 [92160/113287 (81%)]\tLoss: 0.990617\n",
      "Train Epoch: 29 [93440/113287 (82%)]\tLoss: 0.818225\n",
      "Train Epoch: 29 [94720/113287 (84%)]\tLoss: 1.287205\n",
      "Train Epoch: 29 [96000/113287 (85%)]\tLoss: 1.007122\n",
      "Train Epoch: 29 [97280/113287 (86%)]\tLoss: 0.983248\n",
      "Train Epoch: 29 [98560/113287 (87%)]\tLoss: 0.822442\n",
      "Train Epoch: 29 [99840/113287 (88%)]\tLoss: 0.886450\n",
      "Train Epoch: 29 [101120/113287 (89%)]\tLoss: 0.819281\n",
      "Train Epoch: 29 [102400/113287 (90%)]\tLoss: 1.061940\n",
      "Train Epoch: 29 [103680/113287 (91%)]\tLoss: 1.070766\n",
      "Train Epoch: 29 [104960/113287 (93%)]\tLoss: 0.864205\n",
      "Train Epoch: 29 [106240/113287 (94%)]\tLoss: 0.948306\n",
      "Train Epoch: 29 [107520/113287 (95%)]\tLoss: 0.921047\n",
      "Train Epoch: 29 [108800/113287 (96%)]\tLoss: 1.041109\n",
      "Train Epoch: 29 [110080/113287 (97%)]\tLoss: 0.981697\n",
      "Train Epoch: 29 [111360/113287 (98%)]\tLoss: 0.789718\n",
      "Train Epoch: 29 [112640/113287 (99%)]\tLoss: 0.934408\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3559/5000 (71%)\n",
      "\n",
      "Train Epoch: 30 [0/113287 (0%)]\tLoss: 1.134799\n",
      "Train Epoch: 30 [1280/113287 (1%)]\tLoss: 0.942703\n",
      "Train Epoch: 30 [2560/113287 (2%)]\tLoss: 0.908327\n",
      "Train Epoch: 30 [3840/113287 (3%)]\tLoss: 0.955904\n",
      "Train Epoch: 30 [5120/113287 (5%)]\tLoss: 1.071717\n",
      "Train Epoch: 30 [6400/113287 (6%)]\tLoss: 0.862625\n",
      "Train Epoch: 30 [7680/113287 (7%)]\tLoss: 1.036265\n",
      "Train Epoch: 30 [8960/113287 (8%)]\tLoss: 1.035646\n",
      "Train Epoch: 30 [10240/113287 (9%)]\tLoss: 1.075162\n",
      "Train Epoch: 30 [11520/113287 (10%)]\tLoss: 1.000996\n",
      "Train Epoch: 30 [12800/113287 (11%)]\tLoss: 1.120756\n",
      "Train Epoch: 30 [14080/113287 (12%)]\tLoss: 0.921569\n",
      "Train Epoch: 30 [15360/113287 (14%)]\tLoss: 1.074705\n",
      "Train Epoch: 30 [16640/113287 (15%)]\tLoss: 0.947523\n",
      "Train Epoch: 30 [17920/113287 (16%)]\tLoss: 0.953331\n",
      "Train Epoch: 30 [19200/113287 (17%)]\tLoss: 0.635298\n",
      "Train Epoch: 30 [20480/113287 (18%)]\tLoss: 1.077504\n",
      "Train Epoch: 30 [21760/113287 (19%)]\tLoss: 0.841360\n",
      "Train Epoch: 30 [23040/113287 (20%)]\tLoss: 1.146432\n",
      "Train Epoch: 30 [24320/113287 (21%)]\tLoss: 0.760855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 30 [25600/113287 (23%)]\tLoss: 0.726335\n",
      "Train Epoch: 30 [26880/113287 (24%)]\tLoss: 0.716320\n",
      "Train Epoch: 30 [28160/113287 (25%)]\tLoss: 1.088056\n",
      "Train Epoch: 30 [29440/113287 (26%)]\tLoss: 0.727689\n",
      "Train Epoch: 30 [30720/113287 (27%)]\tLoss: 0.782818\n",
      "Train Epoch: 30 [32000/113287 (28%)]\tLoss: 1.169133\n",
      "Train Epoch: 30 [33280/113287 (29%)]\tLoss: 1.194017\n",
      "Train Epoch: 30 [34560/113287 (30%)]\tLoss: 1.014275\n",
      "Train Epoch: 30 [35840/113287 (32%)]\tLoss: 1.063452\n",
      "Train Epoch: 30 [37120/113287 (33%)]\tLoss: 0.958407\n",
      "Train Epoch: 30 [38400/113287 (34%)]\tLoss: 0.919318\n",
      "Train Epoch: 30 [39680/113287 (35%)]\tLoss: 1.018817\n",
      "Train Epoch: 30 [40960/113287 (36%)]\tLoss: 1.114315\n",
      "Train Epoch: 30 [42240/113287 (37%)]\tLoss: 0.748143\n",
      "Train Epoch: 30 [43520/113287 (38%)]\tLoss: 1.261402\n",
      "Train Epoch: 30 [44800/113287 (40%)]\tLoss: 1.026423\n",
      "Train Epoch: 30 [46080/113287 (41%)]\tLoss: 0.933276\n",
      "Train Epoch: 30 [47360/113287 (42%)]\tLoss: 0.708682\n",
      "Train Epoch: 30 [48640/113287 (43%)]\tLoss: 0.715317\n",
      "Train Epoch: 30 [49920/113287 (44%)]\tLoss: 1.041375\n",
      "Train Epoch: 30 [51200/113287 (45%)]\tLoss: 0.988348\n",
      "Train Epoch: 30 [52480/113287 (46%)]\tLoss: 0.922779\n",
      "Train Epoch: 30 [53760/113287 (47%)]\tLoss: 1.146231\n",
      "Train Epoch: 30 [55040/113287 (49%)]\tLoss: 0.890885\n",
      "Train Epoch: 30 [56320/113287 (50%)]\tLoss: 1.123080\n",
      "Train Epoch: 30 [57600/113287 (51%)]\tLoss: 0.883630\n",
      "Train Epoch: 30 [58880/113287 (52%)]\tLoss: 1.157153\n",
      "Train Epoch: 30 [60160/113287 (53%)]\tLoss: 0.716972\n",
      "Train Epoch: 30 [61440/113287 (54%)]\tLoss: 0.908488\n",
      "Train Epoch: 30 [62720/113287 (55%)]\tLoss: 0.997170\n",
      "Train Epoch: 30 [64000/113287 (56%)]\tLoss: 0.835334\n",
      "Train Epoch: 30 [65280/113287 (58%)]\tLoss: 1.011098\n",
      "Train Epoch: 30 [66560/113287 (59%)]\tLoss: 1.192198\n",
      "Train Epoch: 30 [67840/113287 (60%)]\tLoss: 0.892890\n",
      "Train Epoch: 30 [69120/113287 (61%)]\tLoss: 0.999264\n",
      "Train Epoch: 30 [70400/113287 (62%)]\tLoss: 0.998756\n",
      "Train Epoch: 30 [71680/113287 (63%)]\tLoss: 0.888612\n",
      "Train Epoch: 30 [72960/113287 (64%)]\tLoss: 0.977592\n",
      "Train Epoch: 30 [74240/113287 (65%)]\tLoss: 1.021881\n",
      "Train Epoch: 30 [75520/113287 (67%)]\tLoss: 0.948209\n",
      "Train Epoch: 30 [76800/113287 (68%)]\tLoss: 0.847928\n",
      "Train Epoch: 30 [78080/113287 (69%)]\tLoss: 0.916077\n",
      "Train Epoch: 30 [79360/113287 (70%)]\tLoss: 1.003127\n",
      "Train Epoch: 30 [80640/113287 (71%)]\tLoss: 1.076345\n",
      "Train Epoch: 30 [81920/113287 (72%)]\tLoss: 0.872987\n",
      "Train Epoch: 30 [83200/113287 (73%)]\tLoss: 0.859874\n",
      "Train Epoch: 30 [84480/113287 (74%)]\tLoss: 0.984180\n",
      "Train Epoch: 30 [85760/113287 (76%)]\tLoss: 0.909845\n",
      "Train Epoch: 30 [87040/113287 (77%)]\tLoss: 0.963975\n",
      "Train Epoch: 30 [88320/113287 (78%)]\tLoss: 0.878133\n",
      "Train Epoch: 30 [89600/113287 (79%)]\tLoss: 0.902697\n",
      "Train Epoch: 30 [90880/113287 (80%)]\tLoss: 0.952838\n",
      "Train Epoch: 30 [92160/113287 (81%)]\tLoss: 0.920202\n",
      "Train Epoch: 30 [93440/113287 (82%)]\tLoss: 0.842726\n",
      "Train Epoch: 30 [94720/113287 (84%)]\tLoss: 0.886073\n",
      "Train Epoch: 30 [96000/113287 (85%)]\tLoss: 1.111796\n",
      "Train Epoch: 30 [97280/113287 (86%)]\tLoss: 0.844891\n",
      "Train Epoch: 30 [98560/113287 (87%)]\tLoss: 1.065380\n",
      "Train Epoch: 30 [99840/113287 (88%)]\tLoss: 0.758524\n",
      "Train Epoch: 30 [101120/113287 (89%)]\tLoss: 0.912793\n",
      "Train Epoch: 30 [102400/113287 (90%)]\tLoss: 0.866326\n",
      "Train Epoch: 30 [103680/113287 (91%)]\tLoss: 0.963564\n",
      "Train Epoch: 30 [104960/113287 (93%)]\tLoss: 0.915571\n",
      "Train Epoch: 30 [106240/113287 (94%)]\tLoss: 0.771626\n",
      "Train Epoch: 30 [107520/113287 (95%)]\tLoss: 1.113913\n",
      "Train Epoch: 30 [108800/113287 (96%)]\tLoss: 1.185622\n",
      "Train Epoch: 30 [110080/113287 (97%)]\tLoss: 0.936867\n",
      "Train Epoch: 30 [111360/113287 (98%)]\tLoss: 1.070682\n",
      "Train Epoch: 30 [112640/113287 (99%)]\tLoss: 0.895985\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3581/5000 (71%)\n",
      "\n",
      "Train Epoch: 31 [0/113287 (0%)]\tLoss: 0.912614\n",
      "Train Epoch: 31 [1280/113287 (1%)]\tLoss: 0.780677\n",
      "Train Epoch: 31 [2560/113287 (2%)]\tLoss: 0.747444\n",
      "Train Epoch: 31 [3840/113287 (3%)]\tLoss: 0.954791\n",
      "Train Epoch: 31 [5120/113287 (5%)]\tLoss: 1.022828\n",
      "Train Epoch: 31 [6400/113287 (6%)]\tLoss: 0.999808\n",
      "Train Epoch: 31 [7680/113287 (7%)]\tLoss: 0.936817\n",
      "Train Epoch: 31 [8960/113287 (8%)]\tLoss: 0.788505\n",
      "Train Epoch: 31 [10240/113287 (9%)]\tLoss: 0.946743\n",
      "Train Epoch: 31 [11520/113287 (10%)]\tLoss: 0.913397\n",
      "Train Epoch: 31 [12800/113287 (11%)]\tLoss: 0.903584\n",
      "Train Epoch: 31 [14080/113287 (12%)]\tLoss: 0.834738\n",
      "Train Epoch: 31 [15360/113287 (14%)]\tLoss: 1.043855\n",
      "Train Epoch: 31 [16640/113287 (15%)]\tLoss: 0.860924\n",
      "Train Epoch: 31 [17920/113287 (16%)]\tLoss: 0.924520\n",
      "Train Epoch: 31 [19200/113287 (17%)]\tLoss: 1.110074\n",
      "Train Epoch: 31 [20480/113287 (18%)]\tLoss: 0.695014\n",
      "Train Epoch: 31 [21760/113287 (19%)]\tLoss: 0.968038\n",
      "Train Epoch: 31 [23040/113287 (20%)]\tLoss: 0.965954\n",
      "Train Epoch: 31 [24320/113287 (21%)]\tLoss: 0.905188\n",
      "Train Epoch: 31 [25600/113287 (23%)]\tLoss: 0.708830\n",
      "Train Epoch: 31 [26880/113287 (24%)]\tLoss: 0.856219\n",
      "Train Epoch: 31 [28160/113287 (25%)]\tLoss: 0.982570\n",
      "Train Epoch: 31 [29440/113287 (26%)]\tLoss: 1.173094\n",
      "Train Epoch: 31 [30720/113287 (27%)]\tLoss: 0.800791\n",
      "Train Epoch: 31 [32000/113287 (28%)]\tLoss: 0.890807\n",
      "Train Epoch: 31 [33280/113287 (29%)]\tLoss: 0.901629\n",
      "Train Epoch: 31 [34560/113287 (30%)]\tLoss: 0.915721\n",
      "Train Epoch: 31 [35840/113287 (32%)]\tLoss: 1.014637\n",
      "Train Epoch: 31 [37120/113287 (33%)]\tLoss: 0.951706\n",
      "Train Epoch: 31 [38400/113287 (34%)]\tLoss: 0.932885\n",
      "Train Epoch: 31 [39680/113287 (35%)]\tLoss: 0.844164\n",
      "Train Epoch: 31 [40960/113287 (36%)]\tLoss: 1.052300\n",
      "Train Epoch: 31 [42240/113287 (37%)]\tLoss: 1.015316\n",
      "Train Epoch: 31 [43520/113287 (38%)]\tLoss: 1.093930\n",
      "Train Epoch: 31 [44800/113287 (40%)]\tLoss: 0.880225\n",
      "Train Epoch: 31 [46080/113287 (41%)]\tLoss: 0.916233\n",
      "Train Epoch: 31 [47360/113287 (42%)]\tLoss: 0.826571\n",
      "Train Epoch: 31 [48640/113287 (43%)]\tLoss: 0.863200\n",
      "Train Epoch: 31 [49920/113287 (44%)]\tLoss: 1.400178\n",
      "Train Epoch: 31 [51200/113287 (45%)]\tLoss: 0.547241\n",
      "Train Epoch: 31 [52480/113287 (46%)]\tLoss: 1.062202\n",
      "Train Epoch: 31 [53760/113287 (47%)]\tLoss: 0.964058\n",
      "Train Epoch: 31 [55040/113287 (49%)]\tLoss: 0.906966\n",
      "Train Epoch: 31 [56320/113287 (50%)]\tLoss: 0.897989\n",
      "Train Epoch: 31 [57600/113287 (51%)]\tLoss: 0.963970\n",
      "Train Epoch: 31 [58880/113287 (52%)]\tLoss: 0.849325\n",
      "Train Epoch: 31 [60160/113287 (53%)]\tLoss: 1.229869\n",
      "Train Epoch: 31 [61440/113287 (54%)]\tLoss: 0.980218\n",
      "Train Epoch: 31 [62720/113287 (55%)]\tLoss: 0.923859\n",
      "Train Epoch: 31 [64000/113287 (56%)]\tLoss: 0.919128\n",
      "Train Epoch: 31 [65280/113287 (58%)]\tLoss: 0.897138\n",
      "Train Epoch: 31 [66560/113287 (59%)]\tLoss: 1.037139\n",
      "Train Epoch: 31 [67840/113287 (60%)]\tLoss: 1.070589\n",
      "Train Epoch: 31 [69120/113287 (61%)]\tLoss: 0.924875\n",
      "Train Epoch: 31 [70400/113287 (62%)]\tLoss: 0.878580\n",
      "Train Epoch: 31 [71680/113287 (63%)]\tLoss: 0.848855\n",
      "Train Epoch: 31 [72960/113287 (64%)]\tLoss: 0.743899\n",
      "Train Epoch: 31 [74240/113287 (65%)]\tLoss: 0.835210\n",
      "Train Epoch: 31 [75520/113287 (67%)]\tLoss: 1.128750\n",
      "Train Epoch: 31 [76800/113287 (68%)]\tLoss: 0.957981\n",
      "Train Epoch: 31 [78080/113287 (69%)]\tLoss: 1.129526\n",
      "Train Epoch: 31 [79360/113287 (70%)]\tLoss: 1.070610\n",
      "Train Epoch: 31 [80640/113287 (71%)]\tLoss: 0.924995\n",
      "Train Epoch: 31 [81920/113287 (72%)]\tLoss: 1.021843\n",
      "Train Epoch: 31 [83200/113287 (73%)]\tLoss: 1.030881\n",
      "Train Epoch: 31 [84480/113287 (74%)]\tLoss: 0.765454\n",
      "Train Epoch: 31 [85760/113287 (76%)]\tLoss: 0.951713\n",
      "Train Epoch: 31 [87040/113287 (77%)]\tLoss: 0.767170\n",
      "Train Epoch: 31 [88320/113287 (78%)]\tLoss: 1.143347\n",
      "Train Epoch: 31 [89600/113287 (79%)]\tLoss: 0.864383\n",
      "Train Epoch: 31 [90880/113287 (80%)]\tLoss: 0.960219\n",
      "Train Epoch: 31 [92160/113287 (81%)]\tLoss: 0.807234\n",
      "Train Epoch: 31 [93440/113287 (82%)]\tLoss: 1.084892\n",
      "Train Epoch: 31 [94720/113287 (84%)]\tLoss: 0.885215\n",
      "Train Epoch: 31 [96000/113287 (85%)]\tLoss: 0.928495\n",
      "Train Epoch: 31 [97280/113287 (86%)]\tLoss: 1.302643\n",
      "Train Epoch: 31 [98560/113287 (87%)]\tLoss: 0.881030\n",
      "Train Epoch: 31 [99840/113287 (88%)]\tLoss: 0.900514\n",
      "Train Epoch: 31 [101120/113287 (89%)]\tLoss: 0.927791\n",
      "Train Epoch: 31 [102400/113287 (90%)]\tLoss: 0.987020\n",
      "Train Epoch: 31 [103680/113287 (91%)]\tLoss: 0.984497\n",
      "Train Epoch: 31 [104960/113287 (93%)]\tLoss: 0.820378\n",
      "Train Epoch: 31 [106240/113287 (94%)]\tLoss: 0.968857\n",
      "Train Epoch: 31 [107520/113287 (95%)]\tLoss: 1.081070\n",
      "Train Epoch: 31 [108800/113287 (96%)]\tLoss: 0.849938\n",
      "Train Epoch: 31 [110080/113287 (97%)]\tLoss: 0.880409\n",
      "Train Epoch: 31 [111360/113287 (98%)]\tLoss: 0.939698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 31 [112640/113287 (99%)]\tLoss: 1.186357\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3553/5000 (71%)\n",
      "\n",
      "Train Epoch: 32 [0/113287 (0%)]\tLoss: 0.928853\n",
      "Train Epoch: 32 [1280/113287 (1%)]\tLoss: 0.904496\n",
      "Train Epoch: 32 [2560/113287 (2%)]\tLoss: 0.985318\n",
      "Train Epoch: 32 [3840/113287 (3%)]\tLoss: 1.056427\n",
      "Train Epoch: 32 [5120/113287 (5%)]\tLoss: 0.832861\n",
      "Train Epoch: 32 [6400/113287 (6%)]\tLoss: 0.925426\n",
      "Train Epoch: 32 [7680/113287 (7%)]\tLoss: 1.102883\n",
      "Train Epoch: 32 [8960/113287 (8%)]\tLoss: 0.889030\n",
      "Train Epoch: 32 [10240/113287 (9%)]\tLoss: 0.987005\n",
      "Train Epoch: 32 [11520/113287 (10%)]\tLoss: 0.906344\n",
      "Train Epoch: 32 [12800/113287 (11%)]\tLoss: 0.880506\n",
      "Train Epoch: 32 [14080/113287 (12%)]\tLoss: 1.062718\n",
      "Train Epoch: 32 [15360/113287 (14%)]\tLoss: 0.886669\n",
      "Train Epoch: 32 [16640/113287 (15%)]\tLoss: 0.861204\n",
      "Train Epoch: 32 [17920/113287 (16%)]\tLoss: 0.968948\n",
      "Train Epoch: 32 [19200/113287 (17%)]\tLoss: 0.989615\n",
      "Train Epoch: 32 [20480/113287 (18%)]\tLoss: 0.673177\n",
      "Train Epoch: 32 [21760/113287 (19%)]\tLoss: 1.092639\n",
      "Train Epoch: 32 [23040/113287 (20%)]\tLoss: 1.046209\n",
      "Train Epoch: 32 [24320/113287 (21%)]\tLoss: 1.039976\n",
      "Train Epoch: 32 [25600/113287 (23%)]\tLoss: 1.044608\n",
      "Train Epoch: 32 [26880/113287 (24%)]\tLoss: 0.760798\n",
      "Train Epoch: 32 [28160/113287 (25%)]\tLoss: 0.794037\n",
      "Train Epoch: 32 [29440/113287 (26%)]\tLoss: 0.662834\n",
      "Train Epoch: 32 [30720/113287 (27%)]\tLoss: 1.100498\n",
      "Train Epoch: 32 [32000/113287 (28%)]\tLoss: 0.761031\n",
      "Train Epoch: 32 [33280/113287 (29%)]\tLoss: 0.706470\n",
      "Train Epoch: 32 [34560/113287 (30%)]\tLoss: 0.776534\n",
      "Train Epoch: 32 [35840/113287 (32%)]\tLoss: 0.763050\n",
      "Train Epoch: 32 [37120/113287 (33%)]\tLoss: 1.000107\n",
      "Train Epoch: 32 [38400/113287 (34%)]\tLoss: 0.863252\n",
      "Train Epoch: 32 [39680/113287 (35%)]\tLoss: 0.777411\n",
      "Train Epoch: 32 [40960/113287 (36%)]\tLoss: 1.043253\n",
      "Train Epoch: 32 [42240/113287 (37%)]\tLoss: 1.103624\n",
      "Train Epoch: 32 [43520/113287 (38%)]\tLoss: 0.851233\n",
      "Train Epoch: 32 [44800/113287 (40%)]\tLoss: 1.057909\n",
      "Train Epoch: 32 [46080/113287 (41%)]\tLoss: 0.969275\n",
      "Train Epoch: 32 [47360/113287 (42%)]\tLoss: 1.076884\n",
      "Train Epoch: 32 [48640/113287 (43%)]\tLoss: 0.859308\n",
      "Train Epoch: 32 [49920/113287 (44%)]\tLoss: 1.016070\n",
      "Train Epoch: 32 [51200/113287 (45%)]\tLoss: 0.766945\n",
      "Train Epoch: 32 [52480/113287 (46%)]\tLoss: 0.946300\n",
      "Train Epoch: 32 [53760/113287 (47%)]\tLoss: 0.825177\n",
      "Train Epoch: 32 [55040/113287 (49%)]\tLoss: 1.011178\n",
      "Train Epoch: 32 [56320/113287 (50%)]\tLoss: 0.869846\n",
      "Train Epoch: 32 [57600/113287 (51%)]\tLoss: 0.971549\n",
      "Train Epoch: 32 [58880/113287 (52%)]\tLoss: 0.728736\n",
      "Train Epoch: 32 [60160/113287 (53%)]\tLoss: 0.994245\n",
      "Train Epoch: 32 [61440/113287 (54%)]\tLoss: 0.966074\n",
      "Train Epoch: 32 [62720/113287 (55%)]\tLoss: 0.832955\n",
      "Train Epoch: 32 [64000/113287 (56%)]\tLoss: 0.994577\n",
      "Train Epoch: 32 [65280/113287 (58%)]\tLoss: 0.892823\n",
      "Train Epoch: 32 [66560/113287 (59%)]\tLoss: 0.761987\n",
      "Train Epoch: 32 [67840/113287 (60%)]\tLoss: 0.733443\n",
      "Train Epoch: 32 [69120/113287 (61%)]\tLoss: 1.025450\n",
      "Train Epoch: 32 [70400/113287 (62%)]\tLoss: 0.951218\n",
      "Train Epoch: 32 [71680/113287 (63%)]\tLoss: 0.878544\n",
      "Train Epoch: 32 [72960/113287 (64%)]\tLoss: 0.979675\n",
      "Train Epoch: 32 [74240/113287 (65%)]\tLoss: 1.087088\n",
      "Train Epoch: 32 [75520/113287 (67%)]\tLoss: 0.966322\n",
      "Train Epoch: 32 [76800/113287 (68%)]\tLoss: 0.902246\n",
      "Train Epoch: 32 [78080/113287 (69%)]\tLoss: 0.980755\n",
      "Train Epoch: 32 [79360/113287 (70%)]\tLoss: 0.864314\n",
      "Train Epoch: 32 [80640/113287 (71%)]\tLoss: 0.914081\n",
      "Train Epoch: 32 [81920/113287 (72%)]\tLoss: 1.049238\n",
      "Train Epoch: 32 [83200/113287 (73%)]\tLoss: 0.998766\n",
      "Train Epoch: 32 [84480/113287 (74%)]\tLoss: 0.934593\n",
      "Train Epoch: 32 [85760/113287 (76%)]\tLoss: 1.073075\n",
      "Train Epoch: 32 [87040/113287 (77%)]\tLoss: 0.886258\n",
      "Train Epoch: 32 [88320/113287 (78%)]\tLoss: 1.002799\n",
      "Train Epoch: 32 [89600/113287 (79%)]\tLoss: 0.973679\n",
      "Train Epoch: 32 [90880/113287 (80%)]\tLoss: 0.849975\n",
      "Train Epoch: 32 [92160/113287 (81%)]\tLoss: 0.908597\n",
      "Train Epoch: 32 [93440/113287 (82%)]\tLoss: 0.935914\n",
      "Train Epoch: 32 [94720/113287 (84%)]\tLoss: 0.929054\n",
      "Train Epoch: 32 [96000/113287 (85%)]\tLoss: 0.968692\n",
      "Train Epoch: 32 [97280/113287 (86%)]\tLoss: 0.879821\n",
      "Train Epoch: 32 [98560/113287 (87%)]\tLoss: 0.968314\n",
      "Train Epoch: 32 [99840/113287 (88%)]\tLoss: 0.847296\n",
      "Train Epoch: 32 [101120/113287 (89%)]\tLoss: 1.150478\n",
      "Train Epoch: 32 [102400/113287 (90%)]\tLoss: 1.144009\n",
      "Train Epoch: 32 [103680/113287 (91%)]\tLoss: 0.878143\n",
      "Train Epoch: 32 [104960/113287 (93%)]\tLoss: 0.913712\n",
      "Train Epoch: 32 [106240/113287 (94%)]\tLoss: 0.941589\n",
      "Train Epoch: 32 [107520/113287 (95%)]\tLoss: 0.939877\n",
      "Train Epoch: 32 [108800/113287 (96%)]\tLoss: 1.214008\n",
      "Train Epoch: 32 [110080/113287 (97%)]\tLoss: 0.776394\n",
      "Train Epoch: 32 [111360/113287 (98%)]\tLoss: 0.899604\n",
      "Train Epoch: 32 [112640/113287 (99%)]\tLoss: 1.272285\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3552/5000 (71%)\n",
      "\n",
      "Train Epoch: 33 [0/113287 (0%)]\tLoss: 0.891938\n",
      "Train Epoch: 33 [1280/113287 (1%)]\tLoss: 0.738372\n",
      "Train Epoch: 33 [2560/113287 (2%)]\tLoss: 0.763442\n",
      "Train Epoch: 33 [3840/113287 (3%)]\tLoss: 0.986728\n",
      "Train Epoch: 33 [5120/113287 (5%)]\tLoss: 1.138270\n",
      "Train Epoch: 33 [6400/113287 (6%)]\tLoss: 0.710192\n",
      "Train Epoch: 33 [7680/113287 (7%)]\tLoss: 1.097407\n",
      "Train Epoch: 33 [8960/113287 (8%)]\tLoss: 0.845305\n",
      "Train Epoch: 33 [10240/113287 (9%)]\tLoss: 0.691497\n",
      "Train Epoch: 33 [11520/113287 (10%)]\tLoss: 1.047457\n",
      "Train Epoch: 33 [12800/113287 (11%)]\tLoss: 0.928958\n",
      "Train Epoch: 33 [14080/113287 (12%)]\tLoss: 1.159707\n",
      "Train Epoch: 33 [15360/113287 (14%)]\tLoss: 0.864030\n",
      "Train Epoch: 33 [16640/113287 (15%)]\tLoss: 1.179161\n",
      "Train Epoch: 33 [17920/113287 (16%)]\tLoss: 0.853290\n",
      "Train Epoch: 33 [19200/113287 (17%)]\tLoss: 0.981461\n",
      "Train Epoch: 33 [20480/113287 (18%)]\tLoss: 1.044505\n",
      "Train Epoch: 33 [21760/113287 (19%)]\tLoss: 1.063585\n",
      "Train Epoch: 33 [23040/113287 (20%)]\tLoss: 0.765076\n",
      "Train Epoch: 33 [24320/113287 (21%)]\tLoss: 0.879506\n",
      "Train Epoch: 33 [25600/113287 (23%)]\tLoss: 1.018425\n",
      "Train Epoch: 33 [26880/113287 (24%)]\tLoss: 1.189362\n",
      "Train Epoch: 33 [28160/113287 (25%)]\tLoss: 0.931635\n",
      "Train Epoch: 33 [29440/113287 (26%)]\tLoss: 0.995855\n",
      "Train Epoch: 33 [30720/113287 (27%)]\tLoss: 0.920451\n",
      "Train Epoch: 33 [32000/113287 (28%)]\tLoss: 1.119648\n",
      "Train Epoch: 33 [33280/113287 (29%)]\tLoss: 0.882176\n",
      "Train Epoch: 33 [34560/113287 (30%)]\tLoss: 1.028529\n",
      "Train Epoch: 33 [35840/113287 (32%)]\tLoss: 1.069530\n",
      "Train Epoch: 33 [37120/113287 (33%)]\tLoss: 1.023485\n",
      "Train Epoch: 33 [38400/113287 (34%)]\tLoss: 0.964342\n",
      "Train Epoch: 33 [39680/113287 (35%)]\tLoss: 0.834972\n",
      "Train Epoch: 33 [40960/113287 (36%)]\tLoss: 1.172811\n",
      "Train Epoch: 33 [42240/113287 (37%)]\tLoss: 0.895884\n",
      "Train Epoch: 33 [43520/113287 (38%)]\tLoss: 0.880286\n",
      "Train Epoch: 33 [44800/113287 (40%)]\tLoss: 0.913069\n",
      "Train Epoch: 33 [46080/113287 (41%)]\tLoss: 1.021832\n",
      "Train Epoch: 33 [47360/113287 (42%)]\tLoss: 1.105680\n",
      "Train Epoch: 33 [48640/113287 (43%)]\tLoss: 0.973998\n",
      "Train Epoch: 33 [49920/113287 (44%)]\tLoss: 0.840143\n",
      "Train Epoch: 33 [51200/113287 (45%)]\tLoss: 0.856215\n",
      "Train Epoch: 33 [52480/113287 (46%)]\tLoss: 0.853684\n",
      "Train Epoch: 33 [53760/113287 (47%)]\tLoss: 1.040186\n",
      "Train Epoch: 33 [55040/113287 (49%)]\tLoss: 0.915262\n",
      "Train Epoch: 33 [56320/113287 (50%)]\tLoss: 0.995119\n",
      "Train Epoch: 33 [57600/113287 (51%)]\tLoss: 0.972078\n",
      "Train Epoch: 33 [58880/113287 (52%)]\tLoss: 1.152959\n",
      "Train Epoch: 33 [60160/113287 (53%)]\tLoss: 0.843867\n",
      "Train Epoch: 33 [61440/113287 (54%)]\tLoss: 0.944551\n",
      "Train Epoch: 33 [62720/113287 (55%)]\tLoss: 0.946355\n",
      "Train Epoch: 33 [64000/113287 (56%)]\tLoss: 0.916404\n",
      "Train Epoch: 33 [65280/113287 (58%)]\tLoss: 1.031358\n",
      "Train Epoch: 33 [66560/113287 (59%)]\tLoss: 0.843246\n",
      "Train Epoch: 33 [67840/113287 (60%)]\tLoss: 1.192442\n",
      "Train Epoch: 33 [69120/113287 (61%)]\tLoss: 0.863954\n",
      "Train Epoch: 33 [70400/113287 (62%)]\tLoss: 0.859651\n",
      "Train Epoch: 33 [71680/113287 (63%)]\tLoss: 1.295965\n",
      "Train Epoch: 33 [72960/113287 (64%)]\tLoss: 0.654871\n",
      "Train Epoch: 33 [74240/113287 (65%)]\tLoss: 0.815305\n",
      "Train Epoch: 33 [75520/113287 (67%)]\tLoss: 1.170640\n",
      "Train Epoch: 33 [76800/113287 (68%)]\tLoss: 1.219085\n",
      "Train Epoch: 33 [78080/113287 (69%)]\tLoss: 0.971920\n",
      "Train Epoch: 33 [79360/113287 (70%)]\tLoss: 0.919025\n",
      "Train Epoch: 33 [80640/113287 (71%)]\tLoss: 0.760792\n",
      "Train Epoch: 33 [81920/113287 (72%)]\tLoss: 0.709835\n",
      "Train Epoch: 33 [83200/113287 (73%)]\tLoss: 0.963650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 33 [84480/113287 (74%)]\tLoss: 0.931204\n",
      "Train Epoch: 33 [85760/113287 (76%)]\tLoss: 1.099590\n",
      "Train Epoch: 33 [87040/113287 (77%)]\tLoss: 1.006202\n",
      "Train Epoch: 33 [88320/113287 (78%)]\tLoss: 0.730438\n",
      "Train Epoch: 33 [89600/113287 (79%)]\tLoss: 1.009021\n",
      "Train Epoch: 33 [90880/113287 (80%)]\tLoss: 0.954035\n",
      "Train Epoch: 33 [92160/113287 (81%)]\tLoss: 1.013765\n",
      "Train Epoch: 33 [93440/113287 (82%)]\tLoss: 0.958672\n",
      "Train Epoch: 33 [94720/113287 (84%)]\tLoss: 1.085598\n",
      "Train Epoch: 33 [96000/113287 (85%)]\tLoss: 0.876880\n",
      "Train Epoch: 33 [97280/113287 (86%)]\tLoss: 0.912817\n",
      "Train Epoch: 33 [98560/113287 (87%)]\tLoss: 0.832025\n",
      "Train Epoch: 33 [99840/113287 (88%)]\tLoss: 1.214472\n",
      "Train Epoch: 33 [101120/113287 (89%)]\tLoss: 1.105107\n",
      "Train Epoch: 33 [102400/113287 (90%)]\tLoss: 0.962306\n",
      "Train Epoch: 33 [103680/113287 (91%)]\tLoss: 0.891384\n",
      "Train Epoch: 33 [104960/113287 (93%)]\tLoss: 0.883585\n",
      "Train Epoch: 33 [106240/113287 (94%)]\tLoss: 0.840471\n",
      "Train Epoch: 33 [107520/113287 (95%)]\tLoss: 1.180595\n",
      "Train Epoch: 33 [108800/113287 (96%)]\tLoss: 0.863286\n",
      "Train Epoch: 33 [110080/113287 (97%)]\tLoss: 1.027057\n",
      "Train Epoch: 33 [111360/113287 (98%)]\tLoss: 1.031534\n",
      "Train Epoch: 33 [112640/113287 (99%)]\tLoss: 1.108594\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3559/5000 (71%)\n",
      "\n",
      "Train Epoch: 34 [0/113287 (0%)]\tLoss: 0.810139\n",
      "Train Epoch: 34 [1280/113287 (1%)]\tLoss: 0.923665\n",
      "Train Epoch: 34 [2560/113287 (2%)]\tLoss: 0.859841\n",
      "Train Epoch: 34 [3840/113287 (3%)]\tLoss: 0.807420\n",
      "Train Epoch: 34 [5120/113287 (5%)]\tLoss: 1.208223\n",
      "Train Epoch: 34 [6400/113287 (6%)]\tLoss: 0.793152\n",
      "Train Epoch: 34 [7680/113287 (7%)]\tLoss: 0.881954\n",
      "Train Epoch: 34 [8960/113287 (8%)]\tLoss: 1.139742\n",
      "Train Epoch: 34 [10240/113287 (9%)]\tLoss: 1.002273\n",
      "Train Epoch: 34 [11520/113287 (10%)]\tLoss: 0.888049\n",
      "Train Epoch: 34 [12800/113287 (11%)]\tLoss: 0.681314\n",
      "Train Epoch: 34 [14080/113287 (12%)]\tLoss: 0.928664\n",
      "Train Epoch: 34 [15360/113287 (14%)]\tLoss: 0.893695\n",
      "Train Epoch: 34 [16640/113287 (15%)]\tLoss: 0.769731\n",
      "Train Epoch: 34 [17920/113287 (16%)]\tLoss: 1.066503\n",
      "Train Epoch: 34 [19200/113287 (17%)]\tLoss: 1.116982\n",
      "Train Epoch: 34 [20480/113287 (18%)]\tLoss: 0.845261\n",
      "Train Epoch: 34 [21760/113287 (19%)]\tLoss: 0.872434\n",
      "Train Epoch: 34 [23040/113287 (20%)]\tLoss: 1.106971\n",
      "Train Epoch: 34 [24320/113287 (21%)]\tLoss: 0.827686\n",
      "Train Epoch: 34 [25600/113287 (23%)]\tLoss: 1.073103\n",
      "Train Epoch: 34 [26880/113287 (24%)]\tLoss: 0.738990\n",
      "Train Epoch: 34 [28160/113287 (25%)]\tLoss: 0.872405\n",
      "Train Epoch: 34 [29440/113287 (26%)]\tLoss: 1.059726\n",
      "Train Epoch: 34 [30720/113287 (27%)]\tLoss: 1.064344\n",
      "Train Epoch: 34 [32000/113287 (28%)]\tLoss: 1.025730\n",
      "Train Epoch: 34 [33280/113287 (29%)]\tLoss: 1.036739\n",
      "Train Epoch: 34 [34560/113287 (30%)]\tLoss: 0.918630\n",
      "Train Epoch: 34 [35840/113287 (32%)]\tLoss: 1.155510\n",
      "Train Epoch: 34 [37120/113287 (33%)]\tLoss: 0.842747\n",
      "Train Epoch: 34 [38400/113287 (34%)]\tLoss: 0.781874\n",
      "Train Epoch: 34 [39680/113287 (35%)]\tLoss: 0.818768\n",
      "Train Epoch: 34 [40960/113287 (36%)]\tLoss: 0.959819\n",
      "Train Epoch: 34 [42240/113287 (37%)]\tLoss: 0.981619\n",
      "Train Epoch: 34 [43520/113287 (38%)]\tLoss: 0.796429\n",
      "Train Epoch: 34 [44800/113287 (40%)]\tLoss: 0.873689\n",
      "Train Epoch: 34 [46080/113287 (41%)]\tLoss: 1.147339\n",
      "Train Epoch: 34 [47360/113287 (42%)]\tLoss: 1.067195\n",
      "Train Epoch: 34 [48640/113287 (43%)]\tLoss: 0.898192\n",
      "Train Epoch: 34 [49920/113287 (44%)]\tLoss: 0.698651\n",
      "Train Epoch: 34 [51200/113287 (45%)]\tLoss: 0.992096\n",
      "Train Epoch: 34 [52480/113287 (46%)]\tLoss: 0.917773\n",
      "Train Epoch: 34 [53760/113287 (47%)]\tLoss: 1.074469\n",
      "Train Epoch: 34 [55040/113287 (49%)]\tLoss: 0.966560\n",
      "Train Epoch: 34 [56320/113287 (50%)]\tLoss: 0.778839\n",
      "Train Epoch: 34 [57600/113287 (51%)]\tLoss: 1.087398\n",
      "Train Epoch: 34 [58880/113287 (52%)]\tLoss: 0.854915\n",
      "Train Epoch: 34 [60160/113287 (53%)]\tLoss: 0.774544\n",
      "Train Epoch: 34 [61440/113287 (54%)]\tLoss: 1.120489\n",
      "Train Epoch: 34 [62720/113287 (55%)]\tLoss: 0.951380\n",
      "Train Epoch: 34 [64000/113287 (56%)]\tLoss: 0.853970\n",
      "Train Epoch: 34 [65280/113287 (58%)]\tLoss: 0.859892\n",
      "Train Epoch: 34 [66560/113287 (59%)]\tLoss: 0.966167\n",
      "Train Epoch: 34 [67840/113287 (60%)]\tLoss: 0.915151\n",
      "Train Epoch: 34 [69120/113287 (61%)]\tLoss: 0.845629\n",
      "Train Epoch: 34 [70400/113287 (62%)]\tLoss: 0.718656\n",
      "Train Epoch: 34 [71680/113287 (63%)]\tLoss: 0.920807\n",
      "Train Epoch: 34 [72960/113287 (64%)]\tLoss: 0.874055\n",
      "Train Epoch: 34 [74240/113287 (65%)]\tLoss: 0.881236\n",
      "Train Epoch: 34 [75520/113287 (67%)]\tLoss: 1.069174\n",
      "Train Epoch: 34 [76800/113287 (68%)]\tLoss: 0.793553\n",
      "Train Epoch: 34 [78080/113287 (69%)]\tLoss: 1.042461\n",
      "Train Epoch: 34 [79360/113287 (70%)]\tLoss: 1.034286\n",
      "Train Epoch: 34 [80640/113287 (71%)]\tLoss: 0.969824\n",
      "Train Epoch: 34 [81920/113287 (72%)]\tLoss: 0.964803\n",
      "Train Epoch: 34 [83200/113287 (73%)]\tLoss: 1.054861\n",
      "Train Epoch: 34 [84480/113287 (74%)]\tLoss: 0.966229\n",
      "Train Epoch: 34 [85760/113287 (76%)]\tLoss: 0.927565\n",
      "Train Epoch: 34 [87040/113287 (77%)]\tLoss: 0.861547\n",
      "Train Epoch: 34 [88320/113287 (78%)]\tLoss: 1.038843\n",
      "Train Epoch: 34 [89600/113287 (79%)]\tLoss: 0.991675\n",
      "Train Epoch: 34 [90880/113287 (80%)]\tLoss: 0.896811\n",
      "Train Epoch: 34 [92160/113287 (81%)]\tLoss: 0.918950\n",
      "Train Epoch: 34 [93440/113287 (82%)]\tLoss: 1.169388\n",
      "Train Epoch: 34 [94720/113287 (84%)]\tLoss: 0.833370\n",
      "Train Epoch: 34 [96000/113287 (85%)]\tLoss: 0.927206\n",
      "Train Epoch: 34 [97280/113287 (86%)]\tLoss: 0.849361\n",
      "Train Epoch: 34 [98560/113287 (87%)]\tLoss: 1.004574\n",
      "Train Epoch: 34 [99840/113287 (88%)]\tLoss: 0.674093\n",
      "Train Epoch: 34 [101120/113287 (89%)]\tLoss: 0.883892\n",
      "Train Epoch: 34 [102400/113287 (90%)]\tLoss: 0.845045\n",
      "Train Epoch: 34 [103680/113287 (91%)]\tLoss: 0.959352\n",
      "Train Epoch: 34 [104960/113287 (93%)]\tLoss: 0.760271\n",
      "Train Epoch: 34 [106240/113287 (94%)]\tLoss: 1.131230\n",
      "Train Epoch: 34 [107520/113287 (95%)]\tLoss: 0.907337\n",
      "Train Epoch: 34 [108800/113287 (96%)]\tLoss: 0.952967\n",
      "Train Epoch: 34 [110080/113287 (97%)]\tLoss: 1.234444\n",
      "Train Epoch: 34 [111360/113287 (98%)]\tLoss: 1.048057\n",
      "Train Epoch: 34 [112640/113287 (99%)]\tLoss: 0.931835\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3562/5000 (71%)\n",
      "\n",
      "Train Epoch: 35 [0/113287 (0%)]\tLoss: 0.931255\n",
      "Train Epoch: 35 [1280/113287 (1%)]\tLoss: 0.737296\n",
      "Train Epoch: 35 [2560/113287 (2%)]\tLoss: 0.899605\n",
      "Train Epoch: 35 [3840/113287 (3%)]\tLoss: 0.973418\n",
      "Train Epoch: 35 [5120/113287 (5%)]\tLoss: 0.597527\n",
      "Train Epoch: 35 [6400/113287 (6%)]\tLoss: 0.898380\n",
      "Train Epoch: 35 [7680/113287 (7%)]\tLoss: 0.903948\n",
      "Train Epoch: 35 [8960/113287 (8%)]\tLoss: 0.942424\n",
      "Train Epoch: 35 [10240/113287 (9%)]\tLoss: 0.986810\n",
      "Train Epoch: 35 [11520/113287 (10%)]\tLoss: 0.972987\n",
      "Train Epoch: 35 [12800/113287 (11%)]\tLoss: 0.976821\n",
      "Train Epoch: 35 [14080/113287 (12%)]\tLoss: 0.992693\n",
      "Train Epoch: 35 [15360/113287 (14%)]\tLoss: 0.918967\n",
      "Train Epoch: 35 [16640/113287 (15%)]\tLoss: 0.878037\n",
      "Train Epoch: 35 [17920/113287 (16%)]\tLoss: 0.923199\n",
      "Train Epoch: 35 [19200/113287 (17%)]\tLoss: 0.909611\n",
      "Train Epoch: 35 [20480/113287 (18%)]\tLoss: 0.925129\n",
      "Train Epoch: 35 [21760/113287 (19%)]\tLoss: 0.894051\n",
      "Train Epoch: 35 [23040/113287 (20%)]\tLoss: 0.907662\n",
      "Train Epoch: 35 [24320/113287 (21%)]\tLoss: 0.730343\n",
      "Train Epoch: 35 [25600/113287 (23%)]\tLoss: 0.924443\n",
      "Train Epoch: 35 [26880/113287 (24%)]\tLoss: 0.769550\n",
      "Train Epoch: 35 [28160/113287 (25%)]\tLoss: 0.963411\n",
      "Train Epoch: 35 [29440/113287 (26%)]\tLoss: 1.234004\n",
      "Train Epoch: 35 [30720/113287 (27%)]\tLoss: 1.086882\n",
      "Train Epoch: 35 [32000/113287 (28%)]\tLoss: 0.807472\n",
      "Train Epoch: 35 [33280/113287 (29%)]\tLoss: 0.929122\n",
      "Train Epoch: 35 [34560/113287 (30%)]\tLoss: 1.062244\n",
      "Train Epoch: 35 [35840/113287 (32%)]\tLoss: 1.115971\n",
      "Train Epoch: 35 [37120/113287 (33%)]\tLoss: 0.823062\n",
      "Train Epoch: 35 [38400/113287 (34%)]\tLoss: 0.856973\n",
      "Train Epoch: 35 [39680/113287 (35%)]\tLoss: 0.761150\n",
      "Train Epoch: 35 [40960/113287 (36%)]\tLoss: 0.768799\n",
      "Train Epoch: 35 [42240/113287 (37%)]\tLoss: 0.664338\n",
      "Train Epoch: 35 [43520/113287 (38%)]\tLoss: 0.938210\n",
      "Train Epoch: 35 [44800/113287 (40%)]\tLoss: 0.757266\n",
      "Train Epoch: 35 [46080/113287 (41%)]\tLoss: 0.939608\n",
      "Train Epoch: 35 [47360/113287 (42%)]\tLoss: 0.988862\n",
      "Train Epoch: 35 [48640/113287 (43%)]\tLoss: 0.863613\n",
      "Train Epoch: 35 [49920/113287 (44%)]\tLoss: 0.908101\n",
      "Train Epoch: 35 [51200/113287 (45%)]\tLoss: 0.987369\n",
      "Train Epoch: 35 [52480/113287 (46%)]\tLoss: 1.202182\n",
      "Train Epoch: 35 [53760/113287 (47%)]\tLoss: 0.894335\n",
      "Train Epoch: 35 [55040/113287 (49%)]\tLoss: 0.849612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 35 [56320/113287 (50%)]\tLoss: 1.199148\n",
      "Train Epoch: 35 [57600/113287 (51%)]\tLoss: 0.938347\n",
      "Train Epoch: 35 [58880/113287 (52%)]\tLoss: 0.751276\n",
      "Train Epoch: 35 [60160/113287 (53%)]\tLoss: 0.887348\n",
      "Train Epoch: 35 [61440/113287 (54%)]\tLoss: 1.015774\n",
      "Train Epoch: 35 [62720/113287 (55%)]\tLoss: 0.898940\n",
      "Train Epoch: 35 [64000/113287 (56%)]\tLoss: 0.889338\n",
      "Train Epoch: 35 [65280/113287 (58%)]\tLoss: 0.900450\n",
      "Train Epoch: 35 [66560/113287 (59%)]\tLoss: 1.010954\n",
      "Train Epoch: 35 [67840/113287 (60%)]\tLoss: 1.174128\n",
      "Train Epoch: 35 [69120/113287 (61%)]\tLoss: 0.923719\n",
      "Train Epoch: 35 [70400/113287 (62%)]\tLoss: 1.047632\n",
      "Train Epoch: 35 [71680/113287 (63%)]\tLoss: 1.006984\n",
      "Train Epoch: 35 [72960/113287 (64%)]\tLoss: 0.692684\n",
      "Train Epoch: 35 [74240/113287 (65%)]\tLoss: 0.818449\n",
      "Train Epoch: 35 [75520/113287 (67%)]\tLoss: 0.993012\n",
      "Train Epoch: 35 [76800/113287 (68%)]\tLoss: 0.799263\n",
      "Train Epoch: 35 [78080/113287 (69%)]\tLoss: 1.113423\n",
      "Train Epoch: 35 [79360/113287 (70%)]\tLoss: 1.143774\n",
      "Train Epoch: 35 [80640/113287 (71%)]\tLoss: 0.883626\n",
      "Train Epoch: 35 [81920/113287 (72%)]\tLoss: 0.909814\n",
      "Train Epoch: 35 [83200/113287 (73%)]\tLoss: 0.979303\n",
      "Train Epoch: 35 [84480/113287 (74%)]\tLoss: 0.912414\n",
      "Train Epoch: 35 [85760/113287 (76%)]\tLoss: 0.934539\n",
      "Train Epoch: 35 [87040/113287 (77%)]\tLoss: 0.952419\n",
      "Train Epoch: 35 [88320/113287 (78%)]\tLoss: 0.834660\n",
      "Train Epoch: 35 [89600/113287 (79%)]\tLoss: 1.272303\n",
      "Train Epoch: 35 [90880/113287 (80%)]\tLoss: 0.889457\n",
      "Train Epoch: 35 [92160/113287 (81%)]\tLoss: 0.840039\n",
      "Train Epoch: 35 [93440/113287 (82%)]\tLoss: 1.010367\n",
      "Train Epoch: 35 [94720/113287 (84%)]\tLoss: 0.776369\n",
      "Train Epoch: 35 [96000/113287 (85%)]\tLoss: 0.775754\n",
      "Train Epoch: 35 [97280/113287 (86%)]\tLoss: 1.016024\n",
      "Train Epoch: 35 [98560/113287 (87%)]\tLoss: 0.903965\n",
      "Train Epoch: 35 [99840/113287 (88%)]\tLoss: 1.056463\n",
      "Train Epoch: 35 [101120/113287 (89%)]\tLoss: 0.832866\n",
      "Train Epoch: 35 [102400/113287 (90%)]\tLoss: 0.882617\n",
      "Train Epoch: 35 [103680/113287 (91%)]\tLoss: 0.854840\n",
      "Train Epoch: 35 [104960/113287 (93%)]\tLoss: 0.766877\n",
      "Train Epoch: 35 [106240/113287 (94%)]\tLoss: 0.763501\n",
      "Train Epoch: 35 [107520/113287 (95%)]\tLoss: 0.820812\n",
      "Train Epoch: 35 [108800/113287 (96%)]\tLoss: 0.914266\n",
      "Train Epoch: 35 [110080/113287 (97%)]\tLoss: 0.936497\n",
      "Train Epoch: 35 [111360/113287 (98%)]\tLoss: 1.253210\n",
      "Train Epoch: 35 [112640/113287 (99%)]\tLoss: 0.997489\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3562/5000 (71%)\n",
      "\n",
      "Train Epoch: 36 [0/113287 (0%)]\tLoss: 0.846606\n",
      "Train Epoch: 36 [1280/113287 (1%)]\tLoss: 0.989227\n",
      "Train Epoch: 36 [2560/113287 (2%)]\tLoss: 0.687838\n",
      "Train Epoch: 36 [3840/113287 (3%)]\tLoss: 0.806326\n",
      "Train Epoch: 36 [5120/113287 (5%)]\tLoss: 1.078402\n",
      "Train Epoch: 36 [6400/113287 (6%)]\tLoss: 0.993715\n",
      "Train Epoch: 36 [7680/113287 (7%)]\tLoss: 1.223968\n",
      "Train Epoch: 36 [8960/113287 (8%)]\tLoss: 0.820074\n",
      "Train Epoch: 36 [10240/113287 (9%)]\tLoss: 1.016731\n",
      "Train Epoch: 36 [11520/113287 (10%)]\tLoss: 0.966685\n",
      "Train Epoch: 36 [12800/113287 (11%)]\tLoss: 1.018566\n",
      "Train Epoch: 36 [14080/113287 (12%)]\tLoss: 0.954641\n",
      "Train Epoch: 36 [15360/113287 (14%)]\tLoss: 0.943130\n",
      "Train Epoch: 36 [16640/113287 (15%)]\tLoss: 1.116763\n",
      "Train Epoch: 36 [17920/113287 (16%)]\tLoss: 0.932030\n",
      "Train Epoch: 36 [19200/113287 (17%)]\tLoss: 1.075962\n",
      "Train Epoch: 36 [20480/113287 (18%)]\tLoss: 0.855249\n",
      "Train Epoch: 36 [21760/113287 (19%)]\tLoss: 0.799861\n",
      "Train Epoch: 36 [23040/113287 (20%)]\tLoss: 0.818624\n",
      "Train Epoch: 36 [24320/113287 (21%)]\tLoss: 0.847956\n",
      "Train Epoch: 36 [25600/113287 (23%)]\tLoss: 0.872373\n",
      "Train Epoch: 36 [26880/113287 (24%)]\tLoss: 0.886635\n",
      "Train Epoch: 36 [28160/113287 (25%)]\tLoss: 0.880972\n",
      "Train Epoch: 36 [29440/113287 (26%)]\tLoss: 0.789823\n",
      "Train Epoch: 36 [30720/113287 (27%)]\tLoss: 1.041255\n",
      "Train Epoch: 36 [32000/113287 (28%)]\tLoss: 0.981246\n",
      "Train Epoch: 36 [33280/113287 (29%)]\tLoss: 1.032510\n",
      "Train Epoch: 36 [34560/113287 (30%)]\tLoss: 0.882137\n",
      "Train Epoch: 36 [35840/113287 (32%)]\tLoss: 0.882576\n",
      "Train Epoch: 36 [37120/113287 (33%)]\tLoss: 1.169882\n",
      "Train Epoch: 36 [38400/113287 (34%)]\tLoss: 0.863725\n",
      "Train Epoch: 36 [39680/113287 (35%)]\tLoss: 1.098273\n",
      "Train Epoch: 36 [40960/113287 (36%)]\tLoss: 0.861002\n",
      "Train Epoch: 36 [42240/113287 (37%)]\tLoss: 0.980616\n",
      "Train Epoch: 36 [43520/113287 (38%)]\tLoss: 0.994247\n",
      "Train Epoch: 36 [44800/113287 (40%)]\tLoss: 0.938054\n",
      "Train Epoch: 36 [46080/113287 (41%)]\tLoss: 0.836921\n",
      "Train Epoch: 36 [47360/113287 (42%)]\tLoss: 1.083285\n",
      "Train Epoch: 36 [48640/113287 (43%)]\tLoss: 1.002564\n",
      "Train Epoch: 36 [49920/113287 (44%)]\tLoss: 1.037636\n",
      "Train Epoch: 36 [51200/113287 (45%)]\tLoss: 1.283903\n",
      "Train Epoch: 36 [52480/113287 (46%)]\tLoss: 0.921090\n",
      "Train Epoch: 36 [53760/113287 (47%)]\tLoss: 0.949335\n",
      "Train Epoch: 36 [55040/113287 (49%)]\tLoss: 0.794348\n",
      "Train Epoch: 36 [56320/113287 (50%)]\tLoss: 0.925417\n",
      "Train Epoch: 36 [57600/113287 (51%)]\tLoss: 0.623828\n",
      "Train Epoch: 36 [58880/113287 (52%)]\tLoss: 0.959988\n",
      "Train Epoch: 36 [60160/113287 (53%)]\tLoss: 1.052495\n",
      "Train Epoch: 36 [61440/113287 (54%)]\tLoss: 1.313735\n",
      "Train Epoch: 36 [62720/113287 (55%)]\tLoss: 0.895378\n",
      "Train Epoch: 36 [64000/113287 (56%)]\tLoss: 1.016836\n",
      "Train Epoch: 36 [65280/113287 (58%)]\tLoss: 0.819704\n",
      "Train Epoch: 36 [66560/113287 (59%)]\tLoss: 0.932865\n",
      "Train Epoch: 36 [67840/113287 (60%)]\tLoss: 0.962504\n",
      "Train Epoch: 36 [69120/113287 (61%)]\tLoss: 0.978210\n",
      "Train Epoch: 36 [70400/113287 (62%)]\tLoss: 1.053048\n",
      "Train Epoch: 36 [71680/113287 (63%)]\tLoss: 0.990945\n",
      "Train Epoch: 36 [72960/113287 (64%)]\tLoss: 0.926811\n",
      "Train Epoch: 36 [74240/113287 (65%)]\tLoss: 0.882233\n",
      "Train Epoch: 36 [75520/113287 (67%)]\tLoss: 0.799511\n",
      "Train Epoch: 36 [76800/113287 (68%)]\tLoss: 0.967369\n",
      "Train Epoch: 36 [78080/113287 (69%)]\tLoss: 0.878553\n",
      "Train Epoch: 36 [79360/113287 (70%)]\tLoss: 0.748178\n",
      "Train Epoch: 36 [80640/113287 (71%)]\tLoss: 1.099760\n",
      "Train Epoch: 36 [81920/113287 (72%)]\tLoss: 0.776796\n",
      "Train Epoch: 36 [83200/113287 (73%)]\tLoss: 0.887585\n",
      "Train Epoch: 36 [84480/113287 (74%)]\tLoss: 1.036095\n",
      "Train Epoch: 36 [85760/113287 (76%)]\tLoss: 1.043474\n",
      "Train Epoch: 36 [87040/113287 (77%)]\tLoss: 0.935153\n",
      "Train Epoch: 36 [88320/113287 (78%)]\tLoss: 0.992498\n",
      "Train Epoch: 36 [89600/113287 (79%)]\tLoss: 0.745916\n",
      "Train Epoch: 36 [90880/113287 (80%)]\tLoss: 0.910494\n",
      "Train Epoch: 36 [92160/113287 (81%)]\tLoss: 0.735711\n",
      "Train Epoch: 36 [93440/113287 (82%)]\tLoss: 0.983915\n",
      "Train Epoch: 36 [94720/113287 (84%)]\tLoss: 1.025933\n",
      "Train Epoch: 36 [96000/113287 (85%)]\tLoss: 0.737469\n",
      "Train Epoch: 36 [97280/113287 (86%)]\tLoss: 0.822276\n",
      "Train Epoch: 36 [98560/113287 (87%)]\tLoss: 1.100880\n",
      "Train Epoch: 36 [99840/113287 (88%)]\tLoss: 0.746517\n",
      "Train Epoch: 36 [101120/113287 (89%)]\tLoss: 0.915924\n",
      "Train Epoch: 36 [102400/113287 (90%)]\tLoss: 0.903441\n",
      "Train Epoch: 36 [103680/113287 (91%)]\tLoss: 1.066030\n",
      "Train Epoch: 36 [104960/113287 (93%)]\tLoss: 0.956235\n",
      "Train Epoch: 36 [106240/113287 (94%)]\tLoss: 0.975614\n",
      "Train Epoch: 36 [107520/113287 (95%)]\tLoss: 0.915281\n",
      "Train Epoch: 36 [108800/113287 (96%)]\tLoss: 1.077956\n",
      "Train Epoch: 36 [110080/113287 (97%)]\tLoss: 0.877215\n",
      "Train Epoch: 36 [111360/113287 (98%)]\tLoss: 0.694295\n",
      "Train Epoch: 36 [112640/113287 (99%)]\tLoss: 0.975893\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3575/5000 (71%)\n",
      "\n",
      "Train Epoch: 37 [0/113287 (0%)]\tLoss: 1.236609\n",
      "Train Epoch: 37 [1280/113287 (1%)]\tLoss: 0.941519\n",
      "Train Epoch: 37 [2560/113287 (2%)]\tLoss: 0.941315\n",
      "Train Epoch: 37 [3840/113287 (3%)]\tLoss: 1.008469\n",
      "Train Epoch: 37 [5120/113287 (5%)]\tLoss: 1.004389\n",
      "Train Epoch: 37 [6400/113287 (6%)]\tLoss: 1.056638\n",
      "Train Epoch: 37 [7680/113287 (7%)]\tLoss: 0.950240\n",
      "Train Epoch: 37 [8960/113287 (8%)]\tLoss: 0.962064\n",
      "Train Epoch: 37 [10240/113287 (9%)]\tLoss: 0.959673\n",
      "Train Epoch: 37 [11520/113287 (10%)]\tLoss: 0.947750\n",
      "Train Epoch: 37 [12800/113287 (11%)]\tLoss: 1.087097\n",
      "Train Epoch: 37 [14080/113287 (12%)]\tLoss: 0.814614\n",
      "Train Epoch: 37 [15360/113287 (14%)]\tLoss: 1.022725\n",
      "Train Epoch: 37 [16640/113287 (15%)]\tLoss: 0.776093\n",
      "Train Epoch: 37 [17920/113287 (16%)]\tLoss: 0.979607\n",
      "Train Epoch: 37 [19200/113287 (17%)]\tLoss: 0.952777\n",
      "Train Epoch: 37 [20480/113287 (18%)]\tLoss: 0.993876\n",
      "Train Epoch: 37 [21760/113287 (19%)]\tLoss: 0.864415\n",
      "Train Epoch: 37 [23040/113287 (20%)]\tLoss: 0.946859\n",
      "Train Epoch: 37 [24320/113287 (21%)]\tLoss: 0.929709\n",
      "Train Epoch: 37 [25600/113287 (23%)]\tLoss: 0.825101\n",
      "Train Epoch: 37 [26880/113287 (24%)]\tLoss: 1.018490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 37 [28160/113287 (25%)]\tLoss: 0.879646\n",
      "Train Epoch: 37 [29440/113287 (26%)]\tLoss: 0.763945\n",
      "Train Epoch: 37 [30720/113287 (27%)]\tLoss: 0.872709\n",
      "Train Epoch: 37 [32000/113287 (28%)]\tLoss: 0.948372\n",
      "Train Epoch: 37 [33280/113287 (29%)]\tLoss: 0.892411\n",
      "Train Epoch: 37 [34560/113287 (30%)]\tLoss: 1.139155\n",
      "Train Epoch: 37 [35840/113287 (32%)]\tLoss: 1.054073\n",
      "Train Epoch: 37 [37120/113287 (33%)]\tLoss: 0.959086\n",
      "Train Epoch: 37 [38400/113287 (34%)]\tLoss: 0.983485\n",
      "Train Epoch: 37 [39680/113287 (35%)]\tLoss: 1.180097\n",
      "Train Epoch: 37 [40960/113287 (36%)]\tLoss: 1.024066\n",
      "Train Epoch: 37 [42240/113287 (37%)]\tLoss: 0.795565\n",
      "Train Epoch: 37 [43520/113287 (38%)]\tLoss: 0.914432\n",
      "Train Epoch: 37 [44800/113287 (40%)]\tLoss: 1.000279\n",
      "Train Epoch: 37 [46080/113287 (41%)]\tLoss: 0.842878\n",
      "Train Epoch: 37 [47360/113287 (42%)]\tLoss: 0.998732\n",
      "Train Epoch: 37 [48640/113287 (43%)]\tLoss: 0.894056\n",
      "Train Epoch: 37 [49920/113287 (44%)]\tLoss: 0.964058\n",
      "Train Epoch: 37 [51200/113287 (45%)]\tLoss: 0.937453\n",
      "Train Epoch: 37 [52480/113287 (46%)]\tLoss: 0.930277\n",
      "Train Epoch: 37 [53760/113287 (47%)]\tLoss: 0.943404\n",
      "Train Epoch: 37 [55040/113287 (49%)]\tLoss: 1.017039\n",
      "Train Epoch: 37 [56320/113287 (50%)]\tLoss: 0.892085\n",
      "Train Epoch: 37 [57600/113287 (51%)]\tLoss: 0.948091\n",
      "Train Epoch: 37 [58880/113287 (52%)]\tLoss: 0.881884\n",
      "Train Epoch: 37 [60160/113287 (53%)]\tLoss: 0.911143\n",
      "Train Epoch: 37 [61440/113287 (54%)]\tLoss: 1.062154\n",
      "Train Epoch: 37 [62720/113287 (55%)]\tLoss: 0.992670\n",
      "Train Epoch: 37 [64000/113287 (56%)]\tLoss: 0.883538\n",
      "Train Epoch: 37 [65280/113287 (58%)]\tLoss: 1.042359\n",
      "Train Epoch: 37 [66560/113287 (59%)]\tLoss: 0.866595\n",
      "Train Epoch: 37 [67840/113287 (60%)]\tLoss: 0.869341\n",
      "Train Epoch: 37 [69120/113287 (61%)]\tLoss: 1.072405\n",
      "Train Epoch: 37 [70400/113287 (62%)]\tLoss: 1.137740\n",
      "Train Epoch: 37 [71680/113287 (63%)]\tLoss: 1.289138\n",
      "Train Epoch: 37 [72960/113287 (64%)]\tLoss: 0.951682\n",
      "Train Epoch: 37 [74240/113287 (65%)]\tLoss: 1.076286\n",
      "Train Epoch: 37 [75520/113287 (67%)]\tLoss: 1.064764\n",
      "Train Epoch: 37 [76800/113287 (68%)]\tLoss: 0.963446\n",
      "Train Epoch: 37 [78080/113287 (69%)]\tLoss: 0.930368\n",
      "Train Epoch: 37 [79360/113287 (70%)]\tLoss: 0.740348\n",
      "Train Epoch: 37 [80640/113287 (71%)]\tLoss: 0.833871\n",
      "Train Epoch: 37 [81920/113287 (72%)]\tLoss: 0.942048\n",
      "Train Epoch: 37 [83200/113287 (73%)]\tLoss: 1.059926\n",
      "Train Epoch: 37 [84480/113287 (74%)]\tLoss: 0.855661\n",
      "Train Epoch: 37 [85760/113287 (76%)]\tLoss: 0.976750\n",
      "Train Epoch: 37 [87040/113287 (77%)]\tLoss: 0.981226\n",
      "Train Epoch: 37 [88320/113287 (78%)]\tLoss: 1.241911\n",
      "Train Epoch: 37 [89600/113287 (79%)]\tLoss: 0.882521\n",
      "Train Epoch: 37 [90880/113287 (80%)]\tLoss: 0.972190\n",
      "Train Epoch: 37 [92160/113287 (81%)]\tLoss: 0.990245\n",
      "Train Epoch: 37 [93440/113287 (82%)]\tLoss: 1.050734\n",
      "Train Epoch: 37 [94720/113287 (84%)]\tLoss: 0.969780\n",
      "Train Epoch: 37 [96000/113287 (85%)]\tLoss: 0.924945\n",
      "Train Epoch: 37 [97280/113287 (86%)]\tLoss: 0.850735\n",
      "Train Epoch: 37 [98560/113287 (87%)]\tLoss: 0.738613\n",
      "Train Epoch: 37 [99840/113287 (88%)]\tLoss: 0.929498\n",
      "Train Epoch: 37 [101120/113287 (89%)]\tLoss: 0.947985\n",
      "Train Epoch: 37 [102400/113287 (90%)]\tLoss: 0.835193\n",
      "Train Epoch: 37 [103680/113287 (91%)]\tLoss: 1.199716\n",
      "Train Epoch: 37 [104960/113287 (93%)]\tLoss: 0.775980\n",
      "Train Epoch: 37 [106240/113287 (94%)]\tLoss: 0.768375\n",
      "Train Epoch: 37 [107520/113287 (95%)]\tLoss: 0.968526\n",
      "Train Epoch: 37 [108800/113287 (96%)]\tLoss: 0.827041\n",
      "Train Epoch: 37 [110080/113287 (97%)]\tLoss: 0.918411\n",
      "Train Epoch: 37 [111360/113287 (98%)]\tLoss: 0.602895\n",
      "Train Epoch: 37 [112640/113287 (99%)]\tLoss: 1.030513\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3575/5000 (71%)\n",
      "\n",
      "Train Epoch: 38 [0/113287 (0%)]\tLoss: 0.928137\n",
      "Train Epoch: 38 [1280/113287 (1%)]\tLoss: 0.828217\n",
      "Train Epoch: 38 [2560/113287 (2%)]\tLoss: 0.836417\n",
      "Train Epoch: 38 [3840/113287 (3%)]\tLoss: 1.018167\n",
      "Train Epoch: 38 [5120/113287 (5%)]\tLoss: 0.782047\n",
      "Train Epoch: 38 [6400/113287 (6%)]\tLoss: 1.040821\n",
      "Train Epoch: 38 [7680/113287 (7%)]\tLoss: 0.831078\n",
      "Train Epoch: 38 [8960/113287 (8%)]\tLoss: 0.799401\n",
      "Train Epoch: 38 [10240/113287 (9%)]\tLoss: 0.862933\n",
      "Train Epoch: 38 [11520/113287 (10%)]\tLoss: 1.024900\n",
      "Train Epoch: 38 [12800/113287 (11%)]\tLoss: 0.706785\n",
      "Train Epoch: 38 [14080/113287 (12%)]\tLoss: 0.901982\n",
      "Train Epoch: 38 [15360/113287 (14%)]\tLoss: 1.020035\n",
      "Train Epoch: 38 [16640/113287 (15%)]\tLoss: 0.958811\n",
      "Train Epoch: 38 [17920/113287 (16%)]\tLoss: 0.828894\n",
      "Train Epoch: 38 [19200/113287 (17%)]\tLoss: 1.050125\n",
      "Train Epoch: 38 [20480/113287 (18%)]\tLoss: 0.937765\n",
      "Train Epoch: 38 [21760/113287 (19%)]\tLoss: 1.108217\n",
      "Train Epoch: 38 [23040/113287 (20%)]\tLoss: 0.822316\n",
      "Train Epoch: 38 [24320/113287 (21%)]\tLoss: 1.112279\n",
      "Train Epoch: 38 [25600/113287 (23%)]\tLoss: 0.935577\n",
      "Train Epoch: 38 [26880/113287 (24%)]\tLoss: 0.972491\n",
      "Train Epoch: 38 [28160/113287 (25%)]\tLoss: 0.818367\n",
      "Train Epoch: 38 [29440/113287 (26%)]\tLoss: 0.890202\n",
      "Train Epoch: 38 [30720/113287 (27%)]\tLoss: 0.799775\n",
      "Train Epoch: 38 [32000/113287 (28%)]\tLoss: 1.102385\n",
      "Train Epoch: 38 [33280/113287 (29%)]\tLoss: 0.930598\n",
      "Train Epoch: 38 [34560/113287 (30%)]\tLoss: 0.873383\n",
      "Train Epoch: 38 [35840/113287 (32%)]\tLoss: 0.961789\n",
      "Train Epoch: 38 [37120/113287 (33%)]\tLoss: 0.910947\n",
      "Train Epoch: 38 [38400/113287 (34%)]\tLoss: 0.917485\n",
      "Train Epoch: 38 [39680/113287 (35%)]\tLoss: 0.935679\n",
      "Train Epoch: 38 [40960/113287 (36%)]\tLoss: 0.924194\n",
      "Train Epoch: 38 [42240/113287 (37%)]\tLoss: 0.964427\n",
      "Train Epoch: 38 [43520/113287 (38%)]\tLoss: 1.050841\n",
      "Train Epoch: 38 [44800/113287 (40%)]\tLoss: 1.082037\n",
      "Train Epoch: 38 [46080/113287 (41%)]\tLoss: 1.187794\n",
      "Train Epoch: 38 [47360/113287 (42%)]\tLoss: 0.825385\n",
      "Train Epoch: 38 [48640/113287 (43%)]\tLoss: 0.797826\n",
      "Train Epoch: 38 [49920/113287 (44%)]\tLoss: 0.937502\n",
      "Train Epoch: 38 [51200/113287 (45%)]\tLoss: 0.889706\n",
      "Train Epoch: 38 [52480/113287 (46%)]\tLoss: 0.995448\n",
      "Train Epoch: 38 [53760/113287 (47%)]\tLoss: 1.004229\n",
      "Train Epoch: 38 [55040/113287 (49%)]\tLoss: 1.058648\n",
      "Train Epoch: 38 [56320/113287 (50%)]\tLoss: 1.068783\n",
      "Train Epoch: 38 [57600/113287 (51%)]\tLoss: 0.933133\n",
      "Train Epoch: 38 [58880/113287 (52%)]\tLoss: 0.966679\n",
      "Train Epoch: 38 [60160/113287 (53%)]\tLoss: 1.041856\n",
      "Train Epoch: 38 [61440/113287 (54%)]\tLoss: 1.196298\n",
      "Train Epoch: 38 [62720/113287 (55%)]\tLoss: 0.669049\n",
      "Train Epoch: 38 [64000/113287 (56%)]\tLoss: 0.962346\n",
      "Train Epoch: 38 [65280/113287 (58%)]\tLoss: 0.973691\n",
      "Train Epoch: 38 [66560/113287 (59%)]\tLoss: 0.923396\n",
      "Train Epoch: 38 [67840/113287 (60%)]\tLoss: 0.780886\n",
      "Train Epoch: 38 [69120/113287 (61%)]\tLoss: 0.848435\n",
      "Train Epoch: 38 [70400/113287 (62%)]\tLoss: 0.872509\n",
      "Train Epoch: 38 [71680/113287 (63%)]\tLoss: 0.824104\n",
      "Train Epoch: 38 [72960/113287 (64%)]\tLoss: 0.907677\n",
      "Train Epoch: 38 [74240/113287 (65%)]\tLoss: 1.062928\n",
      "Train Epoch: 38 [75520/113287 (67%)]\tLoss: 1.100906\n",
      "Train Epoch: 38 [76800/113287 (68%)]\tLoss: 0.961316\n",
      "Train Epoch: 38 [78080/113287 (69%)]\tLoss: 0.843330\n",
      "Train Epoch: 38 [79360/113287 (70%)]\tLoss: 0.842575\n",
      "Train Epoch: 38 [80640/113287 (71%)]\tLoss: 0.988592\n",
      "Train Epoch: 38 [81920/113287 (72%)]\tLoss: 0.987086\n",
      "Train Epoch: 38 [83200/113287 (73%)]\tLoss: 1.197687\n",
      "Train Epoch: 38 [84480/113287 (74%)]\tLoss: 0.898601\n",
      "Train Epoch: 38 [85760/113287 (76%)]\tLoss: 0.920854\n",
      "Train Epoch: 38 [87040/113287 (77%)]\tLoss: 0.836316\n",
      "Train Epoch: 38 [88320/113287 (78%)]\tLoss: 0.773643\n",
      "Train Epoch: 38 [89600/113287 (79%)]\tLoss: 1.045051\n",
      "Train Epoch: 38 [90880/113287 (80%)]\tLoss: 0.814408\n",
      "Train Epoch: 38 [92160/113287 (81%)]\tLoss: 0.894434\n",
      "Train Epoch: 38 [93440/113287 (82%)]\tLoss: 0.787365\n",
      "Train Epoch: 38 [94720/113287 (84%)]\tLoss: 0.727125\n",
      "Train Epoch: 38 [96000/113287 (85%)]\tLoss: 0.952521\n",
      "Train Epoch: 38 [97280/113287 (86%)]\tLoss: 1.089580\n",
      "Train Epoch: 38 [98560/113287 (87%)]\tLoss: 0.922330\n",
      "Train Epoch: 38 [99840/113287 (88%)]\tLoss: 0.685884\n",
      "Train Epoch: 38 [101120/113287 (89%)]\tLoss: 1.366433\n",
      "Train Epoch: 38 [102400/113287 (90%)]\tLoss: 1.105468\n",
      "Train Epoch: 38 [103680/113287 (91%)]\tLoss: 0.943914\n",
      "Train Epoch: 38 [104960/113287 (93%)]\tLoss: 0.918336\n",
      "Train Epoch: 38 [106240/113287 (94%)]\tLoss: 0.832982\n",
      "Train Epoch: 38 [107520/113287 (95%)]\tLoss: 0.733566\n",
      "Train Epoch: 38 [108800/113287 (96%)]\tLoss: 0.893737\n",
      "Train Epoch: 38 [110080/113287 (97%)]\tLoss: 1.095394\n",
      "Train Epoch: 38 [111360/113287 (98%)]\tLoss: 0.965775\n",
      "Train Epoch: 38 [112640/113287 (99%)]\tLoss: 0.919041\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3562/5000 (71%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 39 [0/113287 (0%)]\tLoss: 0.985573\n",
      "Train Epoch: 39 [1280/113287 (1%)]\tLoss: 0.879260\n",
      "Train Epoch: 39 [2560/113287 (2%)]\tLoss: 0.796354\n",
      "Train Epoch: 39 [3840/113287 (3%)]\tLoss: 0.889179\n",
      "Train Epoch: 39 [5120/113287 (5%)]\tLoss: 0.775675\n",
      "Train Epoch: 39 [6400/113287 (6%)]\tLoss: 1.015696\n",
      "Train Epoch: 39 [7680/113287 (7%)]\tLoss: 1.033972\n",
      "Train Epoch: 39 [8960/113287 (8%)]\tLoss: 0.928818\n",
      "Train Epoch: 39 [10240/113287 (9%)]\tLoss: 0.857803\n",
      "Train Epoch: 39 [11520/113287 (10%)]\tLoss: 0.859925\n",
      "Train Epoch: 39 [12800/113287 (11%)]\tLoss: 0.826433\n",
      "Train Epoch: 39 [14080/113287 (12%)]\tLoss: 0.915087\n",
      "Train Epoch: 39 [15360/113287 (14%)]\tLoss: 0.754659\n",
      "Train Epoch: 39 [16640/113287 (15%)]\tLoss: 0.916288\n",
      "Train Epoch: 39 [17920/113287 (16%)]\tLoss: 0.928497\n",
      "Train Epoch: 39 [19200/113287 (17%)]\tLoss: 0.905750\n",
      "Train Epoch: 39 [20480/113287 (18%)]\tLoss: 1.144785\n",
      "Train Epoch: 39 [21760/113287 (19%)]\tLoss: 0.917861\n",
      "Train Epoch: 39 [23040/113287 (20%)]\tLoss: 0.896955\n",
      "Train Epoch: 39 [24320/113287 (21%)]\tLoss: 1.027296\n",
      "Train Epoch: 39 [25600/113287 (23%)]\tLoss: 0.978528\n",
      "Train Epoch: 39 [26880/113287 (24%)]\tLoss: 1.102383\n",
      "Train Epoch: 39 [28160/113287 (25%)]\tLoss: 1.018127\n",
      "Train Epoch: 39 [29440/113287 (26%)]\tLoss: 0.990375\n",
      "Train Epoch: 39 [30720/113287 (27%)]\tLoss: 0.838426\n",
      "Train Epoch: 39 [32000/113287 (28%)]\tLoss: 1.042726\n",
      "Train Epoch: 39 [33280/113287 (29%)]\tLoss: 0.954475\n",
      "Train Epoch: 39 [34560/113287 (30%)]\tLoss: 0.849521\n",
      "Train Epoch: 39 [35840/113287 (32%)]\tLoss: 1.092410\n",
      "Train Epoch: 39 [37120/113287 (33%)]\tLoss: 0.773495\n",
      "Train Epoch: 39 [38400/113287 (34%)]\tLoss: 0.902144\n",
      "Train Epoch: 39 [39680/113287 (35%)]\tLoss: 0.976611\n",
      "Train Epoch: 39 [40960/113287 (36%)]\tLoss: 0.666037\n",
      "Train Epoch: 39 [42240/113287 (37%)]\tLoss: 0.804011\n",
      "Train Epoch: 39 [43520/113287 (38%)]\tLoss: 0.726955\n",
      "Train Epoch: 39 [44800/113287 (40%)]\tLoss: 0.812949\n",
      "Train Epoch: 39 [46080/113287 (41%)]\tLoss: 0.995524\n",
      "Train Epoch: 39 [47360/113287 (42%)]\tLoss: 0.905963\n",
      "Train Epoch: 39 [48640/113287 (43%)]\tLoss: 1.019588\n",
      "Train Epoch: 39 [49920/113287 (44%)]\tLoss: 0.938099\n",
      "Train Epoch: 39 [51200/113287 (45%)]\tLoss: 1.016235\n",
      "Train Epoch: 39 [52480/113287 (46%)]\tLoss: 0.908701\n",
      "Train Epoch: 39 [53760/113287 (47%)]\tLoss: 1.011543\n",
      "Train Epoch: 39 [55040/113287 (49%)]\tLoss: 0.748480\n",
      "Train Epoch: 39 [56320/113287 (50%)]\tLoss: 0.964813\n",
      "Train Epoch: 39 [57600/113287 (51%)]\tLoss: 0.756641\n",
      "Train Epoch: 39 [58880/113287 (52%)]\tLoss: 1.007639\n",
      "Train Epoch: 39 [60160/113287 (53%)]\tLoss: 0.803260\n",
      "Train Epoch: 39 [61440/113287 (54%)]\tLoss: 1.009959\n",
      "Train Epoch: 39 [62720/113287 (55%)]\tLoss: 0.868218\n",
      "Train Epoch: 39 [64000/113287 (56%)]\tLoss: 0.833007\n",
      "Train Epoch: 39 [65280/113287 (58%)]\tLoss: 0.878768\n",
      "Train Epoch: 39 [66560/113287 (59%)]\tLoss: 0.946416\n",
      "Train Epoch: 39 [67840/113287 (60%)]\tLoss: 1.174298\n",
      "Train Epoch: 39 [69120/113287 (61%)]\tLoss: 0.863937\n",
      "Train Epoch: 39 [70400/113287 (62%)]\tLoss: 0.944497\n",
      "Train Epoch: 39 [71680/113287 (63%)]\tLoss: 0.916487\n",
      "Train Epoch: 39 [72960/113287 (64%)]\tLoss: 1.029145\n",
      "Train Epoch: 39 [74240/113287 (65%)]\tLoss: 0.921554\n",
      "Train Epoch: 39 [75520/113287 (67%)]\tLoss: 0.832792\n",
      "Train Epoch: 39 [76800/113287 (68%)]\tLoss: 0.880590\n",
      "Train Epoch: 39 [78080/113287 (69%)]\tLoss: 1.070564\n",
      "Train Epoch: 39 [79360/113287 (70%)]\tLoss: 1.041582\n",
      "Train Epoch: 39 [80640/113287 (71%)]\tLoss: 0.873802\n",
      "Train Epoch: 39 [81920/113287 (72%)]\tLoss: 1.018007\n",
      "Train Epoch: 39 [83200/113287 (73%)]\tLoss: 0.911481\n",
      "Train Epoch: 39 [84480/113287 (74%)]\tLoss: 0.827809\n",
      "Train Epoch: 39 [85760/113287 (76%)]\tLoss: 1.081657\n",
      "Train Epoch: 39 [87040/113287 (77%)]\tLoss: 1.076784\n",
      "Train Epoch: 39 [88320/113287 (78%)]\tLoss: 0.948933\n",
      "Train Epoch: 39 [89600/113287 (79%)]\tLoss: 0.926686\n",
      "Train Epoch: 39 [90880/113287 (80%)]\tLoss: 1.100055\n",
      "Train Epoch: 39 [92160/113287 (81%)]\tLoss: 0.770585\n",
      "Train Epoch: 39 [93440/113287 (82%)]\tLoss: 0.923063\n",
      "Train Epoch: 39 [94720/113287 (84%)]\tLoss: 1.133021\n",
      "Train Epoch: 39 [96000/113287 (85%)]\tLoss: 1.013794\n",
      "Train Epoch: 39 [97280/113287 (86%)]\tLoss: 0.999260\n",
      "Train Epoch: 39 [98560/113287 (87%)]\tLoss: 1.075650\n",
      "Train Epoch: 39 [99840/113287 (88%)]\tLoss: 0.863178\n",
      "Train Epoch: 39 [101120/113287 (89%)]\tLoss: 0.746707\n",
      "Train Epoch: 39 [102400/113287 (90%)]\tLoss: 0.840801\n",
      "Train Epoch: 39 [103680/113287 (91%)]\tLoss: 0.837576\n",
      "Train Epoch: 39 [104960/113287 (93%)]\tLoss: 0.967887\n",
      "Train Epoch: 39 [106240/113287 (94%)]\tLoss: 0.869179\n",
      "Train Epoch: 39 [107520/113287 (95%)]\tLoss: 0.753104\n",
      "Train Epoch: 39 [108800/113287 (96%)]\tLoss: 0.998662\n",
      "Train Epoch: 39 [110080/113287 (97%)]\tLoss: 0.850302\n",
      "Train Epoch: 39 [111360/113287 (98%)]\tLoss: 0.959771\n",
      "Train Epoch: 39 [112640/113287 (99%)]\tLoss: 1.043882\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3579/5000 (71%)\n",
      "\n",
      "Train Epoch: 40 [0/113287 (0%)]\tLoss: 0.796587\n",
      "Train Epoch: 40 [1280/113287 (1%)]\tLoss: 1.126540\n",
      "Train Epoch: 40 [2560/113287 (2%)]\tLoss: 0.840719\n",
      "Train Epoch: 40 [3840/113287 (3%)]\tLoss: 0.915066\n",
      "Train Epoch: 40 [5120/113287 (5%)]\tLoss: 0.925177\n",
      "Train Epoch: 40 [6400/113287 (6%)]\tLoss: 0.753372\n",
      "Train Epoch: 40 [7680/113287 (7%)]\tLoss: 0.917509\n",
      "Train Epoch: 40 [8960/113287 (8%)]\tLoss: 0.837534\n",
      "Train Epoch: 40 [10240/113287 (9%)]\tLoss: 1.304183\n",
      "Train Epoch: 40 [11520/113287 (10%)]\tLoss: 0.879893\n",
      "Train Epoch: 40 [12800/113287 (11%)]\tLoss: 1.004820\n",
      "Train Epoch: 40 [14080/113287 (12%)]\tLoss: 1.187751\n",
      "Train Epoch: 40 [15360/113287 (14%)]\tLoss: 0.946855\n",
      "Train Epoch: 40 [16640/113287 (15%)]\tLoss: 0.791301\n",
      "Train Epoch: 40 [17920/113287 (16%)]\tLoss: 0.933258\n",
      "Train Epoch: 40 [19200/113287 (17%)]\tLoss: 0.862565\n",
      "Train Epoch: 40 [20480/113287 (18%)]\tLoss: 0.909755\n",
      "Train Epoch: 40 [21760/113287 (19%)]\tLoss: 0.856783\n",
      "Train Epoch: 40 [23040/113287 (20%)]\tLoss: 0.994672\n",
      "Train Epoch: 40 [24320/113287 (21%)]\tLoss: 0.885683\n",
      "Train Epoch: 40 [25600/113287 (23%)]\tLoss: 0.982931\n",
      "Train Epoch: 40 [26880/113287 (24%)]\tLoss: 0.937124\n",
      "Train Epoch: 40 [28160/113287 (25%)]\tLoss: 1.123218\n",
      "Train Epoch: 40 [29440/113287 (26%)]\tLoss: 0.980298\n",
      "Train Epoch: 40 [30720/113287 (27%)]\tLoss: 0.933428\n",
      "Train Epoch: 40 [32000/113287 (28%)]\tLoss: 0.950035\n",
      "Train Epoch: 40 [33280/113287 (29%)]\tLoss: 0.987078\n",
      "Train Epoch: 40 [34560/113287 (30%)]\tLoss: 0.978022\n",
      "Train Epoch: 40 [35840/113287 (32%)]\tLoss: 0.836906\n",
      "Train Epoch: 40 [37120/113287 (33%)]\tLoss: 0.806038\n",
      "Train Epoch: 40 [38400/113287 (34%)]\tLoss: 0.998970\n",
      "Train Epoch: 40 [39680/113287 (35%)]\tLoss: 0.990977\n",
      "Train Epoch: 40 [40960/113287 (36%)]\tLoss: 0.936273\n",
      "Train Epoch: 40 [42240/113287 (37%)]\tLoss: 0.820170\n",
      "Train Epoch: 40 [43520/113287 (38%)]\tLoss: 1.030155\n",
      "Train Epoch: 40 [44800/113287 (40%)]\tLoss: 0.715416\n",
      "Train Epoch: 40 [46080/113287 (41%)]\tLoss: 0.921873\n",
      "Train Epoch: 40 [47360/113287 (42%)]\tLoss: 0.944987\n",
      "Train Epoch: 40 [48640/113287 (43%)]\tLoss: 0.903007\n",
      "Train Epoch: 40 [49920/113287 (44%)]\tLoss: 0.858848\n",
      "Train Epoch: 40 [51200/113287 (45%)]\tLoss: 0.797734\n",
      "Train Epoch: 40 [52480/113287 (46%)]\tLoss: 1.032861\n",
      "Train Epoch: 40 [53760/113287 (47%)]\tLoss: 0.930392\n",
      "Train Epoch: 40 [55040/113287 (49%)]\tLoss: 1.054823\n",
      "Train Epoch: 40 [56320/113287 (50%)]\tLoss: 0.949654\n",
      "Train Epoch: 40 [57600/113287 (51%)]\tLoss: 0.726506\n",
      "Train Epoch: 40 [58880/113287 (52%)]\tLoss: 0.985143\n",
      "Train Epoch: 40 [60160/113287 (53%)]\tLoss: 1.194738\n",
      "Train Epoch: 40 [61440/113287 (54%)]\tLoss: 0.889467\n",
      "Train Epoch: 40 [62720/113287 (55%)]\tLoss: 1.060877\n",
      "Train Epoch: 40 [64000/113287 (56%)]\tLoss: 0.897396\n",
      "Train Epoch: 40 [65280/113287 (58%)]\tLoss: 0.947999\n",
      "Train Epoch: 40 [66560/113287 (59%)]\tLoss: 0.887988\n",
      "Train Epoch: 40 [67840/113287 (60%)]\tLoss: 1.104057\n",
      "Train Epoch: 40 [69120/113287 (61%)]\tLoss: 0.915981\n",
      "Train Epoch: 40 [70400/113287 (62%)]\tLoss: 1.071355\n",
      "Train Epoch: 40 [71680/113287 (63%)]\tLoss: 0.966058\n",
      "Train Epoch: 40 [72960/113287 (64%)]\tLoss: 1.079771\n",
      "Train Epoch: 40 [74240/113287 (65%)]\tLoss: 1.124935\n",
      "Train Epoch: 40 [75520/113287 (67%)]\tLoss: 0.866913\n",
      "Train Epoch: 40 [76800/113287 (68%)]\tLoss: 0.863442\n",
      "Train Epoch: 40 [78080/113287 (69%)]\tLoss: 0.801665\n",
      "Train Epoch: 40 [79360/113287 (70%)]\tLoss: 0.976160\n",
      "Train Epoch: 40 [80640/113287 (71%)]\tLoss: 0.729292\n",
      "Train Epoch: 40 [81920/113287 (72%)]\tLoss: 0.971196\n",
      "Train Epoch: 40 [83200/113287 (73%)]\tLoss: 0.744172\n",
      "Train Epoch: 40 [84480/113287 (74%)]\tLoss: 0.965584\n",
      "Train Epoch: 40 [85760/113287 (76%)]\tLoss: 0.815998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 40 [87040/113287 (77%)]\tLoss: 0.991462\n",
      "Train Epoch: 40 [88320/113287 (78%)]\tLoss: 0.963033\n",
      "Train Epoch: 40 [89600/113287 (79%)]\tLoss: 0.957736\n",
      "Train Epoch: 40 [90880/113287 (80%)]\tLoss: 0.884945\n",
      "Train Epoch: 40 [92160/113287 (81%)]\tLoss: 0.992509\n",
      "Train Epoch: 40 [93440/113287 (82%)]\tLoss: 0.835326\n",
      "Train Epoch: 40 [94720/113287 (84%)]\tLoss: 0.771031\n",
      "Train Epoch: 40 [96000/113287 (85%)]\tLoss: 1.030022\n",
      "Train Epoch: 40 [97280/113287 (86%)]\tLoss: 0.782260\n",
      "Train Epoch: 40 [98560/113287 (87%)]\tLoss: 0.863670\n",
      "Train Epoch: 40 [99840/113287 (88%)]\tLoss: 0.989041\n",
      "Train Epoch: 40 [101120/113287 (89%)]\tLoss: 0.978451\n",
      "Train Epoch: 40 [102400/113287 (90%)]\tLoss: 0.927049\n",
      "Train Epoch: 40 [103680/113287 (91%)]\tLoss: 0.933286\n",
      "Train Epoch: 40 [104960/113287 (93%)]\tLoss: 1.073983\n",
      "Train Epoch: 40 [106240/113287 (94%)]\tLoss: 0.891310\n",
      "Train Epoch: 40 [107520/113287 (95%)]\tLoss: 1.022130\n",
      "Train Epoch: 40 [108800/113287 (96%)]\tLoss: 0.855530\n",
      "Train Epoch: 40 [110080/113287 (97%)]\tLoss: 0.923638\n",
      "Train Epoch: 40 [111360/113287 (98%)]\tLoss: 0.915770\n",
      "Train Epoch: 40 [112640/113287 (99%)]\tLoss: 1.180652\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3584/5000 (71%)\n",
      "\n",
      "Train Epoch: 41 [0/113287 (0%)]\tLoss: 0.907050\n",
      "Train Epoch: 41 [1280/113287 (1%)]\tLoss: 1.043765\n",
      "Train Epoch: 41 [2560/113287 (2%)]\tLoss: 0.825207\n",
      "Train Epoch: 41 [3840/113287 (3%)]\tLoss: 0.891160\n",
      "Train Epoch: 41 [5120/113287 (5%)]\tLoss: 0.972529\n",
      "Train Epoch: 41 [6400/113287 (6%)]\tLoss: 0.924023\n",
      "Train Epoch: 41 [7680/113287 (7%)]\tLoss: 0.879553\n",
      "Train Epoch: 41 [8960/113287 (8%)]\tLoss: 0.681461\n",
      "Train Epoch: 41 [10240/113287 (9%)]\tLoss: 0.758947\n",
      "Train Epoch: 41 [11520/113287 (10%)]\tLoss: 0.683417\n",
      "Train Epoch: 41 [12800/113287 (11%)]\tLoss: 0.812904\n",
      "Train Epoch: 41 [14080/113287 (12%)]\tLoss: 0.887830\n",
      "Train Epoch: 41 [15360/113287 (14%)]\tLoss: 0.880181\n",
      "Train Epoch: 41 [16640/113287 (15%)]\tLoss: 1.020579\n",
      "Train Epoch: 41 [17920/113287 (16%)]\tLoss: 1.166902\n",
      "Train Epoch: 41 [19200/113287 (17%)]\tLoss: 0.796200\n",
      "Train Epoch: 41 [20480/113287 (18%)]\tLoss: 0.757353\n",
      "Train Epoch: 41 [21760/113287 (19%)]\tLoss: 1.030816\n",
      "Train Epoch: 41 [23040/113287 (20%)]\tLoss: 1.100394\n",
      "Train Epoch: 41 [24320/113287 (21%)]\tLoss: 0.934781\n",
      "Train Epoch: 41 [25600/113287 (23%)]\tLoss: 0.825423\n",
      "Train Epoch: 41 [26880/113287 (24%)]\tLoss: 0.792961\n",
      "Train Epoch: 41 [28160/113287 (25%)]\tLoss: 0.862754\n",
      "Train Epoch: 41 [29440/113287 (26%)]\tLoss: 1.044330\n",
      "Train Epoch: 41 [30720/113287 (27%)]\tLoss: 1.074678\n",
      "Train Epoch: 41 [32000/113287 (28%)]\tLoss: 0.805823\n",
      "Train Epoch: 41 [33280/113287 (29%)]\tLoss: 0.972733\n",
      "Train Epoch: 41 [34560/113287 (30%)]\tLoss: 0.774132\n",
      "Train Epoch: 41 [35840/113287 (32%)]\tLoss: 0.740811\n",
      "Train Epoch: 41 [37120/113287 (33%)]\tLoss: 0.922572\n",
      "Train Epoch: 41 [38400/113287 (34%)]\tLoss: 0.871795\n",
      "Train Epoch: 41 [39680/113287 (35%)]\tLoss: 0.867822\n",
      "Train Epoch: 41 [40960/113287 (36%)]\tLoss: 0.809271\n",
      "Train Epoch: 41 [42240/113287 (37%)]\tLoss: 0.907871\n",
      "Train Epoch: 41 [43520/113287 (38%)]\tLoss: 0.645349\n",
      "Train Epoch: 41 [44800/113287 (40%)]\tLoss: 0.921922\n",
      "Train Epoch: 41 [46080/113287 (41%)]\tLoss: 0.851707\n",
      "Train Epoch: 41 [47360/113287 (42%)]\tLoss: 0.936078\n",
      "Train Epoch: 41 [48640/113287 (43%)]\tLoss: 1.254816\n",
      "Train Epoch: 41 [49920/113287 (44%)]\tLoss: 0.996758\n",
      "Train Epoch: 41 [51200/113287 (45%)]\tLoss: 0.931791\n",
      "Train Epoch: 41 [52480/113287 (46%)]\tLoss: 0.756725\n",
      "Train Epoch: 41 [53760/113287 (47%)]\tLoss: 1.134090\n",
      "Train Epoch: 41 [55040/113287 (49%)]\tLoss: 0.832979\n",
      "Train Epoch: 41 [56320/113287 (50%)]\tLoss: 0.732163\n",
      "Train Epoch: 41 [57600/113287 (51%)]\tLoss: 0.936617\n",
      "Train Epoch: 41 [58880/113287 (52%)]\tLoss: 1.137109\n",
      "Train Epoch: 41 [60160/113287 (53%)]\tLoss: 1.079874\n",
      "Train Epoch: 41 [61440/113287 (54%)]\tLoss: 1.087440\n",
      "Train Epoch: 41 [62720/113287 (55%)]\tLoss: 1.072623\n",
      "Train Epoch: 41 [64000/113287 (56%)]\tLoss: 1.075004\n",
      "Train Epoch: 41 [65280/113287 (58%)]\tLoss: 0.758863\n",
      "Train Epoch: 41 [66560/113287 (59%)]\tLoss: 0.856369\n",
      "Train Epoch: 41 [67840/113287 (60%)]\tLoss: 0.894708\n",
      "Train Epoch: 41 [69120/113287 (61%)]\tLoss: 1.006956\n",
      "Train Epoch: 41 [70400/113287 (62%)]\tLoss: 0.801995\n",
      "Train Epoch: 41 [71680/113287 (63%)]\tLoss: 0.942735\n",
      "Train Epoch: 41 [72960/113287 (64%)]\tLoss: 0.934537\n",
      "Train Epoch: 41 [74240/113287 (65%)]\tLoss: 0.988620\n",
      "Train Epoch: 41 [75520/113287 (67%)]\tLoss: 1.039620\n",
      "Train Epoch: 41 [76800/113287 (68%)]\tLoss: 0.957231\n",
      "Train Epoch: 41 [78080/113287 (69%)]\tLoss: 1.188671\n",
      "Train Epoch: 41 [79360/113287 (70%)]\tLoss: 0.946555\n",
      "Train Epoch: 41 [80640/113287 (71%)]\tLoss: 0.783332\n",
      "Train Epoch: 41 [81920/113287 (72%)]\tLoss: 1.014808\n",
      "Train Epoch: 41 [83200/113287 (73%)]\tLoss: 0.792188\n",
      "Train Epoch: 41 [84480/113287 (74%)]\tLoss: 0.880836\n",
      "Train Epoch: 41 [85760/113287 (76%)]\tLoss: 0.716410\n",
      "Train Epoch: 41 [87040/113287 (77%)]\tLoss: 1.145308\n",
      "Train Epoch: 41 [88320/113287 (78%)]\tLoss: 1.065574\n",
      "Train Epoch: 41 [89600/113287 (79%)]\tLoss: 0.914810\n",
      "Train Epoch: 41 [90880/113287 (80%)]\tLoss: 1.199958\n",
      "Train Epoch: 41 [92160/113287 (81%)]\tLoss: 0.895790\n",
      "Train Epoch: 41 [93440/113287 (82%)]\tLoss: 0.602898\n",
      "Train Epoch: 41 [94720/113287 (84%)]\tLoss: 0.889941\n",
      "Train Epoch: 41 [96000/113287 (85%)]\tLoss: 0.998251\n",
      "Train Epoch: 41 [97280/113287 (86%)]\tLoss: 0.993913\n",
      "Train Epoch: 41 [98560/113287 (87%)]\tLoss: 1.112081\n",
      "Train Epoch: 41 [99840/113287 (88%)]\tLoss: 0.889585\n",
      "Train Epoch: 41 [101120/113287 (89%)]\tLoss: 1.025779\n",
      "Train Epoch: 41 [102400/113287 (90%)]\tLoss: 1.040245\n",
      "Train Epoch: 41 [103680/113287 (91%)]\tLoss: 0.938277\n",
      "Train Epoch: 41 [104960/113287 (93%)]\tLoss: 1.142865\n",
      "Train Epoch: 41 [106240/113287 (94%)]\tLoss: 0.861311\n",
      "Train Epoch: 41 [107520/113287 (95%)]\tLoss: 1.029734\n",
      "Train Epoch: 41 [108800/113287 (96%)]\tLoss: 1.001695\n",
      "Train Epoch: 41 [110080/113287 (97%)]\tLoss: 0.903668\n",
      "Train Epoch: 41 [111360/113287 (98%)]\tLoss: 1.017391\n",
      "Train Epoch: 41 [112640/113287 (99%)]\tLoss: 1.172587\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3609/5000 (72%)\n",
      "\n",
      "Train Epoch: 42 [0/113287 (0%)]\tLoss: 0.929376\n",
      "Train Epoch: 42 [1280/113287 (1%)]\tLoss: 0.978945\n",
      "Train Epoch: 42 [2560/113287 (2%)]\tLoss: 0.830090\n",
      "Train Epoch: 42 [3840/113287 (3%)]\tLoss: 1.172571\n",
      "Train Epoch: 42 [5120/113287 (5%)]\tLoss: 0.907542\n",
      "Train Epoch: 42 [6400/113287 (6%)]\tLoss: 1.034542\n",
      "Train Epoch: 42 [7680/113287 (7%)]\tLoss: 1.146186\n",
      "Train Epoch: 42 [8960/113287 (8%)]\tLoss: 0.825624\n",
      "Train Epoch: 42 [10240/113287 (9%)]\tLoss: 0.874826\n",
      "Train Epoch: 42 [11520/113287 (10%)]\tLoss: 1.044279\n",
      "Train Epoch: 42 [12800/113287 (11%)]\tLoss: 0.910983\n",
      "Train Epoch: 42 [14080/113287 (12%)]\tLoss: 0.841748\n",
      "Train Epoch: 42 [15360/113287 (14%)]\tLoss: 1.017478\n",
      "Train Epoch: 42 [16640/113287 (15%)]\tLoss: 0.906706\n",
      "Train Epoch: 42 [17920/113287 (16%)]\tLoss: 0.994492\n",
      "Train Epoch: 42 [19200/113287 (17%)]\tLoss: 0.876029\n",
      "Train Epoch: 42 [20480/113287 (18%)]\tLoss: 0.934303\n",
      "Train Epoch: 42 [21760/113287 (19%)]\tLoss: 0.944298\n",
      "Train Epoch: 42 [23040/113287 (20%)]\tLoss: 0.923566\n",
      "Train Epoch: 42 [24320/113287 (21%)]\tLoss: 0.850787\n",
      "Train Epoch: 42 [25600/113287 (23%)]\tLoss: 0.602514\n",
      "Train Epoch: 42 [26880/113287 (24%)]\tLoss: 0.945218\n",
      "Train Epoch: 42 [28160/113287 (25%)]\tLoss: 1.063948\n",
      "Train Epoch: 42 [29440/113287 (26%)]\tLoss: 0.871429\n",
      "Train Epoch: 42 [30720/113287 (27%)]\tLoss: 0.869896\n",
      "Train Epoch: 42 [32000/113287 (28%)]\tLoss: 0.945072\n",
      "Train Epoch: 42 [33280/113287 (29%)]\tLoss: 0.898844\n",
      "Train Epoch: 42 [34560/113287 (30%)]\tLoss: 0.786429\n",
      "Train Epoch: 42 [35840/113287 (32%)]\tLoss: 0.700626\n",
      "Train Epoch: 42 [37120/113287 (33%)]\tLoss: 1.101031\n",
      "Train Epoch: 42 [38400/113287 (34%)]\tLoss: 0.853520\n",
      "Train Epoch: 42 [39680/113287 (35%)]\tLoss: 1.135374\n",
      "Train Epoch: 42 [40960/113287 (36%)]\tLoss: 1.195784\n",
      "Train Epoch: 42 [42240/113287 (37%)]\tLoss: 0.872009\n",
      "Train Epoch: 42 [43520/113287 (38%)]\tLoss: 0.863397\n",
      "Train Epoch: 42 [44800/113287 (40%)]\tLoss: 0.949299\n",
      "Train Epoch: 42 [46080/113287 (41%)]\tLoss: 1.122504\n",
      "Train Epoch: 42 [47360/113287 (42%)]\tLoss: 0.844735\n",
      "Train Epoch: 42 [48640/113287 (43%)]\tLoss: 0.814227\n",
      "Train Epoch: 42 [49920/113287 (44%)]\tLoss: 0.910790\n",
      "Train Epoch: 42 [51200/113287 (45%)]\tLoss: 0.726630\n",
      "Train Epoch: 42 [52480/113287 (46%)]\tLoss: 0.964373\n",
      "Train Epoch: 42 [53760/113287 (47%)]\tLoss: 0.782724\n",
      "Train Epoch: 42 [55040/113287 (49%)]\tLoss: 0.987919\n",
      "Train Epoch: 42 [56320/113287 (50%)]\tLoss: 0.903519\n",
      "Train Epoch: 42 [57600/113287 (51%)]\tLoss: 0.993639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 42 [58880/113287 (52%)]\tLoss: 0.907208\n",
      "Train Epoch: 42 [60160/113287 (53%)]\tLoss: 1.156478\n",
      "Train Epoch: 42 [61440/113287 (54%)]\tLoss: 0.893160\n",
      "Train Epoch: 42 [62720/113287 (55%)]\tLoss: 0.825909\n",
      "Train Epoch: 42 [64000/113287 (56%)]\tLoss: 1.100913\n",
      "Train Epoch: 42 [65280/113287 (58%)]\tLoss: 0.830227\n",
      "Train Epoch: 42 [66560/113287 (59%)]\tLoss: 1.078993\n",
      "Train Epoch: 42 [67840/113287 (60%)]\tLoss: 0.843055\n",
      "Train Epoch: 42 [69120/113287 (61%)]\tLoss: 0.792106\n",
      "Train Epoch: 42 [70400/113287 (62%)]\tLoss: 0.976796\n",
      "Train Epoch: 42 [71680/113287 (63%)]\tLoss: 1.143017\n",
      "Train Epoch: 42 [72960/113287 (64%)]\tLoss: 0.758432\n",
      "Train Epoch: 42 [74240/113287 (65%)]\tLoss: 1.009276\n",
      "Train Epoch: 42 [75520/113287 (67%)]\tLoss: 0.787502\n",
      "Train Epoch: 42 [76800/113287 (68%)]\tLoss: 0.874549\n",
      "Train Epoch: 42 [78080/113287 (69%)]\tLoss: 0.896680\n",
      "Train Epoch: 42 [79360/113287 (70%)]\tLoss: 0.848468\n",
      "Train Epoch: 42 [80640/113287 (71%)]\tLoss: 0.852713\n",
      "Train Epoch: 42 [81920/113287 (72%)]\tLoss: 0.903628\n",
      "Train Epoch: 42 [83200/113287 (73%)]\tLoss: 0.866587\n",
      "Train Epoch: 42 [84480/113287 (74%)]\tLoss: 0.854617\n",
      "Train Epoch: 42 [85760/113287 (76%)]\tLoss: 0.980548\n",
      "Train Epoch: 42 [87040/113287 (77%)]\tLoss: 0.863383\n",
      "Train Epoch: 42 [88320/113287 (78%)]\tLoss: 0.909703\n",
      "Train Epoch: 42 [89600/113287 (79%)]\tLoss: 0.923730\n",
      "Train Epoch: 42 [90880/113287 (80%)]\tLoss: 1.014374\n",
      "Train Epoch: 42 [92160/113287 (81%)]\tLoss: 1.198726\n",
      "Train Epoch: 42 [93440/113287 (82%)]\tLoss: 0.932025\n",
      "Train Epoch: 42 [94720/113287 (84%)]\tLoss: 0.935345\n",
      "Train Epoch: 42 [96000/113287 (85%)]\tLoss: 0.885615\n",
      "Train Epoch: 42 [97280/113287 (86%)]\tLoss: 0.776976\n",
      "Train Epoch: 42 [98560/113287 (87%)]\tLoss: 0.897880\n",
      "Train Epoch: 42 [99840/113287 (88%)]\tLoss: 0.881513\n",
      "Train Epoch: 42 [101120/113287 (89%)]\tLoss: 0.849925\n",
      "Train Epoch: 42 [102400/113287 (90%)]\tLoss: 0.758415\n",
      "Train Epoch: 42 [103680/113287 (91%)]\tLoss: 0.960803\n",
      "Train Epoch: 42 [104960/113287 (93%)]\tLoss: 0.966703\n",
      "Train Epoch: 42 [106240/113287 (94%)]\tLoss: 0.978844\n",
      "Train Epoch: 42 [107520/113287 (95%)]\tLoss: 0.958820\n",
      "Train Epoch: 42 [108800/113287 (96%)]\tLoss: 1.063877\n",
      "Train Epoch: 42 [110080/113287 (97%)]\tLoss: 0.846081\n",
      "Train Epoch: 42 [111360/113287 (98%)]\tLoss: 0.917896\n",
      "Train Epoch: 42 [112640/113287 (99%)]\tLoss: 0.979530\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3586/5000 (71%)\n",
      "\n",
      "Train Epoch: 43 [0/113287 (0%)]\tLoss: 1.061673\n",
      "Train Epoch: 43 [1280/113287 (1%)]\tLoss: 0.964093\n",
      "Train Epoch: 43 [2560/113287 (2%)]\tLoss: 0.941562\n",
      "Train Epoch: 43 [3840/113287 (3%)]\tLoss: 0.819473\n",
      "Train Epoch: 43 [5120/113287 (5%)]\tLoss: 0.822215\n",
      "Train Epoch: 43 [6400/113287 (6%)]\tLoss: 0.935209\n",
      "Train Epoch: 43 [7680/113287 (7%)]\tLoss: 0.738009\n",
      "Train Epoch: 43 [8960/113287 (8%)]\tLoss: 0.811890\n",
      "Train Epoch: 43 [10240/113287 (9%)]\tLoss: 0.905438\n",
      "Train Epoch: 43 [11520/113287 (10%)]\tLoss: 0.975904\n",
      "Train Epoch: 43 [12800/113287 (11%)]\tLoss: 0.755737\n",
      "Train Epoch: 43 [14080/113287 (12%)]\tLoss: 0.755586\n",
      "Train Epoch: 43 [15360/113287 (14%)]\tLoss: 0.935206\n",
      "Train Epoch: 43 [16640/113287 (15%)]\tLoss: 1.228037\n",
      "Train Epoch: 43 [17920/113287 (16%)]\tLoss: 0.914573\n",
      "Train Epoch: 43 [19200/113287 (17%)]\tLoss: 0.549565\n",
      "Train Epoch: 43 [20480/113287 (18%)]\tLoss: 1.174072\n",
      "Train Epoch: 43 [21760/113287 (19%)]\tLoss: 1.192336\n",
      "Train Epoch: 43 [23040/113287 (20%)]\tLoss: 1.091438\n",
      "Train Epoch: 43 [24320/113287 (21%)]\tLoss: 0.972251\n",
      "Train Epoch: 43 [25600/113287 (23%)]\tLoss: 1.194697\n",
      "Train Epoch: 43 [26880/113287 (24%)]\tLoss: 0.917233\n",
      "Train Epoch: 43 [28160/113287 (25%)]\tLoss: 1.037506\n",
      "Train Epoch: 43 [29440/113287 (26%)]\tLoss: 0.935503\n",
      "Train Epoch: 43 [30720/113287 (27%)]\tLoss: 1.001859\n",
      "Train Epoch: 43 [32000/113287 (28%)]\tLoss: 0.842986\n",
      "Train Epoch: 43 [33280/113287 (29%)]\tLoss: 1.014629\n",
      "Train Epoch: 43 [34560/113287 (30%)]\tLoss: 0.923915\n",
      "Train Epoch: 43 [35840/113287 (32%)]\tLoss: 0.889019\n",
      "Train Epoch: 43 [37120/113287 (33%)]\tLoss: 0.875796\n",
      "Train Epoch: 43 [38400/113287 (34%)]\tLoss: 0.843615\n",
      "Train Epoch: 43 [39680/113287 (35%)]\tLoss: 0.839109\n",
      "Train Epoch: 43 [40960/113287 (36%)]\tLoss: 0.852376\n",
      "Train Epoch: 43 [42240/113287 (37%)]\tLoss: 0.871956\n",
      "Train Epoch: 43 [43520/113287 (38%)]\tLoss: 0.880731\n",
      "Train Epoch: 43 [44800/113287 (40%)]\tLoss: 0.929408\n",
      "Train Epoch: 43 [46080/113287 (41%)]\tLoss: 1.008682\n",
      "Train Epoch: 43 [47360/113287 (42%)]\tLoss: 0.890589\n",
      "Train Epoch: 43 [48640/113287 (43%)]\tLoss: 0.972160\n",
      "Train Epoch: 43 [49920/113287 (44%)]\tLoss: 0.985010\n",
      "Train Epoch: 43 [51200/113287 (45%)]\tLoss: 0.851256\n",
      "Train Epoch: 43 [52480/113287 (46%)]\tLoss: 0.726919\n",
      "Train Epoch: 43 [53760/113287 (47%)]\tLoss: 0.918917\n",
      "Train Epoch: 43 [55040/113287 (49%)]\tLoss: 0.827882\n",
      "Train Epoch: 43 [56320/113287 (50%)]\tLoss: 0.998655\n",
      "Train Epoch: 43 [57600/113287 (51%)]\tLoss: 0.732261\n",
      "Train Epoch: 43 [58880/113287 (52%)]\tLoss: 1.046217\n",
      "Train Epoch: 43 [60160/113287 (53%)]\tLoss: 0.749381\n",
      "Train Epoch: 43 [61440/113287 (54%)]\tLoss: 0.941612\n",
      "Train Epoch: 43 [62720/113287 (55%)]\tLoss: 0.665640\n",
      "Train Epoch: 43 [64000/113287 (56%)]\tLoss: 0.883672\n",
      "Train Epoch: 43 [65280/113287 (58%)]\tLoss: 0.812473\n",
      "Train Epoch: 43 [66560/113287 (59%)]\tLoss: 0.815133\n",
      "Train Epoch: 43 [67840/113287 (60%)]\tLoss: 1.099840\n",
      "Train Epoch: 43 [69120/113287 (61%)]\tLoss: 0.945389\n",
      "Train Epoch: 43 [70400/113287 (62%)]\tLoss: 0.938023\n",
      "Train Epoch: 43 [71680/113287 (63%)]\tLoss: 0.734217\n",
      "Train Epoch: 43 [72960/113287 (64%)]\tLoss: 0.860539\n",
      "Train Epoch: 43 [74240/113287 (65%)]\tLoss: 0.658464\n",
      "Train Epoch: 43 [75520/113287 (67%)]\tLoss: 0.754907\n",
      "Train Epoch: 43 [76800/113287 (68%)]\tLoss: 0.984941\n",
      "Train Epoch: 43 [78080/113287 (69%)]\tLoss: 1.039722\n",
      "Train Epoch: 43 [79360/113287 (70%)]\tLoss: 1.013573\n",
      "Train Epoch: 43 [80640/113287 (71%)]\tLoss: 1.001141\n",
      "Train Epoch: 43 [81920/113287 (72%)]\tLoss: 1.022587\n",
      "Train Epoch: 43 [83200/113287 (73%)]\tLoss: 0.896365\n",
      "Train Epoch: 43 [84480/113287 (74%)]\tLoss: 1.096876\n",
      "Train Epoch: 43 [85760/113287 (76%)]\tLoss: 0.694416\n",
      "Train Epoch: 43 [87040/113287 (77%)]\tLoss: 0.851489\n",
      "Train Epoch: 43 [88320/113287 (78%)]\tLoss: 0.878936\n",
      "Train Epoch: 43 [89600/113287 (79%)]\tLoss: 0.808586\n",
      "Train Epoch: 43 [90880/113287 (80%)]\tLoss: 0.960071\n",
      "Train Epoch: 43 [92160/113287 (81%)]\tLoss: 1.167760\n",
      "Train Epoch: 43 [93440/113287 (82%)]\tLoss: 0.901144\n",
      "Train Epoch: 43 [94720/113287 (84%)]\tLoss: 1.103688\n",
      "Train Epoch: 43 [96000/113287 (85%)]\tLoss: 1.158468\n",
      "Train Epoch: 43 [97280/113287 (86%)]\tLoss: 0.900680\n",
      "Train Epoch: 43 [98560/113287 (87%)]\tLoss: 0.835292\n",
      "Train Epoch: 43 [99840/113287 (88%)]\tLoss: 1.041270\n",
      "Train Epoch: 43 [101120/113287 (89%)]\tLoss: 1.047224\n",
      "Train Epoch: 43 [102400/113287 (90%)]\tLoss: 0.942249\n",
      "Train Epoch: 43 [103680/113287 (91%)]\tLoss: 1.010075\n",
      "Train Epoch: 43 [104960/113287 (93%)]\tLoss: 0.997471\n",
      "Train Epoch: 43 [106240/113287 (94%)]\tLoss: 0.918371\n",
      "Train Epoch: 43 [107520/113287 (95%)]\tLoss: 0.811976\n",
      "Train Epoch: 43 [108800/113287 (96%)]\tLoss: 1.100426\n",
      "Train Epoch: 43 [110080/113287 (97%)]\tLoss: 1.064126\n",
      "Train Epoch: 43 [111360/113287 (98%)]\tLoss: 0.929202\n",
      "Train Epoch: 43 [112640/113287 (99%)]\tLoss: 1.004386\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3575/5000 (71%)\n",
      "\n",
      "Train Epoch: 44 [0/113287 (0%)]\tLoss: 1.150022\n",
      "Train Epoch: 44 [1280/113287 (1%)]\tLoss: 0.876043\n",
      "Train Epoch: 44 [2560/113287 (2%)]\tLoss: 1.074518\n",
      "Train Epoch: 44 [3840/113287 (3%)]\tLoss: 1.164996\n",
      "Train Epoch: 44 [5120/113287 (5%)]\tLoss: 0.971751\n",
      "Train Epoch: 44 [6400/113287 (6%)]\tLoss: 0.962718\n",
      "Train Epoch: 44 [7680/113287 (7%)]\tLoss: 1.026200\n",
      "Train Epoch: 44 [8960/113287 (8%)]\tLoss: 0.714719\n",
      "Train Epoch: 44 [10240/113287 (9%)]\tLoss: 0.836455\n",
      "Train Epoch: 44 [11520/113287 (10%)]\tLoss: 1.036317\n",
      "Train Epoch: 44 [12800/113287 (11%)]\tLoss: 0.725341\n",
      "Train Epoch: 44 [14080/113287 (12%)]\tLoss: 0.866753\n",
      "Train Epoch: 44 [15360/113287 (14%)]\tLoss: 0.924123\n",
      "Train Epoch: 44 [16640/113287 (15%)]\tLoss: 1.090166\n",
      "Train Epoch: 44 [17920/113287 (16%)]\tLoss: 0.955492\n",
      "Train Epoch: 44 [19200/113287 (17%)]\tLoss: 0.872365\n",
      "Train Epoch: 44 [20480/113287 (18%)]\tLoss: 0.899395\n",
      "Train Epoch: 44 [21760/113287 (19%)]\tLoss: 1.135816\n",
      "Train Epoch: 44 [23040/113287 (20%)]\tLoss: 0.987217\n",
      "Train Epoch: 44 [24320/113287 (21%)]\tLoss: 0.987925\n",
      "Train Epoch: 44 [25600/113287 (23%)]\tLoss: 0.978347\n",
      "Train Epoch: 44 [26880/113287 (24%)]\tLoss: 0.903884\n",
      "Train Epoch: 44 [28160/113287 (25%)]\tLoss: 1.096791\n",
      "Train Epoch: 44 [29440/113287 (26%)]\tLoss: 0.895611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 44 [30720/113287 (27%)]\tLoss: 0.917543\n",
      "Train Epoch: 44 [32000/113287 (28%)]\tLoss: 1.279707\n",
      "Train Epoch: 44 [33280/113287 (29%)]\tLoss: 0.978142\n",
      "Train Epoch: 44 [34560/113287 (30%)]\tLoss: 1.222848\n",
      "Train Epoch: 44 [35840/113287 (32%)]\tLoss: 0.922946\n",
      "Train Epoch: 44 [37120/113287 (33%)]\tLoss: 0.991227\n",
      "Train Epoch: 44 [38400/113287 (34%)]\tLoss: 0.760550\n",
      "Train Epoch: 44 [39680/113287 (35%)]\tLoss: 0.958628\n",
      "Train Epoch: 44 [40960/113287 (36%)]\tLoss: 0.957031\n",
      "Train Epoch: 44 [42240/113287 (37%)]\tLoss: 0.950453\n",
      "Train Epoch: 44 [43520/113287 (38%)]\tLoss: 0.917420\n",
      "Train Epoch: 44 [44800/113287 (40%)]\tLoss: 0.837877\n",
      "Train Epoch: 44 [46080/113287 (41%)]\tLoss: 0.802961\n",
      "Train Epoch: 44 [47360/113287 (42%)]\tLoss: 0.890064\n",
      "Train Epoch: 44 [48640/113287 (43%)]\tLoss: 1.106075\n",
      "Train Epoch: 44 [49920/113287 (44%)]\tLoss: 1.050214\n",
      "Train Epoch: 44 [51200/113287 (45%)]\tLoss: 0.867268\n",
      "Train Epoch: 44 [52480/113287 (46%)]\tLoss: 1.058190\n",
      "Train Epoch: 44 [53760/113287 (47%)]\tLoss: 0.803634\n",
      "Train Epoch: 44 [55040/113287 (49%)]\tLoss: 0.914384\n",
      "Train Epoch: 44 [56320/113287 (50%)]\tLoss: 0.905404\n",
      "Train Epoch: 44 [57600/113287 (51%)]\tLoss: 0.934373\n",
      "Train Epoch: 44 [58880/113287 (52%)]\tLoss: 1.115851\n",
      "Train Epoch: 44 [60160/113287 (53%)]\tLoss: 0.818723\n",
      "Train Epoch: 44 [61440/113287 (54%)]\tLoss: 0.882005\n",
      "Train Epoch: 44 [62720/113287 (55%)]\tLoss: 0.900261\n",
      "Train Epoch: 44 [64000/113287 (56%)]\tLoss: 0.901693\n",
      "Train Epoch: 44 [65280/113287 (58%)]\tLoss: 0.868709\n",
      "Train Epoch: 44 [66560/113287 (59%)]\tLoss: 0.845953\n",
      "Train Epoch: 44 [67840/113287 (60%)]\tLoss: 0.607775\n",
      "Train Epoch: 44 [69120/113287 (61%)]\tLoss: 1.072443\n",
      "Train Epoch: 44 [70400/113287 (62%)]\tLoss: 1.016924\n",
      "Train Epoch: 44 [71680/113287 (63%)]\tLoss: 0.850727\n",
      "Train Epoch: 44 [72960/113287 (64%)]\tLoss: 0.974579\n",
      "Train Epoch: 44 [74240/113287 (65%)]\tLoss: 0.616229\n",
      "Train Epoch: 44 [75520/113287 (67%)]\tLoss: 0.963896\n",
      "Train Epoch: 44 [76800/113287 (68%)]\tLoss: 0.977609\n",
      "Train Epoch: 44 [78080/113287 (69%)]\tLoss: 0.912268\n",
      "Train Epoch: 44 [79360/113287 (70%)]\tLoss: 0.957028\n",
      "Train Epoch: 44 [80640/113287 (71%)]\tLoss: 0.999449\n",
      "Train Epoch: 44 [81920/113287 (72%)]\tLoss: 0.738018\n",
      "Train Epoch: 44 [83200/113287 (73%)]\tLoss: 0.893737\n",
      "Train Epoch: 44 [84480/113287 (74%)]\tLoss: 0.865954\n",
      "Train Epoch: 44 [85760/113287 (76%)]\tLoss: 0.832011\n",
      "Train Epoch: 44 [87040/113287 (77%)]\tLoss: 0.889494\n",
      "Train Epoch: 44 [88320/113287 (78%)]\tLoss: 0.727611\n",
      "Train Epoch: 44 [89600/113287 (79%)]\tLoss: 0.792450\n",
      "Train Epoch: 44 [90880/113287 (80%)]\tLoss: 0.886929\n",
      "Train Epoch: 44 [92160/113287 (81%)]\tLoss: 1.079160\n",
      "Train Epoch: 44 [93440/113287 (82%)]\tLoss: 0.825163\n",
      "Train Epoch: 44 [94720/113287 (84%)]\tLoss: 0.823988\n",
      "Train Epoch: 44 [96000/113287 (85%)]\tLoss: 0.943650\n",
      "Train Epoch: 44 [97280/113287 (86%)]\tLoss: 1.113261\n",
      "Train Epoch: 44 [98560/113287 (87%)]\tLoss: 0.892059\n",
      "Train Epoch: 44 [99840/113287 (88%)]\tLoss: 0.992661\n",
      "Train Epoch: 44 [101120/113287 (89%)]\tLoss: 1.075767\n",
      "Train Epoch: 44 [102400/113287 (90%)]\tLoss: 0.865135\n",
      "Train Epoch: 44 [103680/113287 (91%)]\tLoss: 0.844447\n",
      "Train Epoch: 44 [104960/113287 (93%)]\tLoss: 0.643785\n",
      "Train Epoch: 44 [106240/113287 (94%)]\tLoss: 0.809220\n",
      "Train Epoch: 44 [107520/113287 (95%)]\tLoss: 0.830793\n",
      "Train Epoch: 44 [108800/113287 (96%)]\tLoss: 1.028621\n",
      "Train Epoch: 44 [110080/113287 (97%)]\tLoss: 1.054706\n",
      "Train Epoch: 44 [111360/113287 (98%)]\tLoss: 1.024009\n",
      "Train Epoch: 44 [112640/113287 (99%)]\tLoss: 0.975939\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3581/5000 (71%)\n",
      "\n",
      "Train Epoch: 45 [0/113287 (0%)]\tLoss: 0.884193\n",
      "Train Epoch: 45 [1280/113287 (1%)]\tLoss: 1.090271\n",
      "Train Epoch: 45 [2560/113287 (2%)]\tLoss: 0.864441\n",
      "Train Epoch: 45 [3840/113287 (3%)]\tLoss: 0.690865\n",
      "Train Epoch: 45 [5120/113287 (5%)]\tLoss: 1.006476\n",
      "Train Epoch: 45 [6400/113287 (6%)]\tLoss: 0.873659\n",
      "Train Epoch: 45 [7680/113287 (7%)]\tLoss: 0.829253\n",
      "Train Epoch: 45 [8960/113287 (8%)]\tLoss: 1.023912\n",
      "Train Epoch: 45 [10240/113287 (9%)]\tLoss: 0.892839\n",
      "Train Epoch: 45 [11520/113287 (10%)]\tLoss: 0.748363\n",
      "Train Epoch: 45 [12800/113287 (11%)]\tLoss: 0.722508\n",
      "Train Epoch: 45 [14080/113287 (12%)]\tLoss: 0.943421\n",
      "Train Epoch: 45 [15360/113287 (14%)]\tLoss: 0.849943\n",
      "Train Epoch: 45 [16640/113287 (15%)]\tLoss: 0.669995\n",
      "Train Epoch: 45 [17920/113287 (16%)]\tLoss: 0.954562\n",
      "Train Epoch: 45 [19200/113287 (17%)]\tLoss: 1.048343\n",
      "Train Epoch: 45 [20480/113287 (18%)]\tLoss: 0.929786\n",
      "Train Epoch: 45 [21760/113287 (19%)]\tLoss: 0.856567\n",
      "Train Epoch: 45 [23040/113287 (20%)]\tLoss: 0.887347\n",
      "Train Epoch: 45 [24320/113287 (21%)]\tLoss: 1.025085\n",
      "Train Epoch: 45 [25600/113287 (23%)]\tLoss: 0.957391\n",
      "Train Epoch: 45 [26880/113287 (24%)]\tLoss: 1.151736\n",
      "Train Epoch: 45 [28160/113287 (25%)]\tLoss: 0.994902\n",
      "Train Epoch: 45 [29440/113287 (26%)]\tLoss: 0.931073\n",
      "Train Epoch: 45 [30720/113287 (27%)]\tLoss: 0.827882\n",
      "Train Epoch: 45 [32000/113287 (28%)]\tLoss: 0.951622\n",
      "Train Epoch: 45 [33280/113287 (29%)]\tLoss: 0.910547\n",
      "Train Epoch: 45 [34560/113287 (30%)]\tLoss: 0.959178\n",
      "Train Epoch: 45 [35840/113287 (32%)]\tLoss: 0.999476\n",
      "Train Epoch: 45 [37120/113287 (33%)]\tLoss: 0.961736\n",
      "Train Epoch: 45 [38400/113287 (34%)]\tLoss: 0.992834\n",
      "Train Epoch: 45 [39680/113287 (35%)]\tLoss: 0.923623\n",
      "Train Epoch: 45 [40960/113287 (36%)]\tLoss: 1.010589\n",
      "Train Epoch: 45 [42240/113287 (37%)]\tLoss: 1.027302\n",
      "Train Epoch: 45 [43520/113287 (38%)]\tLoss: 0.893983\n",
      "Train Epoch: 45 [44800/113287 (40%)]\tLoss: 0.819982\n",
      "Train Epoch: 45 [46080/113287 (41%)]\tLoss: 0.780873\n",
      "Train Epoch: 45 [47360/113287 (42%)]\tLoss: 1.096486\n",
      "Train Epoch: 45 [48640/113287 (43%)]\tLoss: 0.965441\n",
      "Train Epoch: 45 [49920/113287 (44%)]\tLoss: 0.847988\n",
      "Train Epoch: 45 [51200/113287 (45%)]\tLoss: 1.238222\n",
      "Train Epoch: 45 [52480/113287 (46%)]\tLoss: 0.860897\n",
      "Train Epoch: 45 [53760/113287 (47%)]\tLoss: 0.837040\n",
      "Train Epoch: 45 [55040/113287 (49%)]\tLoss: 0.830311\n",
      "Train Epoch: 45 [56320/113287 (50%)]\tLoss: 1.021804\n",
      "Train Epoch: 45 [57600/113287 (51%)]\tLoss: 0.776120\n",
      "Train Epoch: 45 [58880/113287 (52%)]\tLoss: 1.092651\n",
      "Train Epoch: 45 [60160/113287 (53%)]\tLoss: 1.088446\n",
      "Train Epoch: 45 [61440/113287 (54%)]\tLoss: 0.795960\n",
      "Train Epoch: 45 [62720/113287 (55%)]\tLoss: 0.887722\n",
      "Train Epoch: 45 [64000/113287 (56%)]\tLoss: 0.890328\n",
      "Train Epoch: 45 [65280/113287 (58%)]\tLoss: 1.013700\n",
      "Train Epoch: 45 [66560/113287 (59%)]\tLoss: 0.754624\n",
      "Train Epoch: 45 [67840/113287 (60%)]\tLoss: 0.972139\n",
      "Train Epoch: 45 [69120/113287 (61%)]\tLoss: 1.026684\n",
      "Train Epoch: 45 [70400/113287 (62%)]\tLoss: 1.131230\n",
      "Train Epoch: 45 [71680/113287 (63%)]\tLoss: 0.730208\n",
      "Train Epoch: 45 [72960/113287 (64%)]\tLoss: 0.948901\n",
      "Train Epoch: 45 [74240/113287 (65%)]\tLoss: 1.187414\n",
      "Train Epoch: 45 [75520/113287 (67%)]\tLoss: 0.842633\n",
      "Train Epoch: 45 [76800/113287 (68%)]\tLoss: 0.931084\n",
      "Train Epoch: 45 [78080/113287 (69%)]\tLoss: 1.029546\n",
      "Train Epoch: 45 [79360/113287 (70%)]\tLoss: 0.887349\n",
      "Train Epoch: 45 [80640/113287 (71%)]\tLoss: 0.965342\n",
      "Train Epoch: 45 [81920/113287 (72%)]\tLoss: 0.864910\n",
      "Train Epoch: 45 [83200/113287 (73%)]\tLoss: 0.631260\n",
      "Train Epoch: 45 [84480/113287 (74%)]\tLoss: 0.899966\n",
      "Train Epoch: 45 [85760/113287 (76%)]\tLoss: 1.086817\n",
      "Train Epoch: 45 [87040/113287 (77%)]\tLoss: 0.733821\n",
      "Train Epoch: 45 [88320/113287 (78%)]\tLoss: 0.946188\n",
      "Train Epoch: 45 [89600/113287 (79%)]\tLoss: 0.999155\n",
      "Train Epoch: 45 [90880/113287 (80%)]\tLoss: 1.110838\n",
      "Train Epoch: 45 [92160/113287 (81%)]\tLoss: 0.763296\n",
      "Train Epoch: 45 [93440/113287 (82%)]\tLoss: 0.942511\n",
      "Train Epoch: 45 [94720/113287 (84%)]\tLoss: 0.820162\n",
      "Train Epoch: 45 [96000/113287 (85%)]\tLoss: 1.108551\n",
      "Train Epoch: 45 [97280/113287 (86%)]\tLoss: 0.755817\n",
      "Train Epoch: 45 [98560/113287 (87%)]\tLoss: 0.746244\n",
      "Train Epoch: 45 [99840/113287 (88%)]\tLoss: 0.808587\n",
      "Train Epoch: 45 [101120/113287 (89%)]\tLoss: 1.042713\n",
      "Train Epoch: 45 [102400/113287 (90%)]\tLoss: 1.091178\n",
      "Train Epoch: 45 [103680/113287 (91%)]\tLoss: 0.905163\n",
      "Train Epoch: 45 [104960/113287 (93%)]\tLoss: 0.965047\n",
      "Train Epoch: 45 [106240/113287 (94%)]\tLoss: 0.950344\n",
      "Train Epoch: 45 [107520/113287 (95%)]\tLoss: 0.964896\n",
      "Train Epoch: 45 [108800/113287 (96%)]\tLoss: 1.143511\n",
      "Train Epoch: 45 [110080/113287 (97%)]\tLoss: 0.768750\n",
      "Train Epoch: 45 [111360/113287 (98%)]\tLoss: 0.919829\n",
      "Train Epoch: 45 [112640/113287 (99%)]\tLoss: 0.767568\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3581/5000 (71%)\n",
      "\n",
      "Train Epoch: 46 [0/113287 (0%)]\tLoss: 0.724909\n",
      "Train Epoch: 46 [1280/113287 (1%)]\tLoss: 0.875225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 46 [2560/113287 (2%)]\tLoss: 1.036689\n",
      "Train Epoch: 46 [3840/113287 (3%)]\tLoss: 0.804140\n",
      "Train Epoch: 46 [5120/113287 (5%)]\tLoss: 0.904875\n",
      "Train Epoch: 46 [6400/113287 (6%)]\tLoss: 0.877936\n",
      "Train Epoch: 46 [7680/113287 (7%)]\tLoss: 1.114337\n",
      "Train Epoch: 46 [8960/113287 (8%)]\tLoss: 0.943369\n",
      "Train Epoch: 46 [10240/113287 (9%)]\tLoss: 0.841765\n",
      "Train Epoch: 46 [11520/113287 (10%)]\tLoss: 0.974125\n",
      "Train Epoch: 46 [12800/113287 (11%)]\tLoss: 0.999456\n",
      "Train Epoch: 46 [14080/113287 (12%)]\tLoss: 0.616406\n",
      "Train Epoch: 46 [15360/113287 (14%)]\tLoss: 1.159494\n",
      "Train Epoch: 46 [16640/113287 (15%)]\tLoss: 0.748967\n",
      "Train Epoch: 46 [17920/113287 (16%)]\tLoss: 0.864580\n",
      "Train Epoch: 46 [19200/113287 (17%)]\tLoss: 0.887319\n",
      "Train Epoch: 46 [20480/113287 (18%)]\tLoss: 1.030105\n",
      "Train Epoch: 46 [21760/113287 (19%)]\tLoss: 0.826412\n",
      "Train Epoch: 46 [23040/113287 (20%)]\tLoss: 0.909408\n",
      "Train Epoch: 46 [24320/113287 (21%)]\tLoss: 0.939883\n",
      "Train Epoch: 46 [25600/113287 (23%)]\tLoss: 1.031458\n",
      "Train Epoch: 46 [26880/113287 (24%)]\tLoss: 0.850231\n",
      "Train Epoch: 46 [28160/113287 (25%)]\tLoss: 0.940454\n",
      "Train Epoch: 46 [29440/113287 (26%)]\tLoss: 0.720918\n",
      "Train Epoch: 46 [30720/113287 (27%)]\tLoss: 0.774862\n",
      "Train Epoch: 46 [32000/113287 (28%)]\tLoss: 1.102513\n",
      "Train Epoch: 46 [33280/113287 (29%)]\tLoss: 1.004386\n",
      "Train Epoch: 46 [34560/113287 (30%)]\tLoss: 1.199054\n",
      "Train Epoch: 46 [35840/113287 (32%)]\tLoss: 0.756460\n",
      "Train Epoch: 46 [37120/113287 (33%)]\tLoss: 0.920037\n",
      "Train Epoch: 46 [38400/113287 (34%)]\tLoss: 1.099244\n",
      "Train Epoch: 46 [39680/113287 (35%)]\tLoss: 1.173392\n",
      "Train Epoch: 46 [40960/113287 (36%)]\tLoss: 0.989113\n",
      "Train Epoch: 46 [42240/113287 (37%)]\tLoss: 0.847342\n",
      "Train Epoch: 46 [43520/113287 (38%)]\tLoss: 0.854457\n",
      "Train Epoch: 46 [44800/113287 (40%)]\tLoss: 0.724040\n",
      "Train Epoch: 46 [46080/113287 (41%)]\tLoss: 0.802945\n",
      "Train Epoch: 46 [47360/113287 (42%)]\tLoss: 0.869429\n",
      "Train Epoch: 46 [48640/113287 (43%)]\tLoss: 0.734750\n",
      "Train Epoch: 46 [49920/113287 (44%)]\tLoss: 0.970505\n",
      "Train Epoch: 46 [51200/113287 (45%)]\tLoss: 0.896391\n",
      "Train Epoch: 46 [52480/113287 (46%)]\tLoss: 0.900530\n",
      "Train Epoch: 46 [53760/113287 (47%)]\tLoss: 1.028858\n",
      "Train Epoch: 46 [55040/113287 (49%)]\tLoss: 0.917446\n",
      "Train Epoch: 46 [56320/113287 (50%)]\tLoss: 0.848065\n",
      "Train Epoch: 46 [57600/113287 (51%)]\tLoss: 0.970511\n",
      "Train Epoch: 46 [58880/113287 (52%)]\tLoss: 0.765041\n",
      "Train Epoch: 46 [60160/113287 (53%)]\tLoss: 0.962425\n",
      "Train Epoch: 46 [61440/113287 (54%)]\tLoss: 1.027893\n",
      "Train Epoch: 46 [62720/113287 (55%)]\tLoss: 0.973681\n",
      "Train Epoch: 46 [64000/113287 (56%)]\tLoss: 0.952581\n",
      "Train Epoch: 46 [65280/113287 (58%)]\tLoss: 0.853731\n",
      "Train Epoch: 46 [66560/113287 (59%)]\tLoss: 1.030796\n",
      "Train Epoch: 46 [67840/113287 (60%)]\tLoss: 0.941697\n",
      "Train Epoch: 46 [69120/113287 (61%)]\tLoss: 0.752787\n",
      "Train Epoch: 46 [70400/113287 (62%)]\tLoss: 0.812609\n",
      "Train Epoch: 46 [71680/113287 (63%)]\tLoss: 0.960728\n",
      "Train Epoch: 46 [72960/113287 (64%)]\tLoss: 0.937613\n",
      "Train Epoch: 46 [74240/113287 (65%)]\tLoss: 0.741116\n",
      "Train Epoch: 46 [75520/113287 (67%)]\tLoss: 0.896696\n",
      "Train Epoch: 46 [76800/113287 (68%)]\tLoss: 0.731484\n",
      "Train Epoch: 46 [78080/113287 (69%)]\tLoss: 0.834955\n",
      "Train Epoch: 46 [79360/113287 (70%)]\tLoss: 0.912940\n",
      "Train Epoch: 46 [80640/113287 (71%)]\tLoss: 0.864923\n",
      "Train Epoch: 46 [81920/113287 (72%)]\tLoss: 0.714368\n",
      "Train Epoch: 46 [83200/113287 (73%)]\tLoss: 0.907017\n",
      "Train Epoch: 46 [84480/113287 (74%)]\tLoss: 0.868785\n",
      "Train Epoch: 46 [85760/113287 (76%)]\tLoss: 0.838727\n",
      "Train Epoch: 46 [87040/113287 (77%)]\tLoss: 0.818832\n",
      "Train Epoch: 46 [88320/113287 (78%)]\tLoss: 0.972146\n",
      "Train Epoch: 46 [89600/113287 (79%)]\tLoss: 0.944951\n",
      "Train Epoch: 46 [90880/113287 (80%)]\tLoss: 0.884654\n",
      "Train Epoch: 46 [92160/113287 (81%)]\tLoss: 0.975777\n",
      "Train Epoch: 46 [93440/113287 (82%)]\tLoss: 1.102770\n",
      "Train Epoch: 46 [94720/113287 (84%)]\tLoss: 0.941695\n",
      "Train Epoch: 46 [96000/113287 (85%)]\tLoss: 1.056373\n",
      "Train Epoch: 46 [97280/113287 (86%)]\tLoss: 1.147159\n",
      "Train Epoch: 46 [98560/113287 (87%)]\tLoss: 1.004978\n",
      "Train Epoch: 46 [99840/113287 (88%)]\tLoss: 0.985902\n",
      "Train Epoch: 46 [101120/113287 (89%)]\tLoss: 1.049865\n",
      "Train Epoch: 46 [102400/113287 (90%)]\tLoss: 1.003646\n",
      "Train Epoch: 46 [103680/113287 (91%)]\tLoss: 1.135463\n",
      "Train Epoch: 46 [104960/113287 (93%)]\tLoss: 1.154273\n",
      "Train Epoch: 46 [106240/113287 (94%)]\tLoss: 0.746040\n",
      "Train Epoch: 46 [107520/113287 (95%)]\tLoss: 0.826106\n",
      "Train Epoch: 46 [108800/113287 (96%)]\tLoss: 0.987364\n",
      "Train Epoch: 46 [110080/113287 (97%)]\tLoss: 0.926699\n",
      "Train Epoch: 46 [111360/113287 (98%)]\tLoss: 0.903034\n",
      "Train Epoch: 46 [112640/113287 (99%)]\tLoss: 0.748770\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3604/5000 (72%)\n",
      "\n",
      "Train Epoch: 47 [0/113287 (0%)]\tLoss: 0.823323\n",
      "Train Epoch: 47 [1280/113287 (1%)]\tLoss: 0.840128\n",
      "Train Epoch: 47 [2560/113287 (2%)]\tLoss: 0.870930\n",
      "Train Epoch: 47 [3840/113287 (3%)]\tLoss: 0.696961\n",
      "Train Epoch: 47 [5120/113287 (5%)]\tLoss: 0.805656\n",
      "Train Epoch: 47 [6400/113287 (6%)]\tLoss: 1.011583\n",
      "Train Epoch: 47 [7680/113287 (7%)]\tLoss: 0.956445\n",
      "Train Epoch: 47 [8960/113287 (8%)]\tLoss: 0.814873\n",
      "Train Epoch: 47 [10240/113287 (9%)]\tLoss: 0.804943\n",
      "Train Epoch: 47 [11520/113287 (10%)]\tLoss: 1.017310\n",
      "Train Epoch: 47 [12800/113287 (11%)]\tLoss: 0.846140\n",
      "Train Epoch: 47 [14080/113287 (12%)]\tLoss: 0.845698\n",
      "Train Epoch: 47 [15360/113287 (14%)]\tLoss: 0.921236\n",
      "Train Epoch: 47 [16640/113287 (15%)]\tLoss: 0.869846\n",
      "Train Epoch: 47 [17920/113287 (16%)]\tLoss: 0.804512\n",
      "Train Epoch: 47 [19200/113287 (17%)]\tLoss: 0.921422\n",
      "Train Epoch: 47 [20480/113287 (18%)]\tLoss: 0.876281\n",
      "Train Epoch: 47 [21760/113287 (19%)]\tLoss: 0.773899\n",
      "Train Epoch: 47 [23040/113287 (20%)]\tLoss: 0.948234\n",
      "Train Epoch: 47 [24320/113287 (21%)]\tLoss: 1.011125\n",
      "Train Epoch: 47 [25600/113287 (23%)]\tLoss: 0.668783\n",
      "Train Epoch: 47 [26880/113287 (24%)]\tLoss: 1.126208\n",
      "Train Epoch: 47 [28160/113287 (25%)]\tLoss: 0.601430\n",
      "Train Epoch: 47 [29440/113287 (26%)]\tLoss: 0.940859\n",
      "Train Epoch: 47 [30720/113287 (27%)]\tLoss: 0.789718\n",
      "Train Epoch: 47 [32000/113287 (28%)]\tLoss: 1.053393\n",
      "Train Epoch: 47 [33280/113287 (29%)]\tLoss: 0.990665\n",
      "Train Epoch: 47 [34560/113287 (30%)]\tLoss: 0.822692\n",
      "Train Epoch: 47 [35840/113287 (32%)]\tLoss: 0.845631\n",
      "Train Epoch: 47 [37120/113287 (33%)]\tLoss: 0.889167\n",
      "Train Epoch: 47 [38400/113287 (34%)]\tLoss: 0.991322\n",
      "Train Epoch: 47 [39680/113287 (35%)]\tLoss: 1.081489\n",
      "Train Epoch: 47 [40960/113287 (36%)]\tLoss: 0.815824\n",
      "Train Epoch: 47 [42240/113287 (37%)]\tLoss: 0.791408\n",
      "Train Epoch: 47 [43520/113287 (38%)]\tLoss: 1.285253\n",
      "Train Epoch: 47 [44800/113287 (40%)]\tLoss: 0.827804\n",
      "Train Epoch: 47 [46080/113287 (41%)]\tLoss: 0.920387\n",
      "Train Epoch: 47 [47360/113287 (42%)]\tLoss: 0.908765\n",
      "Train Epoch: 47 [48640/113287 (43%)]\tLoss: 0.639171\n",
      "Train Epoch: 47 [49920/113287 (44%)]\tLoss: 1.026613\n",
      "Train Epoch: 47 [51200/113287 (45%)]\tLoss: 0.889366\n",
      "Train Epoch: 47 [52480/113287 (46%)]\tLoss: 0.859879\n",
      "Train Epoch: 47 [53760/113287 (47%)]\tLoss: 1.029132\n",
      "Train Epoch: 47 [55040/113287 (49%)]\tLoss: 0.897839\n",
      "Train Epoch: 47 [56320/113287 (50%)]\tLoss: 0.707440\n",
      "Train Epoch: 47 [57600/113287 (51%)]\tLoss: 0.835155\n",
      "Train Epoch: 47 [58880/113287 (52%)]\tLoss: 1.196353\n",
      "Train Epoch: 47 [60160/113287 (53%)]\tLoss: 1.005219\n",
      "Train Epoch: 47 [61440/113287 (54%)]\tLoss: 0.824369\n",
      "Train Epoch: 47 [62720/113287 (55%)]\tLoss: 0.794370\n",
      "Train Epoch: 47 [64000/113287 (56%)]\tLoss: 0.952353\n",
      "Train Epoch: 47 [65280/113287 (58%)]\tLoss: 0.810932\n",
      "Train Epoch: 47 [66560/113287 (59%)]\tLoss: 0.917186\n",
      "Train Epoch: 47 [67840/113287 (60%)]\tLoss: 1.056937\n",
      "Train Epoch: 47 [69120/113287 (61%)]\tLoss: 1.269409\n",
      "Train Epoch: 47 [70400/113287 (62%)]\tLoss: 0.805767\n",
      "Train Epoch: 47 [71680/113287 (63%)]\tLoss: 0.712860\n",
      "Train Epoch: 47 [72960/113287 (64%)]\tLoss: 0.871787\n",
      "Train Epoch: 47 [74240/113287 (65%)]\tLoss: 0.781448\n",
      "Train Epoch: 47 [75520/113287 (67%)]\tLoss: 0.824235\n",
      "Train Epoch: 47 [76800/113287 (68%)]\tLoss: 1.112244\n",
      "Train Epoch: 47 [78080/113287 (69%)]\tLoss: 1.329818\n",
      "Train Epoch: 47 [79360/113287 (70%)]\tLoss: 0.896032\n",
      "Train Epoch: 47 [80640/113287 (71%)]\tLoss: 0.944037\n",
      "Train Epoch: 47 [81920/113287 (72%)]\tLoss: 1.100341\n",
      "Train Epoch: 47 [83200/113287 (73%)]\tLoss: 0.992104\n",
      "Train Epoch: 47 [84480/113287 (74%)]\tLoss: 0.848077\n",
      "Train Epoch: 47 [85760/113287 (76%)]\tLoss: 0.969862\n",
      "Train Epoch: 47 [87040/113287 (77%)]\tLoss: 1.144749\n",
      "Train Epoch: 47 [88320/113287 (78%)]\tLoss: 0.898303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 47 [89600/113287 (79%)]\tLoss: 0.839537\n",
      "Train Epoch: 47 [90880/113287 (80%)]\tLoss: 0.966487\n",
      "Train Epoch: 47 [92160/113287 (81%)]\tLoss: 0.961458\n",
      "Train Epoch: 47 [93440/113287 (82%)]\tLoss: 0.977131\n",
      "Train Epoch: 47 [94720/113287 (84%)]\tLoss: 0.850925\n",
      "Train Epoch: 47 [96000/113287 (85%)]\tLoss: 1.072795\n",
      "Train Epoch: 47 [97280/113287 (86%)]\tLoss: 0.885150\n",
      "Train Epoch: 47 [98560/113287 (87%)]\tLoss: 0.962181\n",
      "Train Epoch: 47 [99840/113287 (88%)]\tLoss: 1.041693\n",
      "Train Epoch: 47 [101120/113287 (89%)]\tLoss: 0.997406\n",
      "Train Epoch: 47 [102400/113287 (90%)]\tLoss: 1.243246\n",
      "Train Epoch: 47 [103680/113287 (91%)]\tLoss: 0.828854\n",
      "Train Epoch: 47 [104960/113287 (93%)]\tLoss: 1.003646\n",
      "Train Epoch: 47 [106240/113287 (94%)]\tLoss: 0.963988\n",
      "Train Epoch: 47 [107520/113287 (95%)]\tLoss: 0.831327\n",
      "Train Epoch: 47 [108800/113287 (96%)]\tLoss: 0.890200\n",
      "Train Epoch: 47 [110080/113287 (97%)]\tLoss: 1.098419\n",
      "Train Epoch: 47 [111360/113287 (98%)]\tLoss: 0.979133\n",
      "Train Epoch: 47 [112640/113287 (99%)]\tLoss: 0.910585\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3599/5000 (71%)\n",
      "\n",
      "Train Epoch: 48 [0/113287 (0%)]\tLoss: 0.947229\n",
      "Train Epoch: 48 [1280/113287 (1%)]\tLoss: 0.961256\n",
      "Train Epoch: 48 [2560/113287 (2%)]\tLoss: 0.865886\n",
      "Train Epoch: 48 [3840/113287 (3%)]\tLoss: 1.050202\n",
      "Train Epoch: 48 [5120/113287 (5%)]\tLoss: 0.950956\n",
      "Train Epoch: 48 [6400/113287 (6%)]\tLoss: 1.089027\n",
      "Train Epoch: 48 [7680/113287 (7%)]\tLoss: 0.799040\n",
      "Train Epoch: 48 [8960/113287 (8%)]\tLoss: 0.942659\n",
      "Train Epoch: 48 [10240/113287 (9%)]\tLoss: 0.596347\n",
      "Train Epoch: 48 [11520/113287 (10%)]\tLoss: 0.854041\n",
      "Train Epoch: 48 [12800/113287 (11%)]\tLoss: 0.940556\n",
      "Train Epoch: 48 [14080/113287 (12%)]\tLoss: 0.964052\n",
      "Train Epoch: 48 [15360/113287 (14%)]\tLoss: 0.901068\n",
      "Train Epoch: 48 [16640/113287 (15%)]\tLoss: 1.109955\n",
      "Train Epoch: 48 [17920/113287 (16%)]\tLoss: 0.832865\n",
      "Train Epoch: 48 [19200/113287 (17%)]\tLoss: 0.853707\n",
      "Train Epoch: 48 [20480/113287 (18%)]\tLoss: 0.850468\n",
      "Train Epoch: 48 [21760/113287 (19%)]\tLoss: 0.952527\n",
      "Train Epoch: 48 [23040/113287 (20%)]\tLoss: 0.683085\n",
      "Train Epoch: 48 [24320/113287 (21%)]\tLoss: 0.802497\n",
      "Train Epoch: 48 [25600/113287 (23%)]\tLoss: 0.982753\n",
      "Train Epoch: 48 [26880/113287 (24%)]\tLoss: 0.989846\n",
      "Train Epoch: 48 [28160/113287 (25%)]\tLoss: 0.892215\n",
      "Train Epoch: 48 [29440/113287 (26%)]\tLoss: 0.862494\n",
      "Train Epoch: 48 [30720/113287 (27%)]\tLoss: 0.822081\n",
      "Train Epoch: 48 [32000/113287 (28%)]\tLoss: 0.977826\n",
      "Train Epoch: 48 [33280/113287 (29%)]\tLoss: 0.952271\n",
      "Train Epoch: 48 [34560/113287 (30%)]\tLoss: 0.823561\n",
      "Train Epoch: 48 [35840/113287 (32%)]\tLoss: 0.915634\n",
      "Train Epoch: 48 [37120/113287 (33%)]\tLoss: 0.889883\n",
      "Train Epoch: 48 [38400/113287 (34%)]\tLoss: 0.947007\n",
      "Train Epoch: 48 [39680/113287 (35%)]\tLoss: 0.865244\n",
      "Train Epoch: 48 [40960/113287 (36%)]\tLoss: 0.825610\n",
      "Train Epoch: 48 [42240/113287 (37%)]\tLoss: 0.762889\n",
      "Train Epoch: 48 [43520/113287 (38%)]\tLoss: 0.943995\n",
      "Train Epoch: 48 [44800/113287 (40%)]\tLoss: 0.846644\n",
      "Train Epoch: 48 [46080/113287 (41%)]\tLoss: 0.694166\n",
      "Train Epoch: 48 [47360/113287 (42%)]\tLoss: 0.894643\n",
      "Train Epoch: 48 [48640/113287 (43%)]\tLoss: 0.964428\n",
      "Train Epoch: 48 [49920/113287 (44%)]\tLoss: 0.958701\n",
      "Train Epoch: 48 [51200/113287 (45%)]\tLoss: 0.892645\n",
      "Train Epoch: 48 [52480/113287 (46%)]\tLoss: 1.027654\n",
      "Train Epoch: 48 [53760/113287 (47%)]\tLoss: 0.901890\n",
      "Train Epoch: 48 [55040/113287 (49%)]\tLoss: 1.047033\n",
      "Train Epoch: 48 [56320/113287 (50%)]\tLoss: 0.825307\n",
      "Train Epoch: 48 [57600/113287 (51%)]\tLoss: 1.080043\n",
      "Train Epoch: 48 [58880/113287 (52%)]\tLoss: 0.909656\n",
      "Train Epoch: 48 [60160/113287 (53%)]\tLoss: 1.027807\n",
      "Train Epoch: 48 [61440/113287 (54%)]\tLoss: 0.869265\n",
      "Train Epoch: 48 [62720/113287 (55%)]\tLoss: 1.111687\n",
      "Train Epoch: 48 [64000/113287 (56%)]\tLoss: 0.914624\n",
      "Train Epoch: 48 [65280/113287 (58%)]\tLoss: 0.995325\n",
      "Train Epoch: 48 [66560/113287 (59%)]\tLoss: 0.872020\n",
      "Train Epoch: 48 [67840/113287 (60%)]\tLoss: 0.739741\n",
      "Train Epoch: 48 [69120/113287 (61%)]\tLoss: 0.887444\n",
      "Train Epoch: 48 [70400/113287 (62%)]\tLoss: 1.256679\n",
      "Train Epoch: 48 [71680/113287 (63%)]\tLoss: 1.035255\n",
      "Train Epoch: 48 [72960/113287 (64%)]\tLoss: 0.881875\n",
      "Train Epoch: 48 [74240/113287 (65%)]\tLoss: 1.292231\n",
      "Train Epoch: 48 [75520/113287 (67%)]\tLoss: 1.000351\n",
      "Train Epoch: 48 [76800/113287 (68%)]\tLoss: 1.087987\n",
      "Train Epoch: 48 [78080/113287 (69%)]\tLoss: 0.975540\n",
      "Train Epoch: 48 [79360/113287 (70%)]\tLoss: 0.880276\n",
      "Train Epoch: 48 [80640/113287 (71%)]\tLoss: 0.972437\n",
      "Train Epoch: 48 [81920/113287 (72%)]\tLoss: 0.697356\n",
      "Train Epoch: 48 [83200/113287 (73%)]\tLoss: 0.849863\n",
      "Train Epoch: 48 [84480/113287 (74%)]\tLoss: 0.900798\n",
      "Train Epoch: 48 [85760/113287 (76%)]\tLoss: 0.908302\n",
      "Train Epoch: 48 [87040/113287 (77%)]\tLoss: 0.771797\n",
      "Train Epoch: 48 [88320/113287 (78%)]\tLoss: 0.982115\n",
      "Train Epoch: 48 [89600/113287 (79%)]\tLoss: 0.904761\n",
      "Train Epoch: 48 [90880/113287 (80%)]\tLoss: 0.810194\n",
      "Train Epoch: 48 [92160/113287 (81%)]\tLoss: 1.076588\n",
      "Train Epoch: 48 [93440/113287 (82%)]\tLoss: 0.794861\n",
      "Train Epoch: 48 [94720/113287 (84%)]\tLoss: 0.958228\n",
      "Train Epoch: 48 [96000/113287 (85%)]\tLoss: 0.793628\n",
      "Train Epoch: 48 [97280/113287 (86%)]\tLoss: 0.788029\n",
      "Train Epoch: 48 [98560/113287 (87%)]\tLoss: 1.023269\n",
      "Train Epoch: 48 [99840/113287 (88%)]\tLoss: 0.929148\n",
      "Train Epoch: 48 [101120/113287 (89%)]\tLoss: 0.965827\n",
      "Train Epoch: 48 [102400/113287 (90%)]\tLoss: 0.907930\n",
      "Train Epoch: 48 [103680/113287 (91%)]\tLoss: 0.915560\n",
      "Train Epoch: 48 [104960/113287 (93%)]\tLoss: 0.920228\n",
      "Train Epoch: 48 [106240/113287 (94%)]\tLoss: 0.889162\n",
      "Train Epoch: 48 [107520/113287 (95%)]\tLoss: 0.911312\n",
      "Train Epoch: 48 [108800/113287 (96%)]\tLoss: 0.843962\n",
      "Train Epoch: 48 [110080/113287 (97%)]\tLoss: 0.991273\n",
      "Train Epoch: 48 [111360/113287 (98%)]\tLoss: 0.606432\n",
      "Train Epoch: 48 [112640/113287 (99%)]\tLoss: 0.984125\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 3589/5000 (71%)\n",
      "\n",
      "Train Epoch: 49 [0/113287 (0%)]\tLoss: 0.735956\n",
      "Train Epoch: 49 [1280/113287 (1%)]\tLoss: 1.041396\n",
      "Train Epoch: 49 [2560/113287 (2%)]\tLoss: 0.822176\n",
      "Train Epoch: 49 [3840/113287 (3%)]\tLoss: 1.144690\n",
      "Train Epoch: 49 [5120/113287 (5%)]\tLoss: 0.846066\n",
      "Train Epoch: 49 [6400/113287 (6%)]\tLoss: 0.909328\n",
      "Train Epoch: 49 [7680/113287 (7%)]\tLoss: 0.903108\n",
      "Train Epoch: 49 [8960/113287 (8%)]\tLoss: 0.638526\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1f6eee941599>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-1b2df35d6684>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;31m# need to call `.task_done()` because we don't use `.join()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrebuild_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0manswer_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0mdeliver_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mhmac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# reject large message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHALLENGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCHALLENGE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message = %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHALLENGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 50):\n",
    "    \n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/why/anaconda3/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, \"models/image_topic.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "\n",
    "data_folder = '/home/why/image-captioning-bottom-up-top-down/other_dataset'\n",
    "data_name = 'coco_5_cap_per_img_5_min_word_freq'\n",
    "\n",
    "# Training settings\n",
    "batch_size = 128\n",
    "workers = 1\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    CaptionDataset(data_folder ,data_name, 'TEST'),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"models/image_topic.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx,(data, target) in enumerate(test_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/why/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \n",
      "/home/why/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/why/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "data, target = data.cuda(), target.cuda()\n",
    "data = Variable(data,volatile = True)\n",
    "target = Variable(target,volatile = True)\n",
    "output = model(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ind = output.topk(1,1 ,True,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6],\n",
       "        [49],\n",
       "        [38],\n",
       "        [ 0],\n",
       "        [49],\n",
       "        [19],\n",
       "        [49],\n",
       "        [15],\n",
       "        [21],\n",
       "        [49],\n",
       "        [36],\n",
       "        [23],\n",
       "        [12],\n",
       "        [ 7],\n",
       "        [ 7],\n",
       "        [ 1],\n",
       "        [20],\n",
       "        [39],\n",
       "        [22],\n",
       "        [16],\n",
       "        [25],\n",
       "        [14],\n",
       "        [20],\n",
       "        [11],\n",
       "        [26],\n",
       "        [25],\n",
       "        [ 4],\n",
       "        [ 6],\n",
       "        [21],\n",
       "        [47],\n",
       "        [25],\n",
       "        [49],\n",
       "        [ 2],\n",
       "        [22],\n",
       "        [24],\n",
       "        [30],\n",
       "        [33],\n",
       "        [23],\n",
       "        [ 2],\n",
       "        [20],\n",
       "        [37],\n",
       "        [14],\n",
       "        [16],\n",
       "        [46],\n",
       "        [11],\n",
       "        [20],\n",
       "        [41],\n",
       "        [28],\n",
       "        [18],\n",
       "        [35],\n",
       "        [ 9],\n",
       "        [42],\n",
       "        [43],\n",
       "        [22],\n",
       "        [ 4],\n",
       "        [20],\n",
       "        [ 2],\n",
       "        [38],\n",
       "        [11],\n",
       "        [33],\n",
       "        [46],\n",
       "        [ 2],\n",
       "        [43],\n",
       "        [39],\n",
       "        [47],\n",
       "        [ 7],\n",
       "        [ 2],\n",
       "        [33],\n",
       "        [48],\n",
       "        [25],\n",
       "        [15],\n",
       "        [26],\n",
       "        [39],\n",
       "        [16],\n",
       "        [34],\n",
       "        [26],\n",
       "        [28],\n",
       "        [ 3],\n",
       "        [36],\n",
       "        [ 3],\n",
       "        [30],\n",
       "        [11],\n",
       "        [30],\n",
       "        [22],\n",
       "        [ 3],\n",
       "        [16],\n",
       "        [39],\n",
       "        [20],\n",
       "        [ 8],\n",
       "        [25],\n",
       "        [37],\n",
       "        [37],\n",
       "        [ 4],\n",
       "        [ 0],\n",
       "        [20],\n",
       "        [39],\n",
       "        [43],\n",
       "        [ 8],\n",
       "        [41],\n",
       "        [11],\n",
       "        [33],\n",
       "        [13],\n",
       "        [22],\n",
       "        [23],\n",
       "        [37],\n",
       "        [45],\n",
       "        [ 9],\n",
       "        [30],\n",
       "        [ 4],\n",
       "        [45],\n",
       "        [ 4],\n",
       "        [28],\n",
       "        [33],\n",
       "        [14],\n",
       "        [28],\n",
       "        [ 7],\n",
       "        [ 0],\n",
       "        [16],\n",
       "        [ 2],\n",
       "        [45],\n",
       "        [43],\n",
       "        [44],\n",
       "        [ 9],\n",
       "        [30],\n",
       "        [34],\n",
       "        [25],\n",
       "        [42],\n",
       "        [ 2]], device='cuda:1')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx,(data, target) in enumerate(test_loader):\n",
    "        batch_size = data.size(0)\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        data = Variable(data,volatile = True)\n",
    "        target = Variable(target,volatile = True)\n",
    "        #target = target.squeeze()\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        #loss += F.nll_loss(output, target.squeeze(),size_average=False)\n",
    "        # get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        #correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        correct += pred.eq(target).sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
