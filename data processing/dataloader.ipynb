{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import json\n",
    "import h5py\n",
    "import lmdb\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import multiprocessing\n",
    "import six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridLoader:\n",
    "    \n",
    "    def __init__(self, db_path, ext):\n",
    "        self.db_path = db_path\n",
    "        self.ext = ext\n",
    "        if self.ext == '.npy':\n",
    "            self.loader = lambda x: np.load(x)\n",
    "        else:\n",
    "            self.loader = lambda x: np.load(x)['feat']\n",
    "        if db_path.endswith('.lmdb'):\n",
    "            self.db_type = 'lmdb'\n",
    "            self.env = lmdb.open(db_path, subdir=os.path.isdir(db_path),\n",
    "                                readonly=True, lock=False,\n",
    "                                readahead=False, meminit=False)\n",
    "        else:\n",
    "            self.db_type = 'dir'\n",
    "    \n",
    "    def get(self, key):\n",
    "\n",
    "        if self.db_type == 'lmdb':\n",
    "            env = self.env\n",
    "            with env.begin(write=False) as txn:\n",
    "                byteflow = txn.get(key)\n",
    "            f_input = six.BytesIO(byteflow)\n",
    "        else:\n",
    "            f_input = os.path.join(self.db_path, key + self.ext)\n",
    "\n",
    "        # load image\n",
    "        feat = self.loader(f_input)\n",
    "\n",
    "        return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlobFetcher():\n",
    "    \"\"\"Experimental class for prefetching blobs in a separate process.\"\"\"\n",
    "    def __init__(self, split, dataloader, if_shuffle=False):\n",
    "        \"\"\"\n",
    "        db is a list of tuples containing: imcrop_name, caption, bbox_feat of gt box, imname\n",
    "        \"\"\"\n",
    "        self.split = split\n",
    "        self.dataloader = dataloader\n",
    "        self.if_shuffle = if_shuffle\n",
    "\n",
    "    # Add more in the queue\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Two cases for this function to be triggered:\n",
    "        1. not hasattr(self, 'split_loader'): Resume from previous training. Create the dataset given the saved split_ix and iterator\n",
    "        2. wrapped: a new epoch, the split_ix and iterator have been updated in the get_minibatch_inds already.\n",
    "        \"\"\"\n",
    "        # batch_size is 1, the merge is done in DataLoader class\n",
    "        self.split_loader = iter(data.DataLoader(dataset=self.dataloader,\n",
    "                                            batch_size=1,\n",
    "                                            sampler=SubsetSampler(self.dataloader.split_ix[self.split][self.dataloader.iterators[self.split]:]),\n",
    "                                            shuffle=False,\n",
    "                                            pin_memory=True,\n",
    "                                            num_workers=4, # 4 is usually enough\n",
    "                                            collate_fn=lambda x: x[0]))\n",
    "\n",
    "    def _get_next_minibatch_inds(self):\n",
    "        max_index = len(self.dataloader.split_ix[self.split])\n",
    "        wrapped = False\n",
    "\n",
    "        ri = self.dataloader.iterators[self.split]\n",
    "        ix = self.dataloader.split_ix[self.split][ri]\n",
    "\n",
    "        ri_next = ri + 1\n",
    "        if ri_next >= max_index:\n",
    "            ri_next = 0\n",
    "            if self.if_shuffle:\n",
    "                random.shuffle(self.dataloader.split_ix[self.split])\n",
    "            wrapped = True\n",
    "        self.dataloader.iterators[self.split] = ri_next\n",
    "\n",
    "        return ix, wrapped\n",
    "    \n",
    "    def get(self):\n",
    "        if not hasattr(self, 'split_loader'):\n",
    "            self.reset()\n",
    "\n",
    "        ix, wrapped = self._get_next_minibatch_inds()\n",
    "        tmp = self.split_loader.next()\n",
    "        if wrapped:\n",
    "            self.reset()\n",
    "\n",
    "        assert tmp[2] == ix, \"ix not equal\"\n",
    "\n",
    "        return tmp + [wrapped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubsetSampler(torch.utils.data.sampler.Sampler):\n",
    "    r\"\"\"Samples elements randomly from a given list of indices, without replacement.\n",
    "    Arguments:\n",
    "        indices (list): a list of indices\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, indices):\n",
    "        self.indices = indices\n",
    "\n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in range(len(self.indices)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(data.Dataset):\n",
    "\n",
    "    def reset_iterator(self, split):\n",
    "        del self._prefetch_process[split]\n",
    "        self._prefetch_process[split] = BlobFetcher(split, self, split=='train')\n",
    "        self.iterators[split] = 0\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return self.vocab_size\n",
    "\n",
    "    def get_vocab(self):\n",
    "        return self.ix_to_word\n",
    "\n",
    "    def get_seq_length(self):\n",
    "        return self.seq_length\n",
    "\n",
    "    def __init__(self):\n",
    "        self.batch_size = 5\n",
    "        self.seq_per_img = 5\n",
    "        \n",
    "        # feature related options\n",
    "        self.use_fc = True\n",
    "        self.use_att = True\n",
    "        self.use_box = 0\n",
    "        self.norm_att_feat = 0\n",
    "        self.norm_box_feat = 0\n",
    "\n",
    "        # load the json file which contains additional information about the dataset\n",
    "        print('DataLoader loading json file: ', '/home/sdb1/why/self-critical/data/data.json')\n",
    "        self.info = json.load(open('/home/sdb1/why/self-critical/data/data.json'))    \n",
    "        self.ix_to_word = self.info['ix_to_word']\n",
    "        self.vocab_size = len(self.ix_to_word)\n",
    "        print('vocab size is ', self.vocab_size)\n",
    "        \n",
    "        # open the hdf5 file\n",
    "        print('DataLoader loading h5 file: ')\n",
    "        self.h5_label_file = h5py.File('/home/sdb1/why/self-critical/data/data_label.h5', 'r', driver='core')\n",
    "\n",
    "        self.fc_loader = HybridLoader('/home/sdb1/why/COCO/cocobu_fc', '.npy')\n",
    "        self.att_loader = HybridLoader('/home/sdb1/why/COCO/cocobu_att', '.npz')\n",
    "        self.box_loader = HybridLoader('/home/sdb1/why/COCO/cocobu_box', '.npy')\n",
    "\n",
    "        # load in the sequence data\n",
    "        seq_size = self.h5_label_file['labels'].shape\n",
    "        self.seq_length = seq_size[1]\n",
    "        print('max sequence length in data is', self.seq_length)\n",
    "        # load the pointers in full to RAM (should be small enough)\n",
    "        self.label_start_ix = self.h5_label_file['label_start_ix'][:]   # 开始序号\n",
    "        self.label_end_ix = self.h5_label_file['label_end_ix'][:]       # 结束序号\n",
    "\n",
    "        self.num_images = self.label_start_ix.shape[0]\n",
    "        print('read %d image features' %(self.num_images))\n",
    "\n",
    "        # separate out indexes for each of the provided splits\n",
    "        self.split_ix = {'train': [], 'val': [], 'test': []}\n",
    "        for ix in range(len(self.info['images'])):\n",
    "            img = self.info['images'][ix]\n",
    "            if img['split'] == 'train':\n",
    "                self.split_ix['train'].append(ix)\n",
    "            elif img['split'] == 'val':\n",
    "                self.split_ix['val'].append(ix)\n",
    "            elif img['split'] == 'test':\n",
    "                self.split_ix['test'].append(ix)\n",
    "            else: # restval\n",
    "                self.split_ix['train'].append(ix)\n",
    "\n",
    "        print('assigned %d images to split train' %len(self.split_ix['train']))\n",
    "        print('assigned %d images to split val' %len(self.split_ix['val']))\n",
    "        print('assigned %d images to split test' %len(self.split_ix['test']))\n",
    "\n",
    "        self.iterators = {'train': 0, 'val': 0, 'test': 0}\n",
    "        \n",
    "        self._prefetch_process = {} # The three prefetch process\n",
    "        for split in self.iterators.keys():\n",
    "            self._prefetch_process[split] = BlobFetcher(split, self, split=='train')\n",
    "            # Terminate the child process when the parent exists\n",
    "        def cleanup():\n",
    "            print('Terminating BlobFetcher')\n",
    "            for split in self.iterators.keys():\n",
    "                del self._prefetch_process[split]\n",
    "        import atexit\n",
    "        atexit.register(cleanup)\n",
    "\n",
    "    def get_captions(self, ix, seq_per_img):\n",
    "        # fetch the sequence labels\n",
    "        #获取序列标签\n",
    "        ix1 = self.label_start_ix[ix] - 1 #label_start_ix starts from 1\n",
    "        ix2 = self.label_end_ix[ix] - 1\n",
    "        ncap = ix2 - ix1 + 1 # number of captions available for this image\n",
    "        assert ncap > 0, 'an image does not have any label. this can be handled but right now isn\\'t'\n",
    "\n",
    "        if ncap < seq_per_img:\n",
    "            # we need to subsample (with replacement)\n",
    "            seq = np.zeros([seq_per_img, self.seq_length], dtype = 'int')\n",
    "            for q in range(seq_per_img):\n",
    "                ixl = random.randint(ix1,ix2)\n",
    "                seq[q, :] = self.h5_label_file['labels'][ixl, :self.seq_length]\n",
    "        else:\n",
    "            ixl = random.randint(ix1, ix2 - seq_per_img + 1)\n",
    "            seq = self.h5_label_file['labels'][ixl: ixl + seq_per_img, :self.seq_length]\n",
    "\n",
    "        return seq\n",
    "\n",
    "    def get_batch(self, split, batch_size=None, seq_per_img=None):\n",
    "        batch_size = batch_size or self.batch_size\n",
    "        seq_per_img = seq_per_img or self.seq_per_img\n",
    "\n",
    "        fc_batch = [] # np.ndarray((batch_size * seq_per_img, self.opt.fc_feat_size), dtype = 'float32')\n",
    "        att_batch = [] # np.ndarray((batch_size * seq_per_img, 14, 14, self.opt.att_feat_size), dtype = 'float32')\n",
    "        \n",
    "        topic_class_batch = []\n",
    "        topic_word_batch = []\n",
    "        \n",
    "        label_batch = [] #np.zeros([batch_size * seq_per_img, self.seq_length + 2], dtype = 'int')\n",
    "        other_label_batch = []\n",
    "        \n",
    "        wrapped = False\n",
    "\n",
    "        infos = []\n",
    "        gts = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            # fetch image\n",
    "            tmp_fc, tmp_att,\\\n",
    "                ix, tmp_wrapped = self._prefetch_process[split].get()\n",
    "            \n",
    "            if tmp_wrapped:\n",
    "                wrapped = True\n",
    "\n",
    "            fc_batch.append(tmp_fc)\n",
    "            att_batch.append(tmp_att)\n",
    "            \n",
    "            tmp_label = np.zeros([seq_per_img, self.seq_length + 2], dtype = 'int')\n",
    "            tmp_label[:, 1 : self.seq_length + 1] = self.get_captions(ix, seq_per_img)\n",
    "            label_batch.append(tmp_label)\n",
    "\n",
    "            # Used for reward evaluation\n",
    "            gts.append(self.h5_label_file['labels'][self.label_start_ix[ix] - 1: self.label_end_ix[ix]])\n",
    "        \n",
    "            # record associated info as well\n",
    "            info_dict = {}\n",
    "            info_dict['ix'] = ix\n",
    "            info_dict['id'] = self.info['images'][ix]['id']\n",
    "            info_dict['file_path'] = self.info['images'][ix]['file_path']\n",
    "            infos.append(info_dict)\n",
    "            topic_class_batch.append(self.info['images'][ix]['topic_class'])\n",
    "            topic_word_batch.append(self.info['images'][ix]['topic_word'])\n",
    "            \n",
    "\n",
    "        # #sort by att_feat length\n",
    "        # fc_batch, att_batch, label_batch, gts, infos = \\\n",
    "        #     zip(*sorted(zip(fc_batch, att_batch, np.vsplit(label_batch, batch_size), gts, infos), key=lambda x: len(x[1]), reverse=True))\n",
    "        fc_batch, att_batch, label_batch, topic_class_batch,topic_word_batch, gts, infos = \\\n",
    "            zip(*sorted(zip(fc_batch, att_batch, label_batch,topic_class_batch,topic_word_batch, gts, infos), key=lambda x: 0, reverse=True))\n",
    "        data = {}\n",
    "        data['fc_feats'] = np.stack(sum([[_]*seq_per_img for _ in fc_batch], []))\n",
    "        # merge att_feats\n",
    "        max_att_len = max([_.shape[0] for _ in att_batch])\n",
    "        data['att_feats'] = np.zeros([len(att_batch)*seq_per_img, max_att_len, att_batch[0].shape[1]], dtype = 'float32')\n",
    "        for i in range(len(att_batch)):\n",
    "            data['att_feats'][i*seq_per_img:(i+1)*seq_per_img, :att_batch[i].shape[0]] = att_batch[i]\n",
    "        data['att_masks'] = np.zeros(data['att_feats'].shape[:2], dtype='float32')\n",
    "        for i in range(len(att_batch)):\n",
    "            data['att_masks'][i*seq_per_img:(i+1)*seq_per_img, :att_batch[i].shape[0]] = 1\n",
    "        # set att_masks to None if attention features have same length\n",
    "        if data['att_masks'].sum() == data['att_masks'].size:\n",
    "            data['att_masks'] = None\n",
    "\n",
    "        data['labels'] = np.vstack(label_batch)  # 数组堆叠\n",
    "        # generate mask\n",
    "        nonzeros = np.array(list(map(lambda x: (x != 0).sum()+2, data['labels'])))\n",
    "        mask_batch = np.zeros([data['labels'].shape[0], self.seq_length + 2], dtype = 'float32')\n",
    "        for ix, row in enumerate(mask_batch):\n",
    "            row[:nonzeros[ix]] = 1\n",
    "        data['masks'] = mask_batch\n",
    "        \n",
    "        \n",
    "        \n",
    "        data['gts'] = gts # all ground truth captions of each images\n",
    "        data['bounds'] = {'it_pos_now': self.iterators[split], 'it_max': len(self.split_ix[split]), 'wrapped': wrapped}\n",
    "        data['infos'] = infos\n",
    "\n",
    "        ########################################################################\n",
    "        data['topic_class'] = np.stack(sum([[_]*seq_per_img for _ in topic_class_batch], []))\n",
    "        data['topic_word'] = np.stack(sum([[_]*seq_per_img for _ in topic_word_batch], []))\n",
    "        \n",
    "        data['other_labels'] = np.concatenate((data['labels'][5:],data['labels'][:5]),axis = 0)\n",
    "        \n",
    "        #########################################################################\n",
    "        \n",
    "        data = {k:torch.from_numpy(v) if type(v) is np.ndarray else v for k,v in data.items()} # Turn all ndarray to torch tensor\n",
    "        \n",
    "        return data\n",
    "\n",
    "    # It's not coherent to make DataLoader a subclass of Dataset, but essentially, we only need to implement the following to functions,\n",
    "    # so that the torch.utils.data.DataLoader can load the data according the index.\n",
    "    # However, it's minimum change to switch to pytorch data loading.\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"This function returns a tuple that is further passed to collate_fn\n",
    "        \"\"\"\n",
    "        ix = index #self.split_ix[index]\n",
    "        if self.use_att:\n",
    "            att_feat = self.att_loader.get(str(self.info['images'][ix]['id']))\n",
    "            # Reshape to K x C\n",
    "            att_feat = att_feat.reshape(-1, att_feat.shape[-1])\n",
    "            if self.norm_att_feat:\n",
    "                att_feat = att_feat / np.linalg.norm(att_feat, 2, 1, keepdims=True)\n",
    "            if self.use_box:\n",
    "                box_feat = self.box_loader.get(str(self.info['images'][ix]['id']))\n",
    "                # devided by image width and height\n",
    "                x1,y1,x2,y2 = np.hsplit(box_feat, 4)\n",
    "                h,w = self.info['images'][ix]['height'], self.info['images'][ix]['width']\n",
    "                box_feat = np.hstack((x1/w, y1/h, x2/w, y2/h, (x2-x1)*(y2-y1)/(w*h))) # question? x2-x1+1??\n",
    "                if self.norm_box_feat:\n",
    "                    box_feat = box_feat / np.linalg.norm(box_feat, 2, 1, keepdims=True)\n",
    "                att_feat = np.hstack([att_feat, box_feat])\n",
    "                # sort the features by the size of boxes\n",
    "                att_feat = np.stack(sorted(att_feat, key=lambda x:x[-1], reverse=True))\n",
    "        else:\n",
    "            att_feat = np.zeros((1,1,1), dtype='float32')\n",
    "        if self.use_fc:\n",
    "            fc_feat = self.fc_loader.get(str(self.info['images'][ix]['id']))\n",
    "        else:\n",
    "            fc_feat = np.zeros((1), dtype='float32')\n",
    "        return (fc_feat,\n",
    "                att_feat,\n",
    "                ix)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.info['images'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader loading json file:  /home/sdb1/why/self-critical/data/data.json\n",
      "vocab size is  9487\n",
      "DataLoader loading h5 file: \n",
      "max sequence length in data is 18\n",
      "read 123287 image features\n",
      "assigned 113287 images to split train\n",
      "assigned 5000 images to split val\n",
      "assigned 5000 images to split test\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fc_feats', 'att_feats', 'att_masks', 'labels', 'masks', 'gts', 'bounds', 'infos', 'topic_class', 'topic_word', 'other_labels'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 20])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['other_labels'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 20])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['topic_word'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22, 22, 22, 22, 22,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8, 51, 51, 51,\n",
       "        51, 51, 25, 25, 25, 25, 25])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['topic_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
